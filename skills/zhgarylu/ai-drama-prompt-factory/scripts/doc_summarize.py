#!/usr/bin/env python3
"""
doc_summarize.py - æ–‡æ¡£ç»“æ„æ‘˜è¦å™¨
åŸºäºç´¢å¼•ç”Ÿæˆæ–‡æ¡£çš„ç»“æ„åŒ–æ¦‚è§ˆ

ç”¨æ³•ï¼š
    python3 doc_summarize.py --index doc_index.json
    python3 doc_summarize.py --index doc_index.json --depth 3 --keywords
"""

import argparse
import json
from pathlib import Path
from typing import Dict, List, Any


def load_index(index_path: str) -> Dict[str, Any]:
    """åŠ è½½ç´¢å¼•æ–‡ä»¶"""
    with open(index_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def format_size(size_bytes: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if size_bytes < 1024:
        return f'{size_bytes} B'
    elif size_bytes < 1024 * 1024:
        return f'{size_bytes / 1024:.1f} KB'
    else:
        return f'{size_bytes / (1024 * 1024):.1f} MB'


def summarize_file(file_info: Dict[str, Any], depth: int = 2, show_keywords: bool = False) -> str:
    """ç”Ÿæˆå•ä¸ªæ–‡ä»¶çš„æ‘˜è¦"""
    output = []
    
    filename = file_info.get('filename', 'æœªçŸ¥æ–‡ä»¶')
    total_lines = file_info.get('total_lines', 0)
    file_type = file_info.get('type', 'unknown')
    size = file_info.get('size_bytes', 0)
    
    output.append(f'ğŸ“„ {filename}')
    output.append(f'   ç±»å‹: {file_type} | è¡Œæ•°: {total_lines} | å¤§å°: {format_size(size)}')
    
    # æ˜¾ç¤ºç« èŠ‚ç»“æ„
    sections = file_info.get('sections', [])
    if sections:
        output.append(f'   ğŸ“‘ ç« èŠ‚ç»“æ„ ({len(sections)} ä¸ª):')
        
        shown_sections = 0
        for s in sections:
            level = s.get('level', 1)
            if level <= depth:
                title = s.get('title', 'æœªå‘½å')
                start = s.get('start_line', '?')
                end = s.get('end_line', '?')
                s_type = s.get('type', '')
                
                indent = '   ' * level
                type_tag = f' [{s_type}]' if s_type and s_type not in ['section'] else ''
                output.append(f'   {indent}â€¢ {title}{type_tag} (è¡Œ {start}-{end})')
                shown_sections += 1
                
                if shown_sections >= 20:
                    output.append(f'   ... è¿˜æœ‰ {len(sections) - shown_sections} ä¸ªç« èŠ‚')
                    break
    
    # JSON ç»“æ„
    if 'structure' in file_info:
        structure = file_info['structure']
        if isinstance(structure, dict):
            if structure.get('type') == 'object':
                keys = structure.get('keys', [])
                output.append(f'   ğŸ”‘ é¡¶çº§é”®: {", ".join(keys[:15])}')
                if len(keys) > 15:
                    output.append(f'       ... è¿˜æœ‰ {len(keys) - 15} ä¸ªé”®')
            elif structure.get('type') == 'array':
                output.append(f'   ğŸ“¦ æ•°ç»„é•¿åº¦: {structure.get("length", "?")}')
    
    # å…³é”®è¯
    if show_keywords:
        keywords = file_info.get('keywords', [])
        if keywords:
            output.append(f'   ğŸ”‘ å…³é”®è¯: {", ".join(keywords[:15])}')
    
    return '\n'.join(output)


def summarize_directory(index: Dict[str, Any], depth: int = 2, 
                        show_keywords: bool = False, max_files: int = 20) -> str:
    """ç”Ÿæˆç›®å½•ç´¢å¼•çš„æ‘˜è¦"""
    output = []
    
    path = index.get('path', 'æœªçŸ¥ç›®å½•')
    total_files = index.get('total_files', 0)
    total_lines = index.get('total_lines', 0)
    indexed_at = index.get('indexed_at', '?')
    
    output.append('=' * 60)
    output.append(f'ğŸ“ æ–‡æ¡£é›†ç´¢å¼•æ‘˜è¦')
    output.append('=' * 60)
    output.append(f'ğŸ“ è·¯å¾„: {path}')
    output.append(f'ğŸ“Š ç»Ÿè®¡: {total_files} ä¸ªæ–‡ä»¶, {total_lines} è¡Œ')
    output.append(f'ğŸ• ç´¢å¼•æ—¶é—´: {indexed_at}')
    
    # å…¨å±€å…³é”®è¯
    top_keywords = index.get('top_keywords', [])
    if top_keywords:
        output.append(f'ğŸ”‘ çƒ­é—¨å…³é”®è¯: {", ".join(top_keywords[:20])}')
    
    output.append('-' * 60)
    
    # æŒ‰ç±»å‹åˆ†ç»„
    files = index.get('files', [])
    by_type = {}
    for f in files:
        ftype = f.get('type', 'unknown')
        if ftype not in by_type:
            by_type[ftype] = []
        by_type[ftype].append(f)
    
    output.append(f'\nğŸ“Š æ–‡ä»¶ç±»å‹åˆ†å¸ƒ:')
    for ftype, file_list in sorted(by_type.items(), key=lambda x: -len(x[1])):
        total_lines_in_type = sum(f.get('total_lines', 0) for f in file_list)
        output.append(f'   â€¢ {ftype}: {len(file_list)} ä¸ªæ–‡ä»¶, {total_lines_in_type} è¡Œ')
    
    output.append(f'\nğŸ“„ æ–‡ä»¶åˆ—è¡¨ (æ˜¾ç¤º {min(max_files, len(files))}/{len(files)}):')
    output.append('-' * 60)
    
    # æŒ‰è¡Œæ•°æ’åºï¼Œå¤§æ–‡ä»¶ä¼˜å…ˆ
    sorted_files = sorted(files, key=lambda x: x.get('total_lines', 0), reverse=True)
    
    for i, file_info in enumerate(sorted_files[:max_files]):
        if i > 0:
            output.append('')
        output.append(summarize_file(file_info, depth, show_keywords))
    
    if len(files) > max_files:
        output.append(f'\n... è¿˜æœ‰ {len(files) - max_files} ä¸ªæ–‡ä»¶æœªæ˜¾ç¤º')
        output.append('   ä½¿ç”¨ --max-files å¢åŠ æ˜¾ç¤ºæ•°é‡')
    
    return '\n'.join(output)


def summarize_single_file(index: Dict[str, Any], depth: int = 2, 
                          show_keywords: bool = False) -> str:
    """ç”Ÿæˆå•æ–‡ä»¶ç´¢å¼•çš„æ‘˜è¦"""
    files = index.get('files', [])
    if not files:
        return 'âŒ ç´¢å¼•ä¸­æ²¡æœ‰æ–‡ä»¶'
    
    file_info = files[0]
    output = []
    
    output.append('=' * 60)
    output.append(f'ğŸ“„ æ–‡æ¡£æ‘˜è¦')
    output.append('=' * 60)
    output.append(summarize_file(file_info, depth, show_keywords))
    
    # é¢å¤–çš„è¯¦ç»†ä¿¡æ¯
    sections = file_info.get('sections', [])
    if sections and len(sections) > 5:
        output.append('\n' + '=' * 60)
        output.append('ğŸ“‘ å®Œæ•´ç« èŠ‚ç›®å½•:')
        output.append('=' * 60)
        
        for i, s in enumerate(sections, 1):
            level = s.get('level', 1)
            title = s.get('title', 'æœªå‘½å')
            start = s.get('start_line', '?')
            end = s.get('end_line', '?')
            
            indent = '  ' * (level - 1)
            output.append(f'{i:3d}. {indent}{title} (è¡Œ {start}-{end})')
    
    return '\n'.join(output)


def main():
    parser = argparse.ArgumentParser(description='æ–‡æ¡£ç»“æ„æ‘˜è¦å™¨')
    parser.add_argument('--index', '-i', required=True, help='ç´¢å¼•æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--depth', '-d', type=int, default=2, help='æ˜¾ç¤ºçš„ç« èŠ‚å±‚çº§æ·±åº¦')
    parser.add_argument('--keywords', '-k', action='store_true', help='æ˜¾ç¤ºå…³é”®è¯')
    parser.add_argument('--max-files', '-m', type=int, default=20, help='æœ€å¤§æ˜¾ç¤ºæ–‡ä»¶æ•°')
    parser.add_argument('--json', action='store_true', help='è¾“å‡º JSON æ ¼å¼')
    
    args = parser.parse_args()
    
    # åŠ è½½ç´¢å¼•
    try:
        index = load_index(args.index)
    except Exception as e:
        print(f'âŒ æ— æ³•åŠ è½½ç´¢å¼•: {e}')
        return 1
    
    if args.json:
        # è¾“å‡ºç²¾ç®€çš„ JSON æ‘˜è¦
        summary = {
            'type': index.get('type'),
            'path': index.get('path'),
            'total_files': index.get('total_files'),
            'total_lines': index.get('total_lines'),
            'top_keywords': index.get('top_keywords', [])[:20],
            'files': [
                {
                    'filename': f.get('filename'),
                    'type': f.get('type'),
                    'total_lines': f.get('total_lines'),
                    'sections_count': len(f.get('sections', [])),
                }
                for f in index.get('files', [])
            ]
        }
        print(json.dumps(summary, ensure_ascii=False, indent=2))
    else:
        # ç”Ÿæˆæ–‡æœ¬æ‘˜è¦
        if index.get('type') == 'directory':
            print(summarize_directory(index, args.depth, args.keywords, args.max_files))
        else:
            print(summarize_single_file(index, args.depth, args.keywords))
    
    return 0


if __name__ == '__main__':
    exit(main())
