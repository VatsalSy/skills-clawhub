"""
æ¨ç‰¹ Processor èŠ‚ç‚¹ â€” LLM æç‚¼å¼•æ“

è¯»å– pending_tweets.jsonï¼Œè°ƒç”¨ LLM ç”ŸæˆæŠ€æœ¯é”è¯„ï¼Œè¾“å‡ºåˆ° drafts.jsonã€‚

é…ç½®æ–¹å¼ï¼ˆç¯å¢ƒå˜é‡ï¼‰ï¼š
  LLM_API_KEY     - API å¯†é’¥ï¼ˆå¿…é¡»ï¼‰
  LLM_BASE_URL    - API ç«¯ç‚¹ï¼ˆé»˜è®¤ https://api.openai.com/v1ï¼‰
  LLM_MODEL       - æ¨¡å‹åç§°ï¼ˆé»˜è®¤ gpt-4o-miniï¼‰
"""

import json
import os
import sys
from datetime import datetime

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PENDING_FILE = os.path.join(BASE_DIR, "pending_tweets.json")
DRAFTS_FILE = os.path.join(BASE_DIR, "drafts.json")

def get_system_prompt():
    """ä»åŒçº§ç›®å½•çš„ prompt.txt è¯»å–ç³»ç»Ÿ Prompt"""
    prompt_path = os.path.join(BASE_DIR, "prompt.txt")
    if os.path.exists(prompt_path):
        with open(prompt_path, "r", encoding="utf-8") as f:
            return f.read().strip()
    print("âš  è­¦å‘Šï¼šæœªæ‰¾åˆ° prompt.txtï¼Œé™çº§ä½¿ç”¨å†…å»ºç²¾ç®€æ¨¡å¼", file=sys.stderr)
    return "ä½ æ˜¯ä¸€ä¸ªçŠ€åˆ©çš„æŠ€æœ¯è¯„è®ºå®¶ï¼Œè¯·å°†è¾“å…¥çš„æ¨æ–‡æç‚¼æˆ250å­—ä»¥å†…çš„å¸¦æœ‰ä¸ªäººè§‚ç‚¹çš„æ¨ç‰¹è´´æ–‡ï¼Œä½¿ç”¨ä¸­æ–‡è¾“å‡ºã€‚"

SYSTEM_PROMPT = get_system_prompt()


def get_llm_client():
    """æ„å»º LLM API è¯·æ±‚é…ç½®"""
    api_key = os.environ.get("LLM_API_KEY")
    if not api_key:
        print("âœ— æœªè®¾ç½® LLM_API_KEY ç¯å¢ƒå˜é‡", file=sys.stderr)
        print("  è¯·è®¾ç½®: $env:LLM_API_KEY = 'your-api-key'", file=sys.stderr)
        return None

    return {
        "api_key": api_key,
        "base_url": os.environ.get("LLM_BASE_URL", "https://api.openai.com/v1"),
        "model": os.environ.get("LLM_MODEL", "gpt-4o-mini"),
    }


def call_llm(config, user_content):
    """è°ƒç”¨ OpenAI å…¼å®¹ API"""
    import requests

    headers = {
        "Authorization": f"Bearer {config['api_key']}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": config["model"],
        "messages": [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_content},
        ],
        "max_tokens": 500,
        "temperature": 0.7,
    }

    try:
        resp = requests.post(
            f"{config['base_url']}/chat/completions",
            headers=headers,
            json=payload,
            timeout=30,
        )
        resp.raise_for_status()
        data = resp.json()
        return data["choices"][0]["message"]["content"].strip()
    except Exception as e:
        print(f"  LLM è°ƒç”¨å¤±è´¥: {e}", file=sys.stderr)
        return None


def build_prompt(tweet):
    """å°†æ¨æ–‡æ•°æ®ç»„è£…ä¸º LLM è¾“å…¥"""
    content = tweet.get("content", {})
    tweet_type = tweet.get("type", "tweet")

    parts = []
    author = content.get("author", "æœªçŸ¥")
    username = content.get("username", "")
    parts.append(f"ä½œè€…: {author} (@{username})")

    if tweet_type == "article":
        title = content.get("title", "")
        full_text = content.get("full_text", "") or content.get("preview", "")
        parts.append(f"æ ‡é¢˜: {title}")
        parts.append(f"æ­£æ–‡:\n{full_text[:2000]}")
    else:
        text = content.get("text", "")
        parts.append(f"å†…å®¹:\n{text}")

    # é™„åŠ äº’åŠ¨æ•°æ®ä½œä¸ºå‚è€ƒ
    likes = content.get("likes", 0)
    retweets = content.get("retweets", 0)
    if likes or retweets:
        parts.append(f"äº’åŠ¨: {likes} èµ / {retweets} è½¬å‘")

    return "\n".join(parts)


def truncate_text(text, max_chars=280):
    """å¼ºåˆ¶æˆªæ–­è‡³æŒ‡å®šå­—ç¬¦æ•°"""
    if len(text) <= max_chars:
        return text
    return text[:max_chars - 1] + "â€¦"


def process():
    """
    æ ¸å¿ƒå¤„ç†é€»è¾‘ï¼š
    1. è¯»å– pending_tweets.json
    2. é€æ¡è°ƒç”¨ LLM ç”Ÿæˆé”è¯„
    3. è¾“å‡ºåˆ° drafts.json
    
    è¿”å›ï¼šæˆåŠŸç”Ÿæˆçš„è‰ç¨¿æ•°é‡
    """
    if not os.path.exists(PENDING_FILE):
        print("âš  æ²¡æœ‰å¾…å¤„ç†æ¨æ–‡ï¼Œè¯·å…ˆè¿è¡Œ watcher.py", file=sys.stderr)
        return 0

    with open(PENDING_FILE, "r", encoding="utf-8") as f:
        pending = json.load(f)

    if not pending:
        print("âš  pending_tweets.json ä¸ºç©º", file=sys.stderr)
        return 0

    config = get_llm_client()
    if not config:
        return 0

    # åŠ è½½å·²æœ‰è‰ç¨¿
    existing_drafts = []
    if os.path.exists(DRAFTS_FILE):
        with open(DRAFTS_FILE, "r", encoding="utf-8") as f:
            try:
                existing_drafts = json.load(f)
            except json.JSONDecodeError:
                existing_drafts = []

    new_drafts = []
    success = 0
    failed = 0

    print(f"ğŸ§  å¼€å§‹æç‚¼ï¼Œå…± {len(pending)} æ¡å¾…å¤„ç†...")

    for i, tweet in enumerate(pending, 1):
        tweet_id = tweet.get("tweet_id", "?")
        content = tweet.get("content", {})
        author = content.get("author", "æœªçŸ¥")

        print(f"  [{i}/{len(pending)}] @{content.get('username', '?')} - ", end="")

        prompt = build_prompt(tweet)
        commentary = call_llm(config, prompt)

        if commentary:
            commentary = truncate_text(commentary)
            draft = {
                "tweet_id": tweet_id,
                "original_url": tweet.get("original_url", ""),
                "original_author": author,
                "original_username": content.get("username", ""),
                "original_text": content.get("text", "") or content.get("title", ""),
                "commentary": commentary,
                "char_count": len(commentary),
                "generated_at": datetime.now().isoformat(),
                "status": "pending_review",  # pending_review / approved / rejected
            }
            new_drafts.append(draft)
            success += 1
            print(f"âœ“ ({len(commentary)} å­—)")
        else:
            failed += 1
            print("âœ—")

    # ä¿å­˜è‰ç¨¿
    all_drafts = existing_drafts + new_drafts
    with open(DRAFTS_FILE, "w", encoding="utf-8") as f:
        json.dump(all_drafts, f, ensure_ascii=False, indent=2)

    # æ¸…ç©ºå·²å¤„ç†çš„ pending
    with open(PENDING_FILE, "w", encoding="utf-8") as f:
        json.dump([], f)

    print(f"\nğŸ“ æç‚¼å®Œæˆ: æˆåŠŸ {success} | å¤±è´¥ {failed}")
    print(f"   è‰ç¨¿é˜Ÿåˆ—: {len(all_drafts)} æ¡ â†’ {DRAFTS_FILE}")

    return success


if __name__ == "__main__":
    process()
