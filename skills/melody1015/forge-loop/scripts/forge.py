#!/usr/bin/env python3
"""Forge ğŸ”¨ â€” ç»´ä¿®-ç›‘ç†è‡ªåŠ¨å¾ªç¯ç¼–æ’å™¨

é€šç”¨çš„repair-inspect loopï¼Œä»»ä½•é¡¹ç›®éƒ½èƒ½ç”¨ã€‚
è„šæœ¬åšç¼–æ’ï¼ˆä¾èµ–åˆ†æã€çŠ¶æ€ç®¡ç†ã€å®‰å…¨æ£€æŸ¥ï¼‰ï¼ŒLLMåšæ‰§è¡Œï¼ˆrepair/inspectï¼‰ã€‚

ç”¨æ³•:
    python3 forge.py init --workdir /path/to/project
    python3 forge.py add "ä»»åŠ¡æè¿°" --criteria "éªŒæ”¶æ ‡å‡†" [--depends task-1]
    python3 forge.py plan                # ä¾èµ–åˆ†æï¼Œè¾“å‡ºæ‰§è¡Œè®¡åˆ’
    python3 forge.py run                 # æ¨è¿›ä¸‹ä¸€æ‰¹ä»»åŠ¡
    python3 forge.py status              # æŸ¥çœ‹è¿›åº¦
    python3 forge.py advance TASK_ID     # æ‰‹åŠ¨æ¨è¿›æŒ‡å®šä»»åŠ¡
    python3 forge.py reset               # æ¸…é™¤çŠ¶æ€

çŠ¶æ€æŒä¹…åŒ–åˆ° forge-state.jsonï¼Œæ”¯æŒæ–­ç‚¹æ¢å¤ã€‚

Author: Forge Contributors
"""

import argparse
import json
import os
import re
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional

# â”€â”€ è·¯å¾„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FORGE_DIR = Path(__file__).resolve().parent.parent
TEMPLATES_DIR = FORGE_DIR / "assets" / "templates"

# â”€â”€ å¸¸é‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MAX_ROUNDS = 5
REPAIR_TIMEOUT = 600
INSPECT_TIMEOUT = 300
DEFAULT_MODEL = "anthropic/claude-opus-4-6"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Experience Accumulation
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extract_universal_pattern(project_pattern: dict) -> Optional[dict]:
    """Extract a universal (project-agnostic) pattern from a project-specific repair pattern.

    Strips file paths, project-specific names, and keeps only the abstract lesson.
    Returns None if the pattern is too project-specific to generalize.
    """
    name = project_pattern.get("pattern_name", "")
    if not name:
        return None

    # Extract generalizable fields
    universal = {
        "pattern_name": name,
        "error_type": project_pattern.get("error_type", ""),
        "solution_template": project_pattern.get("solution_template", ""),
        "prevention": project_pattern.get("prevention", ""),
    }

    # Strip empty fields
    universal = {k: v for k, v in universal.items() if v}
    if "pattern_name" not in universal:
        return None

    # Skip patterns that are purely project-specific (heuristic: if solution_template
    # contains too many specific file paths, it's not universal)
    template = universal.get("solution_template", "")
    path_indicators = [".py", ".sh", ".json", ".yaml", "scripts/", "cache/", "prompts/"]
    path_count = sum(1 for ind in path_indicators if ind in template)
    if path_count >= 3 and len(template) < 200:
        # Too many paths in a short template = project-specific
        return None

    return universal


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# State Management
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def state_path(workdir: Path) -> Path:
    return workdir / "forge-state.json"


def load_state(workdir: Path) -> Optional[dict]:
    sf = state_path(workdir)
    if sf.exists():
        try:
            with open(sf) as f:
                return json.load(f)
        except json.JSONDecodeError:
            print(f"ğŸš¨ çŠ¶æ€æ–‡ä»¶æŸå: {sf}")
            print(f"   ç”¨ 'forge.py reset' æ¸…é™¤åé‡æ–°å¼€å§‹")
            sys.exit(1)
    return None


def save_state(workdir: Path, state: dict):
    state["updated_at"] = datetime.now().isoformat()
    with open(state_path(workdir), 'w') as f:
        json.dump(state, f, ensure_ascii=False, indent=2)


def init_state(workdir: Path, project_name: str = "") -> dict:
    state = {
        "project": project_name or workdir.name,
        "workdir": str(workdir),
        "created_at": datetime.now().isoformat(),
        "updated_at": datetime.now().isoformat(),
        "tasks": {},
        "task_counter": 0,
        "protected_files": load_protected_files(workdir),
        "config": {
            "max_rounds": MAX_ROUNDS,
            "repair_timeout": REPAIR_TIMEOUT,
            "inspect_timeout": INSPECT_TIMEOUT,
            "model": DEFAULT_MODEL,
            "auto_commit": True,
        },
    }
    save_state(workdir, state)
    return state


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Protected Files
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_protected_files(workdir: Path) -> list:
    """Load protected files list if exists in project."""
    pf = workdir / "protected-files.txt"
    if not pf.exists():
        return []
    lines = pf.read_text().strip().split("\n")
    return [l.strip() for l in lines
            if l.strip() and not l.strip().startswith("#")]


def check_protected_files(workdir: Path, changed_files: list, protected: list) -> list:
    """Check if any changed files are protected. Returns list of violations."""
    violations = []
    for cf in changed_files:
        for pf in protected:
            cf_norm = os.path.normpath(cf.strip())
            pf_norm = os.path.normpath(pf.strip())
            if cf_norm == pf_norm or cf_norm.endswith(os.sep + pf_norm):
                violations.append(cf_norm)
    return violations


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Task Management
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def add_task(state: dict, description: str, criteria: str = "",
             depends: list = None, priority: str = "P1",
             source: str = "", files_hint: list = None) -> str:
    """Add a repair task. Returns task_id."""
    state["task_counter"] += 1
    task_id = f"task-{state['task_counter']:03d}"

    state["tasks"][task_id] = {
        "id": task_id,
        "description": description,
        "criteria": criteria or "ä¿®å¤åä»£ç èƒ½æ­£ç¡®è¿è¡Œï¼Œæ— å›å½’é—®é¢˜",
        "priority": priority,
        "source": source,
        "files_hint": files_hint or [],
        "depends_on": depends or [],
        "status": "pending",
        "current_round": 0,
        "rounds": [],
        "created_at": datetime.now().isoformat(),
        "completed_at": None,
        "result": None,
    }
    return task_id


def get_parallel_groups(state: dict) -> list:
    """Topological sort tasks into parallel execution groups."""
    tasks = state["tasks"]
    remaining = {tid for tid, t in tasks.items()
                 if t["status"] in ("pending", "repair_needed")}
    done = {tid for tid, t in tasks.items()
            if t["status"] in ("done", "skipped")}
    groups = []

    while remaining:
        # Find tasks whose deps are all in 'done'
        group = []
        for tid in list(remaining):
            task = tasks[tid]
            deps = set(task.get("depends_on", []))
            if deps.issubset(done):
                group.append(tid)

        if not group:
            # Circular dependency or blocked
            groups.append({"type": "blocked", "tasks": list(remaining)})
            break

        groups.append({"type": "parallel", "tasks": group})
        for tid in group:
            remaining.discard(tid)
            done.add(tid)

    return groups


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Prompt Generation
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_template(name: str) -> str:
    """Load a prompt template."""
    template_file = TEMPLATES_DIR / f"{name}.md"
    if template_file.exists():
        return template_file.read_text()
    # Fallback to inline template
    return ""


def generate_repair_task(task: dict, state: dict, inspector_issues: str = "") -> str:
    """Generate a repair engineer spawn task."""
    workdir = state["workdir"]
    protected = state.get("protected_files", [])
    round_num = task["current_round"]

    protected_text = ""
    if protected:
        protected_text = "\n".join(f"  - {f}" for f in protected)
        protected_text = f"""
## ğŸ”’ å—ä¿æŠ¤æ–‡ä»¶ï¼ˆç¦æ­¢ä¿®æ”¹ï¼‰
ä»¥ä¸‹æ–‡ä»¶åœ¨è‡ªåŠ¨å¾ªç¯ä¸­ç¦æ­¢ä¿®æ”¹ã€‚å¦‚éœ€æ”¹åŠ¨ï¼Œè¾“å‡º BLOCKED å¹¶è¯´æ˜åŸå› ã€‚
{protected_text}
"""

    files_hint = ""
    if task.get("files_hint"):
        files_hint = "\n## ç›¸å…³æ–‡ä»¶æç¤º\n" + "\n".join(f"- {f}" for f in task["files_hint"])

    prev_issues = ""
    if inspector_issues:
        prev_issues = f"""
## ä¸Šè½®ç›‘ç†åé¦ˆï¼ˆç¬¬{round_num}è½®ï¼‰
{inspector_issues}

è¯·é’ˆå¯¹ä¸Šè¿°é—®é¢˜é€ä¸€ä¿®å¤ã€‚
"""

    # Load reflections: universal patterns (cross-project) + project-specific
    reflections_text = ""
    universal_reflections_file = FORGE_DIR / "reflections" / "patterns.jsonl"
    project_reflections_file = Path(workdir) / "forge-reflections.jsonl"

    patterns = []
    # Universal layer first (cross-project lessons)
    if universal_reflections_file.exists():
        try:
            for line in universal_reflections_file.read_text().strip().split("\n")[-5:]:
                if line.strip():
                    patterns.append(("é€šç”¨", json.loads(line)))
        except Exception:
            pass
    # Project layer (project-specific patterns)
    if project_reflections_file.exists():
        try:
            for line in project_reflections_file.read_text().strip().split("\n")[-5:]:
                if line.strip():
                    patterns.append(("é¡¹ç›®", json.loads(line)))
        except Exception:
            pass

    if patterns:
        reflections_text = "\n## å†å²ä¿®å¤ç»éªŒ\n"
        for layer, r in patterns:
            name = r.get('pattern_name', '?')
            template = r.get('solution_template', r.get('description', ''))
            reflections_text += f"- **{name}**: {template}\n"

    return f"""ä½ æ˜¯ç»´ä¿®å·¥ç¨‹å¸ˆï¼ˆRepair Engineerï¼‰ã€‚

## ä¿®å¤ä»»åŠ¡
{task['description']}

## éªŒæ”¶æ ‡å‡†
{task['criteria']}
{prev_issues}{protected_text}{files_hint}{reflections_text}
## å®‰å…¨è§„åˆ™ï¼ˆä¸å¯è¿åï¼‰
- ğŸš« ç¦æ­¢åˆ é™¤ä»»ä½•æ–‡ä»¶ï¼ˆç”¨ # DEPRECATED æ ‡è®°ï¼‰
- ğŸš« ç¦æ­¢ä¿®æ”¹å—ä¿æŠ¤æ–‡ä»¶ï¼ˆè§ä¸Šæ–¹åˆ—è¡¨ï¼‰
- ğŸš« ç¦æ­¢ä¿®æ”¹ cron é…ç½®
- âœ… åªèƒ½ä¿®æ”¹ä»»åŠ¡æè¿°ä¸­æ˜ç¡®æ¶‰åŠçš„æ–‡ä»¶
- âœ… ç”¨ edit å·¥å…·ç²¾ç¡®ä¿®æ”¹ï¼Œä¸è¦é‡å†™æ•´ä¸ªæ–‡ä»¶

## è¾“å‡ºæ ¼å¼
å°†ä¿®å¤æŠ¥å‘Šå†™å…¥æ–‡ä»¶: `{workdir}/forge-output/{task['id']}-repair-r{round_num}.json`

```json
{{
  "role": "repair_engineer",
  "task_id": "{task['id']}",
  "round": {round_num},
  "repairs": [
    {{
      "title": "ä¿®å¤æ ‡é¢˜",
      "status": "FIXED / PARTIAL / BLOCKED / SKIPPED",
      "diagnosis": {{ "root_cause": "æ ¹å› ", "affected_files": ["file.py"] }},
      "changes": [{{ "file": "path", "description": "æ”¹äº†ä»€ä¹ˆ" }}],
      "self_test": {{ "method": "è‡ªæµ‹æ–¹å¼", "result": "é€šè¿‡/å¤±è´¥", "evidence": "æ•°æ®" }},
      "regression_risk": "low / medium / high"
    }}
  ],
  "repair_pattern": {{
    "error_type": "é”™è¯¯åˆ†ç±»",
    "pattern_name": "ç®€çŸ­æ¨¡å¼å",
    "solution_template": "é€šç”¨è§£å†³æ–¹æ¡ˆ",
    "prevention": "é¢„é˜²æªæ–½"
  }},
  "summary": {{
    "fixed_count": 0,
    "blocked_count": 0,
    "total_files_changed": 0
  }}
}}
```

## æ‰§è¡Œæ­¥éª¤
1. è¯»å–ç›¸å…³æ–‡ä»¶ï¼Œè¯Šæ–­æ ¹å› 
2. ç”¨ edit ç²¾ç¡®ä¿®æ”¹
3. è‡ªæµ‹éªŒè¯
4. å°†ä¿®å¤æŠ¥å‘ŠJSONå†™å…¥ä¸Šè¿°æ–‡ä»¶è·¯å¾„
5. å›å¤ "done"

å·¥ä½œç›®å½•: {workdir}
"""


def generate_inspect_task(task: dict, state: dict, repair_report: dict) -> str:
    """Generate an inspector spawn task."""
    workdir = state["workdir"]
    round_num = task["current_round"]

    # Summarize repair report
    repair_summary = json.dumps(repair_report, ensure_ascii=False, indent=2)
    if len(repair_summary) > 3000:
        # Truncate but keep structure
        repairs = repair_report.get("repairs", [])
        repair_summary = "ä¿®å¤æ‘˜è¦:\n"
        for r in repairs:
            repair_summary += f"- {r.get('title', '?')}: {r.get('status', '?')}\n"
            for c in r.get("changes", []):
                repair_summary += f"  æ”¹åŠ¨: {c.get('file', '?')} â€” {c.get('description', '?')}\n"

    return f"""ä½ æ˜¯ç›‘ç†ï¼ˆInspectorï¼‰ï¼Œç‹¬ç«‹éªŒæ”¶ä¿®å¤æ˜¯å¦çœŸæ­£è§£å†³äº†é—®é¢˜ã€‚

## åŸå§‹é—®é¢˜
{task['description']}

## éªŒæ”¶æ ‡å‡†
{task['criteria']}

## ç»´ä¿®å·¥ç¨‹å¸ˆæŠ¥å‘Šï¼ˆç¬¬{round_num}è½®ï¼‰
{repair_summary}

## éªŒæ”¶è¦æ±‚
1. **å¿…é¡»è·‘ä»£ç éªŒè¯** â€” ä¸æ¥å—"çœ‹èµ·æ¥å¯¹äº†"
2. ç”¨ grep/python åšå…¨é‡æ‰«æï¼Œä¸æŠ½æ ·
3. æ£€æŸ¥è¾¹ç¼˜æƒ…å†µå’Œå›å½’é£é™©
4. éªŒè¯ä¿®å¤åä»£ç å®é™…èƒ½è¿è¡Œ

## è¾“å‡ºæ ¼å¼
å°†éªŒæ”¶æŠ¥å‘Šå†™å…¥æ–‡ä»¶: `{workdir}/forge-output/{task['id']}-inspect-r{round_num}.json`

```json
{{
  "role": "inspector",
  "task_id": "{task['id']}",
  "round": {round_num},
  "verdict": "PASS / FAIL / CONDITIONAL / NEEDS_HUMAN",
  "inspections": [
    {{
      "check": "æ£€æŸ¥å†…å®¹",
      "method": "éªŒè¯æ–¹æ³•",
      "result": "é€šè¿‡/å¤±è´¥",
      "evidence": "å®é™…è¾“å‡º"
    }}
  ],
  "issues_found": [
    {{
      "severity": "critical / warning / info",
      "description": "é—®é¢˜æè¿°",
      "suggestion": "å»ºè®®ä¿®å¤æ–¹å¼"
    }}
  ],
  "summary": "ä¸€å¥è¯ç»“è®º"
}}
```

## æ‰§è¡Œæ­¥éª¤
1. è¯»å–ç»´ä¿®å·¥ç¨‹å¸ˆä¿®æ”¹çš„æ–‡ä»¶
2. è¿è¡Œä»£ç éªŒè¯è¾“å‡º
3. æ£€æŸ¥è¾¹ç¼˜æƒ…å†µ
4. å°†éªŒæ”¶æŠ¥å‘ŠJSONå†™å…¥ä¸Šè¿°æ–‡ä»¶è·¯å¾„
5. å›å¤ "done"

å·¥ä½œç›®å½•: {workdir}
"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Execution Flow
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def prepare_repair(state: dict, task_id: str) -> dict:
    """Prepare repair spawn instruction for a task."""
    task = state["tasks"][task_id]
    workdir = Path(state["workdir"])

    # Increment round
    task["current_round"] += 1
    task["status"] = "repairing"
    round_num = task["current_round"]

    # Get previous inspector issues if any
    inspector_issues = ""
    if task["rounds"]:
        last_round = task["rounds"][-1]
        if last_round.get("inspect_issues"):
            inspector_issues = last_round["inspect_issues"]

    # Generate task content
    task_content = generate_repair_task(task, state, inspector_issues)

    # Ensure output dir exists
    output_dir = workdir / "forge-output"
    output_dir.mkdir(parents=True, exist_ok=True)

    # Write task file
    task_file = output_dir / f"{task_id}-repair-r{round_num}.task.md"
    task_file.write_text(task_content)

    # Record round
    task["rounds"].append({
        "round": round_num,
        "repair_started": datetime.now().isoformat(),
        "repair_file": str(output_dir / f"{task_id}-repair-r{round_num}.json"),
        "inspect_file": str(output_dir / f"{task_id}-inspect-r{round_num}.json"),
        "repair_done": False,
        "inspect_done": False,
        "inspect_issues": "",
    })

    return {
        "type": "repair",
        "task_id": task_id,
        "round": round_num,
        "task_file": str(task_file),
        "result_file": str(output_dir / f"{task_id}-repair-r{round_num}.json"),
        "label": f"forge-repair-{task_id}-r{round_num}",
        "model": state["config"]["model"],
        "timeout": state["config"]["repair_timeout"],
    }


def prepare_inspect(state: dict, task_id: str) -> dict:
    """Prepare inspector spawn instruction for a task."""
    task = state["tasks"][task_id]
    workdir = Path(state["workdir"])
    round_num = task["current_round"]

    # Load repair report
    current_round = task["rounds"][-1]
    repair_file = Path(current_round["repair_file"])
    repair_report = {}
    if repair_file.exists():
        try:
            repair_report = json.loads(repair_file.read_text())
        except json.JSONDecodeError:
            repair_report = {"error": "repair report JSON parse failed"}

    task["status"] = "inspecting"

    # Generate task content
    task_content = generate_inspect_task(task, state, repair_report)

    output_dir = workdir / "forge-output"
    task_file = output_dir / f"{task_id}-inspect-r{round_num}.task.md"
    task_file.write_text(task_content)

    return {
        "type": "inspect",
        "task_id": task_id,
        "round": round_num,
        "task_file": str(task_file),
        "result_file": str(output_dir / f"{task_id}-inspect-r{round_num}.json"),
        "label": f"forge-inspect-{task_id}-r{round_num}",
        "model": state["config"]["model"],
        "timeout": state["config"]["inspect_timeout"],
    }


def check_repair_result(state: dict, task_id: str) -> str:
    """Check if repair result is ready. Returns: ready/waiting/blocked."""
    task = state["tasks"][task_id]
    if not task["rounds"]:
        return "waiting"

    current_round = task["rounds"][-1]
    repair_file = Path(current_round["repair_file"])

    if not repair_file.exists():
        return "waiting"

    try:
        report = json.loads(repair_file.read_text())
    except json.JSONDecodeError:
        return "waiting"

    # Check if all repairs are BLOCKED
    repairs = report.get("repairs", [])
    if repairs and all(r.get("status") == "BLOCKED" for r in repairs):
        task["status"] = "needs_human"
        task["result"] = "ALL_BLOCKED"
        current_round["repair_done"] = True
        return "blocked"

    current_round["repair_done"] = True

    # Save repair pattern to reflections (two-layer)
    pattern = report.get("repair_pattern", {})
    if pattern and pattern.get("pattern_name"):
        # Project layer: full detail (file names, paths, project-specific context)
        project_reflections = Path(state["workdir"]) / "forge-reflections.jsonl"
        with open(project_reflections, "a") as f:
            f.write(json.dumps(pattern, ensure_ascii=False) + "\n")

        # Universal layer: extract abstract pattern (no project-specific paths/filenames)
        universal_pattern = extract_universal_pattern(pattern)
        if universal_pattern:
            universal_dir = FORGE_DIR / "reflections"
            universal_dir.mkdir(parents=True, exist_ok=True)
            universal_file = universal_dir / "patterns.jsonl"
            # Dedup: skip if pattern_name already exists
            existing_names = set()
            if universal_file.exists():
                try:
                    for line in universal_file.read_text().strip().split("\n"):
                        if line.strip():
                            existing_names.add(json.loads(line).get("pattern_name", ""))
                except Exception:
                    pass
            if universal_pattern["pattern_name"] not in existing_names:
                with open(universal_file, "a") as f:
                    f.write(json.dumps(universal_pattern, ensure_ascii=False) + "\n")

    return "ready"


def check_inspect_result(state: dict, task_id: str) -> str:
    """Check inspector result. Returns: pass/fail/needs_human/waiting."""
    task = state["tasks"][task_id]
    current_round = task["rounds"][-1]
    inspect_file = Path(current_round["inspect_file"])

    if not inspect_file.exists():
        return "waiting"

    try:
        report = json.loads(inspect_file.read_text())
    except json.JSONDecodeError:
        return "waiting"

    verdict = report.get("verdict", "").upper()
    current_round["inspect_done"] = True

    if verdict == "PASS":
        task["status"] = "done"
        task["completed_at"] = datetime.now().isoformat()
        task["result"] = "PASS"
        return "pass"

    elif verdict in ("FAIL", "CONDITIONAL"):
        # Extract issues for next round
        issues = report.get("issues_found", [])
        issues_text = "\n".join(
            f"- [{i.get('severity', '?')}] {i.get('description', '?')}\n  å»ºè®®: {i.get('suggestion', '')}"
            for i in issues
        )
        if not issues_text:
            issues_text = report.get("summary", "ç›‘ç†åˆ¤å®šæœªé€šè¿‡ï¼Œä½†æœªæä¾›å…·ä½“issues")
        current_round["inspect_issues"] = issues_text

        # Check max rounds
        if task["current_round"] >= state["config"]["max_rounds"]:
            task["status"] = "escalated"
            task["result"] = f"ESCALATED_AFTER_{MAX_ROUNDS}_ROUNDS"
            return "escalated"

        task["status"] = "repair_needed"
        return "fail"

    elif verdict == "NEEDS_HUMAN":
        task["status"] = "needs_human"
        task["result"] = "NEEDS_HUMAN"
        current_round["inspect_issues"] = report.get("summary", "éœ€è¦äººå·¥åˆ¤æ–­")
        return "needs_human"

    return "waiting"


def run_advance(state: dict) -> list:
    """Advance the forge state machine. Returns spawn instructions."""
    workdir = Path(state["workdir"])
    spawn_instructions = []

    for tid, task in state["tasks"].items():
        status = task["status"]

        if status == "pending":
            # Check dependencies
            deps_met = all(
                state["tasks"].get(dep, {}).get("status") in ("done", "skipped")
                for dep in task.get("depends_on", [])
            )
            if deps_met:
                inst = prepare_repair(state, tid)
                spawn_instructions.append(inst)

        elif status == "repair_needed":
            inst = prepare_repair(state, tid)
            spawn_instructions.append(inst)

        elif status == "repairing":
            result = check_repair_result(state, tid)
            if result == "ready":
                inst = prepare_inspect(state, tid)
                spawn_instructions.append(inst)
            elif result == "blocked":
                print(f"  ğŸš§ {tid}: å…¨éƒ¨BLOCKEDï¼Œéœ€è¦äººå·¥ä»‹å…¥")

        elif status == "inspecting":
            result = check_inspect_result(state, tid)
            if result == "pass":
                print(f"  âœ… {tid}: ç›‘ç†é€šè¿‡!")
            elif result == "fail":
                # Auto-loop: prepare next repair round
                inst = prepare_repair(state, tid)
                spawn_instructions.append(inst)
                print(f"  ğŸ”„ {tid}: ç¬¬{task['current_round']}è½®ä¿®å¤ï¼ˆç›‘ç†ä¸é€šè¿‡ï¼‰")
            elif result == "needs_human":
                print(f"  ğŸš¨ {tid}: éœ€è¦äººå·¥åˆ¤æ–­")
            elif result == "escalated":
                print(f"  â¬†ï¸ {tid}: {MAX_ROUNDS}è½®æœªæ”¶æ•›ï¼Œå‡çº§ç»™äºº")

    save_state(workdir, state)

    # Detect stuck tasks (possible circular dependency)
    if not spawn_instructions:
        stuck = [tid for tid, t in state["tasks"].items()
                 if t["status"] in ("pending", "repair_needed")]
        if stuck:
            print(f"\n  âš ï¸ {len(stuck)} ä¸ªä»»åŠ¡æ— æ³•æ¨è¿›ï¼ˆå¯èƒ½å­˜åœ¨å¾ªç¯ä¾èµ–ï¼‰")
            print(f"     è¿è¡Œ 'forge.py plan' æŸ¥çœ‹ä¾èµ–å…³ç³»")

    return spawn_instructions


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Safety Checks (pre-commit)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def pre_commit_check(state: dict) -> dict:
    """Run pre-commit safety checks. Returns {safe: bool, violations: [], warnings: []}."""
    workdir = Path(state["workdir"])
    result = {"safe": True, "violations": [], "warnings": []}

    try:
        # Get staged changes
        diff_result = subprocess.run(
            ["git", "diff", "--cached", "--name-only"],
            capture_output=True, text=True, cwd=str(workdir)
        )
        changed = [f.strip() for f in diff_result.stdout.strip().split("\n") if f.strip()]

        if not changed:
            # Check unstaged too
            diff_result = subprocess.run(
                ["git", "diff", "--name-only"],
                capture_output=True, text=True, cwd=str(workdir)
            )
            changed = [f.strip() for f in diff_result.stdout.strip().split("\n") if f.strip()]

        # Check protected files
        protected = state.get("protected_files", [])
        violations = check_protected_files(workdir, changed, protected)
        if violations:
            result["safe"] = False
            result["violations"] = [f"å—ä¿æŠ¤æ–‡ä»¶è¢«ä¿®æ”¹: {v}" for v in violations]

        # Check deletions
        del_result = subprocess.run(
            ["git", "diff", "--diff-filter=D", "--name-only"],
            capture_output=True, text=True, cwd=str(workdir)
        )
        deleted = [f.strip() for f in del_result.stdout.strip().split("\n") if f.strip()]
        if deleted:
            result["safe"] = False
            result["violations"].append(f"æ–‡ä»¶è¢«åˆ é™¤: {', '.join(deleted)}")

        # Check change size
        stat_result = subprocess.run(
            ["git", "diff", "--stat"],
            capture_output=True, text=True, cwd=str(workdir)
        )
        # Parse "X files changed, Y insertions, Z deletions"
        stat_line = stat_result.stdout.strip().split("\n")[-1] if stat_result.stdout.strip() else ""
        numbers = re.findall(r"(\d+)", stat_line)
        if numbers and len(numbers) >= 2:
            insertions = int(numbers[1]) if len(numbers) > 1 else 0
            if insertions > 500:
                result["warnings"].append(f"æ”¹åŠ¨è¾ƒå¤§: {insertions} è¡Œæ’å…¥")

    except Exception as e:
        result["warnings"].append(f"å®‰å…¨æ£€æŸ¥å¼‚å¸¸: {e}")

    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Display
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def show_status(state: dict):
    """Display current forge status."""
    if not state:
        print("âŒ æ²¡æœ‰è¿›è¡Œä¸­çš„forgeä¼šè¯ã€‚ç”¨ 'forge.py init' å¼€å§‹ã€‚")
        return

    tasks = state.get("tasks", {})
    total = len(tasks)
    done = sum(1 for t in tasks.values() if t["status"] == "done")
    active = sum(1 for t in tasks.values()
                 if t["status"] in ("repairing", "inspecting"))
    blocked = sum(1 for t in tasks.values()
                  if t["status"] in ("needs_human", "escalated"))
    pending = sum(1 for t in tasks.values()
                  if t["status"] in ("pending", "repair_needed"))

    print(f"\n{'='*60}")
    print(f"ğŸ”¨ Forge â€” {state['project']}")
    print(f"   å·¥ä½œç›®å½•: {state['workdir']}")
    print(f"   ä¿æŠ¤æ–‡ä»¶: {len(state.get('protected_files', []))} ä¸ª")
    print(f"   ä»»åŠ¡: {done}/{total} å®Œæˆ  |  {active} è¿›è¡Œä¸­  |  {blocked} é˜»å¡  |  {pending} å¾…å¤„ç†")
    print(f"{'='*60}")

    for tid, task in sorted(tasks.items()):
        status = task["status"]
        icon = {
            "pending": "â¬œ",
            "repair_needed": "ğŸ”„",
            "repairing": "ğŸ”§",
            "inspecting": "ğŸ”",
            "done": "ğŸŸ©",
            "needs_human": "ğŸš¨",
            "escalated": "â¬†ï¸",
            "skipped": "â­ï¸",
        }.get(status, "â“")

        rounds = f" R{task['current_round']}" if task["current_round"] > 0 else ""
        priority = f" [{task['priority']}]" if task.get('priority') else ""
        deps = ""
        if task.get("depends_on"):
            deps = f" â† {','.join(task['depends_on'])}"

        desc = task["description"][:60]
        if len(task["description"]) > 60:
            desc += "..."

        print(f"  {icon} {tid}{priority}{rounds}: {desc}{deps}")

    # Show execution plan
    groups = get_parallel_groups(state)
    if groups and any(g["type"] == "parallel" for g in groups):
        print(f"\n  ğŸ“‹ æ‰§è¡Œè®¡åˆ’:")
        for i, group in enumerate(groups, 1):
            task_ids = ", ".join(group["tasks"])
            if group["type"] == "blocked":
                print(f"    ğŸš§ é˜»å¡: {task_ids}")
            else:
                print(f"    Wave {i}: {task_ids} (å¹¶è¡Œ)")


def format_spawn_instructions(instructions: list):
    """Format spawn instructions for LLM to execute."""
    if not instructions:
        print("\n  â„¹ï¸ æ²¡æœ‰éœ€è¦spawnçš„ä»»åŠ¡")
        return

    print(f"\n{'='*60}")
    print(f"ğŸš€ SPAWNæŒ‡ä»¤ â€” {len(instructions)} ä¸ªä»»åŠ¡:")
    print(f"{'='*60}")

    for i, inst in enumerate(instructions, 1):
        type_icon = "ğŸ”§" if inst["type"] == "repair" else "ğŸ”"
        print(f"\n  [{i}/{len(instructions)}] {type_icon} {inst['label']}")
        print(f"    ä»»åŠ¡æ–‡ä»¶: {inst['task_file']}")
        print(f"    ç»“æœæ–‡ä»¶: {inst['result_file']}")
        print(f"    æ¨¡å‹: {inst['model']}")
        print(f"    è¶…æ—¶: {inst['timeout']}s")

    print(f"\nğŸ’¡ æ‰§è¡Œæ–¹æ³•:")
    print(f"   1. è¯»å–ä»»åŠ¡æ–‡ä»¶å†…å®¹")
    print(f"   2. sessions_spawn(task=å†…å®¹, label=label, model=model)")
    print(f"   3. ç­‰å¾…å®Œæˆï¼ˆsubagentå†™å…¥result_fileï¼‰")
    print(f"   4. å†æ¬¡è¿è¡Œ: python3 forge.py run")


def check_doc_sync(state: dict) -> list:
    """Check if any modified code files have related docs that need updating.

    Looks for doc-sync-manifest.yaml in the project root. If it exists,
    cross-references modified files against the manifest to find docs
    that may be out of date. Also runs doc-sync-checker.py if available.

    Returns list of warning strings (empty = all good).
    """
    workdir = Path(state["workdir"])
    warnings = []

    # Method 1: Run doc-sync-checker.py if it exists
    checker = workdir / "scripts" / "tools" / "doc-sync-checker.py"
    if checker.exists():
        try:
            result = subprocess.run(
                [sys.executable, str(checker), "--json"],
                capture_output=True, text=True, cwd=str(workdir), timeout=30
            )
            if result.returncode == 0 and result.stdout.strip():
                try:
                    report = json.loads(result.stdout.strip())
                    stale = report.get("stale", [])
                    for item in stale:
                        doc = item.get("doc", "?")
                        authority = item.get("authority", "?")
                        warnings.append(f"{doc} å¯èƒ½è½åäº {authority}")
                except json.JSONDecodeError:
                    pass
        except (subprocess.TimeoutExpired, Exception):
            pass

    # Method 2: Check manifest directly
    manifest_path = workdir / "references" / "doc-sync-manifest.yaml"
    if manifest_path.exists() and not warnings:
        try:
            import yaml  # noqa: E402
            manifest = yaml.safe_load(manifest_path.read_text(encoding="utf-8"))
            facts = manifest.get("facts", {})

            # Get list of files modified in this forge session
            modified_files = set()
            for tid, task in state.get("tasks", {}).items():
                for rnd in task.get("rounds", []):
                    repair_file = rnd.get("repair_file", "")
                    if repair_file and Path(repair_file).exists():
                        try:
                            repair_data = json.loads(Path(repair_file).read_text())
                            for r in repair_data.get("repairs", []):
                                for c in r.get("changes", []):
                                    f = c.get("file", "")
                                    if f:
                                        modified_files.add(f)
                        except (json.JSONDecodeError, KeyError):
                            pass

            # Cross-reference: if any authority file was modified, flag its consumers
            for fact_name, fact_info in facts.items():
                authority = fact_info.get("authority", "")
                consumers = fact_info.get("consumers", [])
                if authority and any(authority in mf or mf in authority for mf in modified_files):
                    for consumer in consumers:
                        warnings.append(f"{consumer} å¯èƒ½éœ€è¦åŒæ­¥æ›´æ–°ï¼ˆ{fact_name} çš„æƒå¨æº {authority} å·²ä¿®æ”¹ï¼‰")
        except ImportError:
            pass  # No yaml module, skip manifest check
        except Exception:
            pass

    return warnings


def generate_summary(state: dict) -> str:
    """Generate completion summary."""
    tasks = state.get("tasks", {})
    lines = [f"ğŸ”¨ Forge å®ŒæˆæŠ¥å‘Š â€” {state['project']}\n"]

    for tid, task in sorted(tasks.items()):
        status_icon = {"done": "âœ…", "needs_human": "ğŸš¨", "escalated": "â¬†ï¸",
                       "skipped": "â­ï¸"}.get(task["status"], "â“")
        rounds = task["current_round"]
        lines.append(f"  {status_icon} {tid}: {task['description'][:50]} (R{rounds})")

    done_count = sum(1 for t in tasks.values() if t["status"] == "done")
    total = len(tasks)
    lines.append(f"\n  ğŸ“Š {done_count}/{total} ä»»åŠ¡å®Œæˆ")

    # Doc-sync check
    doc_warnings = check_doc_sync(state)
    if doc_warnings:
        lines.append(f"\n  ğŸ“„ æ–‡æ¡£åŒæ­¥æ£€æŸ¥ â€” {len(doc_warnings)} ä¸ªæ–‡æ¡£å¯èƒ½éœ€è¦æ›´æ–°:")
        for w in doc_warnings:
            lines.append(f"    âš ï¸ {w}")
        lines.append(f"\n  ğŸ’¡ è¿è¡Œ doc-sync-checker.py æŸ¥çœ‹è¯¦æƒ…ï¼Œæˆ–æ‰‹åŠ¨æ£€æŸ¥ä¸Šè¿°æ–‡æ¡£ã€‚")
    else:
        lines.append(f"\n  ğŸ“„ æ–‡æ¡£åŒæ­¥æ£€æŸ¥ â€” âœ… æ— éœ€æ›´æ–°ï¼ˆæˆ–æœªé…ç½® doc-sync-manifest.yamlï¼‰")

    return "\n".join(lines)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    parser = argparse.ArgumentParser(
        description="ğŸ”¨ Forge â€” ç»´ä¿®-ç›‘ç†è‡ªåŠ¨å¾ªç¯ç¼–æ’å™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  forge.py init --workdir /path/to/project
  forge.py add "Fix null handling in data processor" --criteria "No crash on empty input"
  forge.py add "æ¸…ç†åºŸå¼ƒcollector" --depends task-001
  forge.py plan
  forge.py run
  forge.py status
  forge.py reset
        """)

    sub = parser.add_subparsers(dest="command")

    # init
    p_init = sub.add_parser("init", help="åˆå§‹åŒ–forgeä¼šè¯")
    p_init.add_argument("--workdir", type=str, default=".", help="é¡¹ç›®å·¥ä½œç›®å½•")
    p_init.add_argument("--project", type=str, default="", help="é¡¹ç›®åç§°")
    p_init.add_argument("--model", type=str, default=DEFAULT_MODEL, help="LLMæ¨¡å‹")
    p_init.add_argument("--max-rounds", type=int, default=MAX_ROUNDS, help="æœ€å¤§å¾ªç¯è½®æ•°")

    # add
    p_add = sub.add_parser("add", help="æ·»åŠ ä¿®å¤ä»»åŠ¡")
    p_add.add_argument("description", type=str, help="ä»»åŠ¡æè¿°")
    p_add.add_argument("--criteria", type=str, default="", help="éªŒæ”¶æ ‡å‡†")
    p_add.add_argument("--depends", type=str, nargs="*", default=[], help="ä¾èµ–ä»»åŠ¡ID")
    p_add.add_argument("--priority", type=str, default="P1",
                        choices=["P0", "P1", "P2"], help="ä¼˜å…ˆçº§")
    p_add.add_argument("--source", type=str, default="", help="æ¥æº(å¦‚ GM-R4-003)")
    p_add.add_argument("--files", type=str, nargs="*", default=[], help="ç›¸å…³æ–‡ä»¶æç¤º")

    # plan
    sub.add_parser("plan", help="æ˜¾ç¤ºæ‰§è¡Œè®¡åˆ’ï¼ˆä¾èµ–åˆ†æï¼‰")

    # run
    sub.add_parser("run", help="æ¨è¿›ä»»åŠ¡ï¼ˆå‡†å¤‡spawnæˆ–æ£€æŸ¥ç»“æœï¼‰")

    # status
    sub.add_parser("status", help="æ˜¾ç¤ºå½“å‰è¿›åº¦")

    # advance
    p_advance = sub.add_parser("advance", help="æ¨è¿›æŒ‡å®šä»»åŠ¡")
    p_advance.add_argument("task_id", type=str, help="ä»»åŠ¡ID")

    # reset
    sub.add_parser("reset", help="æ¸…é™¤å½“å‰forgeçŠ¶æ€")

    # check
    sub.add_parser("check", help="è¿è¡Œcommitå‰å®‰å…¨æ£€æŸ¥")

    # summary
    sub.add_parser("summary", help="ç”Ÿæˆå®ŒæˆæŠ¥å‘Š")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    if args.command == "init":
        workdir = Path(args.workdir).resolve()
        if not workdir.exists():
            print(f"âŒ å·¥ä½œç›®å½•ä¸å­˜åœ¨: {workdir}")
            sys.exit(1)
        existing = load_state(workdir)
        if existing and any(t["status"] not in ("done", "skipped", "needs_human", "escalated")
                           for t in existing.get("tasks", {}).values()):
            print(f"âš ï¸ å½“å‰æœ‰è¿›è¡Œä¸­çš„forgeä»»åŠ¡")
            print(f"   ç”¨ 'forge.py reset' å…ˆæ¸…é™¤")
            sys.exit(1)
        state = init_state(workdir, args.project)
        state["config"]["model"] = args.model
        state["config"]["max_rounds"] = args.max_rounds
        save_state(workdir, state)
        print(f"âœ… Forgeå·²åˆå§‹åŒ–: {state['project']}")
        print(f"   å·¥ä½œç›®å½•: {workdir}")
        print(f"   ä¿æŠ¤æ–‡ä»¶: {len(state['protected_files'])} ä¸ª")
        print(f"\nä¸‹ä¸€æ­¥: forge.py add \"ä»»åŠ¡æè¿°\" --criteria \"éªŒæ”¶æ ‡å‡†\"")
        return

    if args.command == "reset":
        # Find workdir from existing state or cwd
        workdir = Path(".").resolve()
        sf = state_path(workdir)
        if sf.exists():
            sf.unlink()
            print("âœ… ForgeçŠ¶æ€å·²æ¸…é™¤")
        else:
            print("â„¹ï¸ æ²¡æœ‰è¿›è¡Œä¸­çš„forgeä¼šè¯")
        return

    # All other commands need state
    workdir = Path(".").resolve()
    state = load_state(workdir)

    if not state and args.command != "init":
        print("âŒ æ²¡æœ‰forgeä¼šè¯ã€‚å…ˆè¿è¡Œ: forge.py init")
        sys.exit(1)

    if args.command == "add":
        tid = add_task(state, args.description, args.criteria,
                       args.depends, args.priority, args.source, args.files)
        save_state(workdir, state)
        print(f"âœ… ä»»åŠ¡å·²æ·»åŠ : {tid}")
        print(f"   æè¿°: {args.description[:60]}")
        if args.depends:
            print(f"   ä¾èµ–: {', '.join(args.depends)}")
        show_status(state)
        return

    if args.command == "plan":
        groups = get_parallel_groups(state)
        print(f"\nğŸ“‹ æ‰§è¡Œè®¡åˆ’ ({len(state['tasks'])} ä¸ªä»»åŠ¡)")
        print(f"{'='*60}")
        for i, group in enumerate(groups, 1):
            if group["type"] == "blocked":
                tasks = ", ".join(group["tasks"])
                print(f"  ğŸš§ é˜»å¡ (å¾ªç¯ä¾èµ–): {tasks}")
            else:
                print(f"\n  Wave {i} (å¹¶è¡Œ):")
                for tid in group["tasks"]:
                    task = state["tasks"][tid]
                    print(f"    {tid} [{task['priority']}]: {task['description'][:50]}")
        return

    if args.command == "run":
        instructions = run_advance(state)
        save_state(workdir, state)
        show_status(state)
        if instructions:
            format_spawn_instructions(instructions)
        else:
            all_done = all(t["status"] in ("done", "skipped", "needs_human", "escalated")
                          for t in state["tasks"].values())
            if all_done:
                print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å·²å¤„ç†å®Œæ¯•!")
                print(generate_summary(state))
        return

    if args.command == "status":
        show_status(state)
        return

    if args.command == "advance":
        task = state["tasks"].get(args.task_id)
        if not task:
            print(f"âŒ ä»»åŠ¡ä¸å­˜åœ¨: {args.task_id}")
            sys.exit(1)
        # Only advance the specified task (not all tasks)
        instructions = []
        tid = args.task_id
        status = task["status"]
        if status in ("pending", "repair_needed"):
            deps_met = all(
                state["tasks"].get(dep, {}).get("status") in ("done", "skipped")
                for dep in task.get("depends_on", [])
            )
            if deps_met:
                inst = prepare_repair(state, tid)
                instructions.append(inst)
            else:
                print(f"  â³ {tid}: ä¾èµ–æœªæ»¡è¶³")
        elif status == "repairing":
            result = check_repair_result(state, tid)
            if result == "ready":
                inst = prepare_inspect(state, tid)
                instructions.append(inst)
            elif result == "blocked":
                print(f"  ğŸš§ {tid}: å…¨éƒ¨BLOCKEDï¼Œéœ€è¦äººå·¥ä»‹å…¥")
            else:
                print(f"  â³ {tid}: ç­‰å¾…ç»´ä¿®ç»“æœ")
        elif status == "inspecting":
            result = check_inspect_result(state, tid)
            if result == "pass":
                print(f"  âœ… {tid}: ç›‘ç†é€šè¿‡!")
            elif result == "fail":
                inst = prepare_repair(state, tid)
                instructions.append(inst)
                print(f"  ğŸ”„ {tid}: ç¬¬{task['current_round']}è½®ä¿®å¤")
            elif result == "needs_human":
                print(f"  ğŸš¨ {tid}: éœ€è¦äººå·¥åˆ¤æ–­")
            elif result == "escalated":
                print(f"  â¬†ï¸ {tid}: è¶…è½®æ•°ï¼Œå‡çº§")
            else:
                print(f"  â³ {tid}: ç­‰å¾…ç›‘ç†ç»“æœ")
        else:
            print(f"  {tid}: {status}")
        save_state(workdir, state)
        if instructions:
            format_spawn_instructions(instructions)
        return

    if args.command == "check":
        result = pre_commit_check(state)
        if result["safe"]:
            print("âœ… å®‰å…¨æ£€æŸ¥é€šè¿‡")
        else:
            print("ğŸš¨ å®‰å…¨æ£€æŸ¥å¤±è´¥:")
            for v in result["violations"]:
                print(f"  âŒ {v}")
        for w in result.get("warnings", []):
            print(f"  âš ï¸ {w}")
        return

    if args.command == "summary":
        print(generate_summary(state))
        return


if __name__ == "__main__":
    main()
