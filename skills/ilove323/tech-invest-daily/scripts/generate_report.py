#!/usr/bin/env python3
"""ç§‘æŠ€æŠ•èµ„æ—¥æŠ¥ç”Ÿæˆè„šæœ¬"""
import subprocess, re, sys
from datetime import datetime

def fetch_url(url):
    result = subprocess.run(
        ['curl', '-s', '-L', '--max-time', '10', url],
        capture_output=True
    )
    return result.stdout.decode('utf-8', errors='ignore')

def fetch_cls_news():
    """æŠ“è´¢è”ç¤¾ç”µæŠ¥"""
    content = fetch_url('https://www.cls.cn/telegraph')
    # æå–æ–°é—»æ¡ç›®ï¼ˆæ—¶é—´+å†…å®¹æ ¼å¼ï¼‰
    items = re.findall(r'(\d{2}:\d{2}:\d{2})ã€([^ã€‘]+)ã€‘([^\n]+)', content)
    return items[:20]  # å–æœ€æ–°20æ¡

def extract_companies(news_items):
    """ä»æ–°é—»ä¸­æå–å…¬å¸åå’Œè‚¡ç¥¨ä»£ç æ˜ å°„"""
    # å¸¸è§ç§‘æŠ€å…¬å¸æ˜ å°„è¡¨
    company_map = {
        'è‹±ä¼Ÿè¾¾': 'usNVDA', 'NVIDIA': 'usNVDA',
        'è‹¹æœ': 'usAAPL', 'Apple': 'usAAPL',
        'å¾®è½¯': 'usMSFT', 'Microsoft': 'usMSFT',
        'è°·æ­Œ': 'usGOOGL', 'Google': 'usGOOGL',
        'ç‰¹æ–¯æ‹‰': 'usTSLA', 'Tesla': 'usTSLA',
        'é˜¿é‡Œå·´å·´': 'usBABA', 'é˜¿é‡Œ': 'usBABA',
        'è…¾è®¯': 'hk00700',
        'ç™¾åº¦': 'usBIDU',
        'ä¸­èŠ¯å›½é™…': 'hk00981',
        'ä¸­ç§‘æ›™å…‰': 'sh603019',
        'æµ·å…‰ä¿¡æ¯': 'sh688041',
        'ç§‘å¤§è®¯é£': 'sz002230',
        'æ½æŸ´åŠ¨åŠ›': 'sz000338',
        'æ‹“é‚¦è‚¡ä»½': 'sz002139',
        'ä¹å®‰åŒ»ç–—': 'sz002432',
        'ç»¿çš„è°æ³¢': 'sh688017',
        'æ°´æ™¶å…‰ç”µ': 'sz002273',
        'æ­Œå°”è‚¡ä»½': 'sz002241',
        'æ¯”äºšè¿ª': 'sz002594',
        'å°ç±³': 'hk01810',
        'åä¸º': None,  # éä¸Šå¸‚
        'OpenAI': None,  # éä¸Šå¸‚
        'æœˆä¹‹æš—é¢': None,  # éä¸Šå¸‚
    }
    found = {}
    all_text = ' '.join([t + c for _, t, c in news_items])
    for name, code in company_map.items():
        if name in all_text and code:
            found[name] = code
    return found

def get_stock_prices(codes):
    """æ‰¹é‡è·å–è‚¡ä»·"""
    if not codes:
        return {}
    query = ','.join(codes)
    raw = subprocess.run(
        ['curl', '-s', f'http://qt.gtimg.cn/q={query}'],
        capture_output=True
    ).stdout.decode('gbk', errors='ignore')
    
    result = {}
    for line in raw.split('\n'):
        m = re.search(r'v_(\w+)="([^"]+)"', line)
        if m:
            code = m.group(1)
            f = m.group(2).split('~')
            if len(f) > 34:
                result[code] = {
                    'name': f[1], 'price': f[3], 'prev': f[4],
                    'change': f[31], 'pct': f[32],
                    'high': f[33], 'low': f[34]
                }
    return result

def generate_report(news_items, companies, prices):
    """ç”ŸæˆæŠ¥å‘Šæ–‡æœ¬"""
    date = datetime.now().strftime('%Y-%m-%d')
    lines = [f'# ğŸ“Š ç§‘æŠ€æŠ•èµ„æ—¥æŠ¥ Â· {date}\n']
    
    # ç§‘æŠ€ç›¸å…³æ–°é—»
    tech_keywords = ['AI', 'èŠ¯ç‰‡', 'åŠå¯¼ä½“', 'ç§‘æŠ€', 'æ™ºèƒ½', 'æœºå™¨äºº', 'ç®—åŠ›', 'å¤§æ¨¡å‹', 'èèµ„', 'æŠ•èµ„']
    tech_news = [(t, title, content) for t, title, content in news_items 
                 if any(k in title or k in content for k in tech_keywords)]
    
    if tech_news:
        lines.append('## ä»Šæ—¥ç§‘æŠ€çƒ­ç‚¹\n')
        for time, title, content in tech_news[:8]:
            lines.append(f'**{time} ã€{title}ã€‘**\n{content}\n')
    
    # è‚¡ä»·æ•°æ®
    if prices:
        lines.append('\n## æ¶‰åŠä¸Šå¸‚å…¬å¸è‚¡ä»·\n')
        lines.append('| å…¬å¸ | ç°ä»· | æ¶¨è·Œ | æ¶¨è·Œå¹… | æœ€é«˜ | æœ€ä½ |')
        lines.append('|------|------|------|--------|------|------|')
        for code, info in prices.items():
            pct = info["pct"]
            emoji = 'ğŸ”´' if float(pct) < 0 else 'ğŸŸ¢'
            lines.append(f'| {info["name"]} | {info["price"]} | {info["change"]} | {emoji}{pct}% | {info["high"]} | {info["low"]} |')
    
    return '\n'.join(lines)

if __name__ == '__main__':
    print('æŠ“å–è´¢è”ç¤¾æ–°é—»...', file=sys.stderr)
    news = fetch_cls_news()
    
    print('æå–ä¸Šå¸‚å…¬å¸...', file=sys.stderr)
    companies = extract_companies(news)
    
    print(f'è·å–è‚¡ä»·: {list(companies.values())}', file=sys.stderr)
    prices = get_stock_prices(list(companies.values())) if companies else {}
    
    report = generate_report(news, companies, prices)
    print(report)
