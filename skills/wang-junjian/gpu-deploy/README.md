# 🚀 gpu-deploy Skill

在 GPU 服务器上一键部署 vLLM 模型服务。

## ✨ 特点

- 🖥️ **多服务器支持** - 配置多个 GPU 服务器
- 🔍 **自动检查** - 一键检查 GPU 和端口
- 🤖 **预置模型** - 支持流行的开源模型
- ⚡ **快速部署** - 简单命令启动服务

## 🚀 快速开始

### 1. 安装

将 `gpu-deploy` 脚本放到你的 PATH 中：

```bash
# 复制到 ~/.local/bin
cp gpu-deploy ~/.local/bin/
chmod +x ~/.local/bin/gpu-deploy
```

### 2. 检查服务器

```bash
gpu-deploy check
```

### 3. 部署模型

```bash
gpu-deploy deploy deepseek-r1-32b
```

## 📖 详细文档

查看 [SKILL.md](./SKILL.md) 了解完整用法。

## 🤝 贡献

欢迎提交 Issue 和 PR！

## 📄 许可证

MIT License

---

**来自 OpenClaw 社区 🦞**
