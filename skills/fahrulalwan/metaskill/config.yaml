# Metaskill LLM Provider Configuration
# Edit this file to match your setup. No code changes needed.

providers:
  # "fast" provider: quick extraction tasks (haiku-level speed/cost)
  fast: anthropic
  # "deep" provider: transfer learning & semantic eval (sonnet-level)
  deep: anthropic

# Model per provider Ã— tier
models:
  anthropic:
    fast: claude-haiku-4-5
    deep: claude-sonnet-4-6
  openai:
    fast: gpt-4o-mini
    deep: gpt-4o
  ollama:
    fast: llama3.2
    deep: llama3.1:70b
  gemini:
    fast: gemini-2.5-flash-lite
    deep: gemini-2.5-flash

# Env var name for each provider's API key ("" = no key needed)
env_vars:
  anthropic: ANTHROPIC_API_KEY
  openai: OPENAI_API_KEY
  ollama: ""
  gemini: GOOGLE_API_KEY
