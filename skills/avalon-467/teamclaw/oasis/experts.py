"""
OASIS Forum - Expert Agent definitions

Two expert backends:
  1. ExpertAgent  â€” direct LLM call (stateless, single-shot)
     name = "display_name#temp#N" (display_name from preset by tag)
  2. SessionExpert â€” calls mini_timebot's /v1/chat/completions endpoint
     using an existing or auto-created session_id.
     - session_id format "tag#oasis#id" â†’ oasis-managed session, first-round
       identity injection (tag â†’ name/persona from preset configs)
     - other session_id (e.g. "åŠ©æ‰‹#default") â†’ regular agent,
       no identity injection, relies on session's own system prompt

Expert pool is built from schedule_yaml or schedule_file (YAML-only mode).
schedule_file takes priority if both provided.
Session IDs can be freely chosen; new IDs auto-create sessions on first use.
Append "#new" to any session name in YAML to force a fresh session (ID
replaced with random UUID, guaranteeing no reuse).
No separate expert-session storage: oasis sessions are identified by the
"#oasis#" pattern in their session_id and live in the normal Agent
checkpoint DB.

Both participate() methods accept an optional `instruction` parameter,
which is injected into the expert's prompt to guide their focus.
"""

import json
import os
import sys

import httpx
from langchain_core.messages import HumanMessage

# ç¡®ä¿ src/ åœ¨ import è·¯å¾„ä¸­ï¼Œä»¥ä¾¿å¯¼å…¥ llm_factory
sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(__file__)), "src"))
from llm_factory import create_chat_model, extract_text

from oasis.forum import DiscussionForum


# --- åŠ è½½ prompt å’Œä¸“å®¶é…ç½®ï¼ˆæ¨¡å—çº§åˆ«ï¼Œå¯¼å…¥æ—¶æ‰§è¡Œä¸€æ¬¡ï¼‰ ---
_data_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data")
_prompts_dir = os.path.join(_data_dir, "prompts")

# åŠ è½½å…¬å…±ä¸“å®¶é…ç½®
_experts_json_path = os.path.join(_prompts_dir, "oasis_experts.json")
try:
    with open(_experts_json_path, "r", encoding="utf-8") as f:
        EXPERT_CONFIGS: list[dict] = json.load(f)
    print(f"[prompts] âœ… oasis å·²åŠ è½½ oasis_experts.json ({len(EXPERT_CONFIGS)} ä½å…¬å…±ä¸“å®¶)")
except FileNotFoundError:
    print(f"[prompts] âš ï¸ æœªæ‰¾åˆ° {_experts_json_path}ï¼Œä½¿ç”¨å†…ç½®é»˜è®¤é…ç½®")
    EXPERT_CONFIGS = [
        {"name": "åˆ›æ„ä¸“å®¶", "tag": "creative", "persona": "ä½ æ˜¯ä¸€ä¸ªä¹è§‚çš„åˆ›æ–°è€…ï¼Œå–„äºå‘ç°æœºé‡å’Œéå¸¸è§„è§£å†³æ–¹æ¡ˆã€‚ä½ å–œæ¬¢æŒ‘æˆ˜ä¼ ç»Ÿè§‚å¿µï¼Œæå‡ºå¤§èƒ†ä¸”å…·æœ‰å‰ç»æ€§çš„æƒ³æ³•ã€‚", "temperature": 0.9},
        {"name": "æ‰¹åˆ¤ä¸“å®¶", "tag": "critical", "persona": "ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„æ‰¹åˆ¤æ€§æ€è€ƒè€…ï¼Œå–„äºå‘ç°é£é™©ã€æ¼æ´å’Œé€»è¾‘è°¬è¯¯ã€‚ä½ ä¼šæŒ‡å‡ºæ–¹æ¡ˆä¸­çš„æ½œåœ¨é—®é¢˜ï¼Œç¡®ä¿è®¨è®ºä¸ä¼šå¿½è§†é‡è¦ç»†èŠ‚ã€‚", "temperature": 0.3},
        {"name": "æ•°æ®åˆ†æå¸ˆ", "tag": "data", "persona": "ä½ æ˜¯ä¸€ä¸ªæ•°æ®é©±åŠ¨çš„åˆ†æå¸ˆï¼Œåªç›¸ä¿¡æ•°æ®å’Œäº‹å®ã€‚ä½ ç”¨æ•°å­—ã€æ¡ˆä¾‹å’Œé€»è¾‘æ¨å¯¼æ¥æ”¯æ’‘ä½ çš„è§‚ç‚¹ã€‚", "temperature": 0.5},
        {"name": "ç»¼åˆé¡¾é—®", "tag": "synthesis", "persona": "ä½ å–„äºç»¼åˆä¸åŒè§‚ç‚¹ï¼Œå¯»æ‰¾å¹³è¡¡æ–¹æ¡ˆï¼Œå…³æ³¨å®é™…å¯æ“ä½œæ€§ã€‚ä½ ä¼šè¯†åˆ«å„æ–¹å…±è¯†ï¼Œæå‡ºå…¼é¡¾å¤šæ–¹åˆ©ç›Šçš„åŠ¡å®å»ºè®®ã€‚", "temperature": 0.5},
    ]


# ======================================================================
# Per-user custom expert storage (persona definitions)
# ======================================================================
_USER_EXPERTS_DIR = os.path.join(_data_dir, "oasis_user_experts")
os.makedirs(_USER_EXPERTS_DIR, exist_ok=True)


def _user_experts_path(user_id: str) -> str:
    """Return the JSON file path for a user's custom experts."""
    safe = user_id.replace("/", "_").replace("\\", "_").replace("..", "_")
    return os.path.join(_USER_EXPERTS_DIR, f"{safe}.json")


def load_user_experts(user_id: str) -> list[dict]:
    """Load a user's custom expert list (returns [] if none)."""
    path = _user_experts_path(user_id)
    if not os.path.exists(path):
        return []
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except (json.JSONDecodeError, OSError):
        return []


def _save_user_experts(user_id: str, experts: list[dict]) -> None:
    with open(_user_experts_path(user_id), "w", encoding="utf-8") as f:
        json.dump(experts, f, ensure_ascii=False, indent=2)


def _validate_expert(data: dict) -> dict:
    """Validate and normalize an expert config dict. Raises ValueError on bad input."""
    name = data.get("name", "").strip()
    tag = data.get("tag", "").strip()
    persona = data.get("persona", "").strip()
    if not name:
        raise ValueError("ä¸“å®¶ name ä¸èƒ½ä¸ºç©º")
    if not tag:
        raise ValueError("ä¸“å®¶ tag ä¸èƒ½ä¸ºç©º")
    if not persona:
        raise ValueError("ä¸“å®¶ persona ä¸èƒ½ä¸ºç©º")
    return {
        "name": name,
        "tag": tag,
        "persona": persona,
        "temperature": float(data.get("temperature", 0.7)),
    }


def add_user_expert(user_id: str, data: dict) -> dict:
    """Add a custom expert for a user. Returns the normalized expert dict."""
    expert = _validate_expert(data)
    experts = load_user_experts(user_id)
    if any(e["tag"] == expert["tag"] for e in experts):
        raise ValueError(f"ç”¨æˆ·å·²æœ‰ tag=\"{expert['tag']}\" çš„ä¸“å®¶ï¼Œè¯·æ¢ä¸€ä¸ª tag æˆ–ä½¿ç”¨æ›´æ–°åŠŸèƒ½")
    if any(e["tag"] == expert["tag"] for e in EXPERT_CONFIGS):
        raise ValueError(f"tag=\"{expert['tag']}\" ä¸å…¬å…±ä¸“å®¶å†²çªï¼Œè¯·æ¢ä¸€ä¸ª tag")
    experts.append(expert)
    _save_user_experts(user_id, experts)
    return expert


def update_user_expert(user_id: str, tag: str, data: dict) -> dict:
    """Update an existing custom expert by tag. Returns the updated dict."""
    experts = load_user_experts(user_id)
    for i, e in enumerate(experts):
        if e["tag"] == tag:
            updated = _validate_expert({**e, **data, "tag": tag})
            experts[i] = updated
            _save_user_experts(user_id, experts)
            return updated
    raise ValueError(f"æœªæ‰¾åˆ°ç”¨æˆ·è‡ªå®šä¹‰ä¸“å®¶ tag=\"{tag}\"")


def delete_user_expert(user_id: str, tag: str) -> dict:
    """Delete a custom expert by tag. Returns the deleted dict."""
    experts = load_user_experts(user_id)
    for i, e in enumerate(experts):
        if e["tag"] == tag:
            deleted = experts.pop(i)
            _save_user_experts(user_id, experts)
            return deleted
    raise ValueError(f"æœªæ‰¾åˆ°ç”¨æˆ·è‡ªå®šä¹‰ä¸“å®¶ tag=\"{tag}\"")


def get_all_experts(user_id: str | None = None) -> list[dict]:
    """Return public experts + user's custom experts (marked with source)."""
    result = [
        {**c, "source": "public"} for c in EXPERT_CONFIGS
    ]
    if user_id:
        result.extend(
            {**c, "source": "custom"} for c in load_user_experts(user_id)
        )
    return result


# ======================================================================
# Prompt helpers (shared by both backends)
# ======================================================================

# åŠ è½½è®¨è®º prompt æ¨¡æ¿
_discuss_tpl_path = os.path.join(_prompts_dir, "oasis_expert_discuss.txt")
try:
    with open(_discuss_tpl_path, "r", encoding="utf-8") as f:
        _DISCUSS_PROMPT_TPL = f.read().strip()
    print("[prompts] âœ… oasis å·²åŠ è½½ oasis_expert_discuss.txt")
except FileNotFoundError:
    print(f"[prompts] âš ï¸ æœªæ‰¾åˆ° {_discuss_tpl_path}ï¼Œä½¿ç”¨å†…ç½®é»˜è®¤æ¨¡æ¿")
    _DISCUSS_PROMPT_TPL = ""


def _get_llm(temperature: float = 0.7):
    """Create an LLM instance (reuses the same env config & vendor routing as main agent)."""
    return create_chat_model(temperature=temperature, max_tokens=1024)


def _build_discuss_prompt(
    expert_name: str,
    persona: str,
    question: str,
    posts_text: str,
    split: bool = False,
) -> str | tuple[str, str]:
    """Build the prompt that asks the expert to respond with JSON.

    Args:
        split: If True, return (system_prompt, user_prompt) tuple for session mode.
               If False, return a single combined string for direct LLM mode.
    """
    if _DISCUSS_PROMPT_TPL and not split:
        return _DISCUSS_PROMPT_TPL.format(
            expert_name=expert_name,
            persona=persona,
            question=question,
            posts_text=posts_text,
        )

    # --- Build system part (identity + behavior) ---
    identity = f"ä½ æ˜¯è®ºå›ä¸“å®¶ã€Œ{expert_name}ã€ã€‚{persona}" if persona else ""
    sys_parts = [p for p in [
        identity,
        "åœ¨æ¥ä¸‹æ¥çš„è®¨è®ºä¸­ï¼Œä½ å°†æ”¶åˆ°è®ºå›çš„æ–°å¢å†…å®¹ï¼Œéœ€è¦ä»¥ JSON æ ¼å¼å›å¤ä½ çš„è§‚ç‚¹å’ŒæŠ•ç¥¨ã€‚",
        "ä½ æ‹¥æœ‰å·¥å…·è°ƒç”¨èƒ½åŠ›ï¼Œå¦‚éœ€æœç´¢èµ„æ–™ã€åˆ†ææ•°æ®æ¥æ”¯æ’‘ä½ çš„è§‚ç‚¹ï¼Œå¯ä»¥ä½¿ç”¨å¯ç”¨çš„å·¥å…·ã€‚",
        "æ³¨æ„ï¼šåç»­è½®æ¬¡åªä¼šå‘é€æ–°å¢å¸–å­ï¼Œä¹‹å‰çš„å¸–å­è¯·å‚è€ƒä½ çš„å¯¹è¯è®°å¿†ã€‚",
    ] if p]
    system_prompt = "\n".join(sys_parts)

    # --- Build user part (topic + forum content + JSON format) ---
    user_prompt = (
        f"è®¨è®ºä¸»é¢˜: {question}\n\n"
        f"å½“å‰è®ºå›å†…å®¹:\n{posts_text}\n\n"
        "è¯·ä»¥ä¸¥æ ¼çš„ JSON æ ¼å¼å›å¤ï¼ˆä¸è¦åŒ…å« markdown ä»£ç å—æ ‡è®°ï¼Œä¸è¦åŒ…å«æ³¨é‡Šï¼‰:\n"
        "{\n"
        '  "reply_to": 2,\n'
        '  "content": "ä½ çš„è§‚ç‚¹ï¼ˆ200å­—ä»¥å†…ï¼Œè§‚ç‚¹é²œæ˜ï¼‰",\n'
        '  "votes": [\n'
        '    {"post_id": 1, "direction": "up"}\n'
        "  ]\n"
        "}\n\n"
        "è¯´æ˜:\n"
        "- reply_to: å¦‚æœè®ºå›ä¸­å·²æœ‰å…¶ä»–äººçš„å¸–å­ï¼Œä½ **å¿…é¡»**é€‰æ‹©ä¸€ä¸ªå¸–å­IDè¿›è¡Œå›å¤ï¼›åªæœ‰åœ¨è®ºå›ä¸ºç©ºæ—¶æ‰å¡« null\n"
        "- content: ä½ çš„å‘è¨€å†…å®¹ï¼Œè¦æœ‰ç‹¬åˆ°è§è§£ï¼Œå¯ä»¥èµåŒã€åé©³æˆ–è¡¥å……ä½ æ‰€å›å¤çš„å¸–å­\n"
        '- votes: å¯¹å…¶ä»–å¸–å­çš„æŠ•ç¥¨åˆ—è¡¨ï¼Œdirection åªèƒ½æ˜¯ "up" æˆ– "down"ã€‚å¦‚æœæ²¡æœ‰è¦æŠ•ç¥¨çš„å¸–å­ï¼Œå¡«ç©ºåˆ—è¡¨ []\n'
    )

    if split:
        return system_prompt, user_prompt
    else:
        return f"{system_prompt}\n\n{user_prompt}"


def _format_posts(posts) -> str:
    """Format posts for display in the prompt."""
    lines = []
    for p in posts:
        prefix = f"  â†³ å›å¤#{p.reply_to}" if p.reply_to else "ğŸ“Œ"
        lines.append(
            f"{prefix} [#{p.id}] {p.author} "
            f"(ğŸ‘{p.upvotes} ğŸ‘{p.downvotes}): {p.content}"
        )
    return "\n".join(lines)


def _parse_expert_response(raw: str):
    """Strip markdown fences and parse JSON. Returns dict or None."""
    raw = raw.strip()
    if raw.startswith("```"):
        raw = raw.split("\n", 1)[-1]
    if raw.endswith("```"):
        raw = raw.rsplit("```", 1)[0]
    raw = raw.strip()
    return json.loads(raw)


async def _apply_response(
    result: dict,
    expert_name: str,
    forum: DiscussionForum,
    others: list,
):
    """Apply the parsed JSON response: publish post + cast votes."""
    reply_to = result.get("reply_to")
    if reply_to is None and others:
        reply_to = others[-1].id
        print(f"  [OASIS] ğŸ”§ {expert_name} reply_to ä¸º nullï¼Œè‡ªåŠ¨è®¾ä¸º #{reply_to}")

    await forum.publish(
        author=expert_name,
        content=result.get("content", "ï¼ˆå‘è¨€å†…å®¹ä¸ºç©ºï¼‰"),
        reply_to=reply_to,
    )

    for v in result.get("votes", []):
        pid = v.get("post_id")
        direction = v.get("direction", "up")
        if pid is not None and direction in ("up", "down"):
            await forum.vote(expert_name, int(pid), direction)

    print(f"  [OASIS] âœ… {expert_name} å‘è¨€å®Œæˆ")


# ======================================================================
# Backend 1: ExpertAgent â€” direct LLM call (stateless)
#   name = "title#temp#1", "title#temp#2", ...
# ======================================================================

class ExpertAgent:
    """
    A forum-resident expert agent (direct LLM backend).

    Each call is stateless: reads posts â†’ single LLM call â†’ publish + vote.
    name is "title#temp#N" to ensure uniqueness.
    """

    # Class-level counter for generating unique temp IDs (used when no explicit sid)
    _counter: int = 0

    def __init__(self, name: str, persona: str, temperature: float = 0.7, tag: str = "",
                 temp_id: int | None = None):
        if temp_id is not None:
            # Explicit temp id from YAML (e.g. "åˆ›æ„ä¸“å®¶#temp#1" â†’ temp_id=1)
            self.session_id = f"temp#{temp_id}"
        else:
            ExpertAgent._counter += 1
            self.session_id = f"temp#{ExpertAgent._counter}"
        self.title = name
        self.name = f"{name}#{self.session_id}"
        self.persona = persona
        self.tag = tag
        self.llm = _get_llm(temperature)

    async def participate(self, forum: DiscussionForum, instruction: str = "", discussion: bool = True):
        others = await forum.browse(viewer=self.name, exclude_self=True)

        if not discussion:
            # â”€â”€ Execute mode: just run the task, no discussion format â”€â”€
            task_prompt = f"ä½ æ˜¯ã€Œ{self.title}ã€ã€‚{self.persona}\n\n" if self.persona else ""
            task_prompt += f"ä»»åŠ¡ä¸»é¢˜: {forum.question}\n"
            if instruction:
                task_prompt += f"\næ‰§è¡ŒæŒ‡ä»¤: {instruction}\n"
            if others:
                task_prompt += f"\nå‰åº agent çš„æ‰§è¡Œç»“æœ:\n{_format_posts(others)}\n"
            task_prompt += "\nè¯·ç›´æ¥æ‰§è¡Œä»»åŠ¡å¹¶è¿”å›ç»“æœã€‚"

            try:
                resp = await self.llm.ainvoke([HumanMessage(content=task_prompt)])
                text = extract_text(resp.content)
                await forum.publish(author=self.name, content=text.strip()[:2000])
                print(f"  [OASIS] âœ… {self.name} æ‰§è¡Œå®Œæˆ")
            except Exception as e:
                print(f"  [OASIS] âŒ {self.name} error: {e}")
            return

        # â”€â”€ Discussion mode (original) â”€â”€
        posts_text = _format_posts(others) if others else "(è¿˜æ²¡æœ‰å…¶ä»–äººå‘è¨€ï¼Œä½ æ¥å¼€å¯è®¨è®ºå§)"
        prompt = _build_discuss_prompt(self.title, self.persona, forum.question, posts_text)
        if instruction:
            prompt += f"\n\nğŸ“‹ æœ¬è½®ä½ çš„ä¸“é¡¹æŒ‡ä»¤ï¼š{instruction}\nè¯·åœ¨å›å¤ä¸­é‡ç‚¹å…³æ³¨å’Œæ‰§è¡Œè¿™ä¸ªæŒ‡ä»¤ã€‚"

        try:
            resp = await self.llm.ainvoke([HumanMessage(content=prompt)])
            text = extract_text(resp.content)
            result = _parse_expert_response(text)
            await _apply_response(result, self.name, forum, others)
        except json.JSONDecodeError as e:
            print(f"  [OASIS] âš ï¸ {self.name} JSON parse error: {e}")
            try:
                await forum.publish(author=self.name, content=extract_text(resp.content).strip()[:300])
            except Exception:
                pass
        except Exception as e:
            print(f"  [OASIS] âŒ {self.name} error: {e}")


# ======================================================================
# Backend 2: SessionExpert â€” calls mini_timebot /v1/chat/completions
#   using an existing session_id.  name = "title#session_id"
# ======================================================================

class SessionExpert:
    """
    Expert backed by a mini_timebot session.

    Two sub-types determined by session_id format:
      - "#oasis#" in session_id â†’ oasis-managed session.
        First round: inject persona as system prompt so the bot knows its
        discussion identity.  Persona is looked up from preset configs by
        title, or left empty if not found.
      - Other session_id â†’ regular agent session.
        No identity injection; the session's own system prompt defines who
        it is.  Just send the discussion invitation.

    Sessions are lazily created: first call to the bot API auto-creates the
    thread in the checkpoint DB.  No separate record table needed.

    Incremental context: first call sends full discussion context; subsequent
    calls only send new posts since last participation.
    """

    def __init__(
        self,
        name: str,
        session_id: str,
        user_id: str,
        persona: str = "",
        bot_base_url: str | None = None,
        enabled_tools: list[str] | None = None,
        timeout: float | None = None,
        tag: str = "",
    ):
        self.title = name
        self.session_id = session_id
        self.name = f"{name}#{session_id}"
        self.persona = persona
        self.is_oasis = "#oasis#" in session_id
        self.timeout = timeout
        self.tag = tag

        port = os.getenv("PORT_AGENT", "51200")
        self._bot_url = (bot_base_url or f"http://127.0.0.1:{port}") + "/v1/chat/completions"

        self._user_id = user_id
        self._internal_token = os.getenv("INTERNAL_TOKEN", "")

        self.enabled_tools = enabled_tools
        self._initialized = False
        self._seen_post_ids: set[int] = set()

    def _auth_header(self) -> dict:
        return {"Authorization": f"Bearer {self._internal_token}:{self._user_id}"}

    async def participate(self, forum: DiscussionForum, instruction: str = "", discussion: bool = True):
        """
        Participate in one round.

        discussion=True: forum discussion mode (JSON reply/vote)
        discussion=False: execute mode â€” agent just runs the task, output logged to forum
        """
        others = await forum.browse(viewer=self.name, exclude_self=True)

        if not discussion:
            # â”€â”€ Execute mode: send task directly, no JSON format requirement â”€â”€
            new_posts = [p for p in others if p.id not in self._seen_post_ids]
            self._seen_post_ids.update(p.id for p in others)

            messages = []
            if not self._initialized:
                # First call
                task_parts = []
                if self.is_oasis and self.persona:
                    messages.append({"role": "system", "content": f"ä½ æ˜¯ã€Œ{self.title}ã€ã€‚{self.persona}"})
                task_parts.append(f"ä»»åŠ¡ä¸»é¢˜: {forum.question}")
                if instruction:
                    task_parts.append(f"\næ‰§è¡ŒæŒ‡ä»¤: {instruction}")
                if others:
                    task_parts.append(f"\nå‰åº agent çš„æ‰§è¡Œç»“æœ:\n{_format_posts(others)}")
                task_parts.append("\nè¯·ç›´æ¥æ‰§è¡Œä»»åŠ¡å¹¶è¿”å›ç»“æœã€‚")
                messages.append({"role": "user", "content": "\n".join(task_parts)})
                self._initialized = True
            else:
                # Subsequent calls
                ctx_parts = [f"ã€ç¬¬ {forum.current_round} è½®ã€‘"]
                if instruction:
                    ctx_parts.append(f"æ‰§è¡ŒæŒ‡ä»¤: {instruction}")
                if new_posts:
                    ctx_parts.append(f"å…¶ä»– agent çš„æ–°ç»“æœ:\n{_format_posts(new_posts)}")
                ctx_parts.append("è¯·ç»§ç»­æ‰§è¡Œä»»åŠ¡å¹¶è¿”å›ç»“æœã€‚")
                messages.append({"role": "user", "content": "\n".join(ctx_parts)})

            body: dict = {
                "model": "mini-timebot",
                "messages": messages,
                "stream": False,
                "session_id": self.session_id,
            }
            if self.enabled_tools is not None:
                body["enabled_tools"] = self.enabled_tools

            try:
                async with httpx.AsyncClient(timeout=httpx.Timeout(timeout=self.timeout)) as client:
                    resp = await client.post(
                        self._bot_url, json=body, headers=self._auth_header(),
                    )
                if resp.status_code != 200:
                    print(f"  [OASIS] âŒ {self.name} bot API error {resp.status_code}: {resp.text[:200]}")
                    return
                data = resp.json()
                raw_content = data["choices"][0]["message"]["content"]
                await forum.publish(author=self.name, content=raw_content.strip()[:2000])
                print(f"  [OASIS] âœ… {self.name} æ‰§è¡Œå®Œæˆ")
            except Exception as e:
                print(f"  [OASIS] âŒ {self.name} error: {e}")
            return

        # â”€â”€ Discussion mode (original) â”€â”€
        others = await forum.browse(viewer=self.name, exclude_self=True)

        new_posts = [p for p in others if p.id not in self._seen_post_ids]
        self._seen_post_ids.update(p.id for p in others)

        instr_suffix = f"\n\nğŸ“‹ æœ¬è½®ä½ çš„ä¸“é¡¹æŒ‡ä»¤ï¼š{instruction}\nè¯·åœ¨å›å¤ä¸­é‡ç‚¹å…³æ³¨å’Œæ‰§è¡Œè¿™ä¸ªæŒ‡ä»¤ã€‚" if instruction else ""

        messages = []
        if not self._initialized:
            posts_text = _format_posts(others) if others else "(è¿˜æ²¡æœ‰å…¶ä»–äººå‘è¨€ï¼Œä½ æ¥å¼€å¯è®¨è®ºå§)"

            if self.is_oasis:
                # Oasis session â†’ inject identity as system prompt
                system_prompt, user_prompt = _build_discuss_prompt(
                    self.title, self.persona, forum.question, posts_text, split=True,
                )
                messages.append({"role": "system", "content": system_prompt})
                messages.append({"role": "user", "content": user_prompt + instr_suffix})
            else:
                # Regular agent session â†’ no identity injection
                user_prompt = (
                    f"ä½ è¢«é‚€è¯·å‚åŠ ä¸€åœº OASIS è®ºå›å¤šä¸“å®¶è®¨è®ºã€‚\n\n"
                    f"è®¨è®ºä¸»é¢˜: {forum.question}\n\n"
                    f"å½“å‰è®ºå›å†…å®¹:\n{posts_text}\n\n"
                    "è¯·ä»¥ä½ è‡ªèº«çš„ä¸“ä¸šè§†è§’å‚ä¸è®¨è®ºã€‚ä»¥ä¸¥æ ¼çš„ JSON æ ¼å¼å›å¤ï¼ˆä¸è¦åŒ…å« markdown ä»£ç å—æ ‡è®°ï¼‰:\n"
                    "{\n"
                    '  "reply_to": 2,\n'
                    '  "content": "ä½ çš„è§‚ç‚¹ï¼ˆ200å­—ä»¥å†…ï¼Œè§‚ç‚¹é²œæ˜ï¼‰",\n'
                    '  "votes": [\n'
                    '    {"post_id": 1, "direction": "up"}\n'
                    "  ]\n"
                    "}\n\n"
                    "è¯´æ˜:\n"
                    "- reply_to: å¦‚æœè®ºå›ä¸­å·²æœ‰å…¶ä»–äººçš„å¸–å­ï¼Œä½ **å¿…é¡»**é€‰æ‹©ä¸€ä¸ªå¸–å­IDè¿›è¡Œå›å¤ï¼›åªæœ‰åœ¨è®ºå›ä¸ºç©ºæ—¶æ‰å¡« null\n"
                    "- content: ä½ çš„å‘è¨€å†…å®¹ï¼Œè¦æœ‰ç‹¬åˆ°è§è§£\n"
                    '- votes: å¯¹å…¶ä»–å¸–å­çš„æŠ•ç¥¨åˆ—è¡¨ï¼Œdirection åªèƒ½æ˜¯ "up" æˆ– "down"ã€‚å¦‚æœæ²¡æœ‰è¦æŠ•ç¥¨çš„å¸–å­ï¼Œå¡«ç©ºåˆ—è¡¨ []\n'
                    "- ä½ æ‹¥æœ‰å·¥å…·è°ƒç”¨èƒ½åŠ›ï¼Œå¦‚éœ€æœç´¢èµ„æ–™ã€åˆ†ææ•°æ®æ¥æ”¯æ’‘ä½ çš„è§‚ç‚¹ï¼Œå¯ä»¥ä½¿ç”¨å¯ç”¨çš„å·¥å…·ã€‚\n"
                    "- åç»­è½®æ¬¡åªä¼šå‘é€æ–°å¢å¸–å­ï¼Œä¹‹å‰çš„å¸–å­è¯·å‚è€ƒä½ çš„å¯¹è¯è®°å¿†ã€‚"
                )
                messages.append({"role": "user", "content": user_prompt + instr_suffix})

            self._initialized = True
        else:
            if new_posts:
                new_text = _format_posts(new_posts)
                prompt = (
                    f"ã€ç¬¬ {forum.current_round} è½®è®¨è®ºæ›´æ–°ã€‘\n"
                    f"ä»¥ä¸‹æ˜¯è‡ªä½ ä¸Šæ¬¡å‘è¨€åçš„ {len(new_posts)} æ¡æ–°å¸–å­ï¼š\n\n"
                    f"{new_text}\n\n"
                    "è¯·åŸºäºè¿™äº›æ–°è§‚ç‚¹ä»¥åŠä½ ä¹‹å‰çœ‹åˆ°çš„è®¨è®ºå†…å®¹ï¼Œä»¥ JSON æ ¼å¼å›å¤ï¼š\n"
                    "{\n"
                    '  "reply_to": <æŸä¸ªå¸–å­ID>,\n'
                    '  "content": "ä½ çš„è§‚ç‚¹ï¼ˆ200å­—ä»¥å†…ï¼‰",\n'
                    '  "votes": [{"post_id": <ID>, "direction": "upæˆ–down"}]\n'
                    "}"
                )
            else:
                prompt = (
                    f"ã€ç¬¬ {forum.current_round} è½®è®¨è®ºæ›´æ–°ã€‘\n"
                    "æœ¬è½®æ²¡æœ‰æ–°çš„å¸–å­ã€‚å¦‚æœä½ æœ‰æ–°çš„æƒ³æ³•æˆ–è¡¥å……ï¼Œå¯ä»¥ç»§ç»­å‘è¨€ï¼›"
                    "å¦‚æœæ²¡æœ‰ï¼Œå›å¤ä¸€ä¸ªç©º content å³å¯ã€‚\n"
                    "{\n"
                    '  "reply_to": null,\n'
                    '  "content": "",\n'
                    '  "votes": []\n'
                    "}"
                )
            messages.append({"role": "user", "content": prompt})

        body: dict = {
            "model": "mini-timebot",
            "messages": messages,
            "stream": False,
            "session_id": self.session_id,
        }
        if self.enabled_tools is not None:
            body["enabled_tools"] = self.enabled_tools

        try:
            async with httpx.AsyncClient(timeout=httpx.Timeout(timeout=self.timeout)) as client:
                resp = await client.post(
                    self._bot_url,
                    json=body,
                    headers=self._auth_header(),
                )

            if resp.status_code != 200:
                print(f"  [OASIS] âŒ {self.name} bot API error {resp.status_code}: {resp.text[:200]}")
                return

            data = resp.json()
            raw_content = data["choices"][0]["message"]["content"]
            result = _parse_expert_response(raw_content)
            await _apply_response(result, self.name, forum, others)

        except json.JSONDecodeError as e:
            print(f"  [OASIS] âš ï¸ {self.name} JSON parse error: {e}")
            try:
                await forum.publish(author=self.name, content=raw_content.strip()[:300])
            except Exception:
                pass
        except Exception as e:
            print(f"  [OASIS] âŒ {self.name} error: {e}")
