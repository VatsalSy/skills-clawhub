#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenClaw Multi-Agent - æ™ºèƒ½ä»»åŠ¡è·¯ç”±å™¨
æ ¹æ®ä»»åŠ¡å†…å®¹è‡ªåŠ¨åˆ¤æ–­ä»»åŠ¡ç±»å‹å¹¶æ¨èæ¨¡å‹ tier
"""

import argparse
import json
import re
from dataclasses import dataclass, asdict
from typing import List, Dict, Optional, Tuple


# æœ€å¤§ä»»åŠ¡å­—ç¬¦ä¸²é•¿åº¦é™åˆ¶
MAX_TASK_LENGTH = 10000


# Tier å®šä¹‰å’Œå…³é”®è¯æ˜ å°„
# æ··åˆæ¨¡å¼è§¦å‘ä¿¡å·è¯ï¼šç”¨æˆ·æƒ³è¦å¤šç‰ˆæœ¬è‰ç¨¿/å¤šè§’åº¦å¯¹æ¯”
HYBRID_SIGNALS = [
    # ä¸­æ–‡
    "å‡ ä¸ªç‰ˆæœ¬", "å¤šä¸ªç‰ˆæœ¬", "å¤šç‰ˆæœ¬", "å¤šä¸ªè‰ç¨¿", "å¤šç‰ˆè‰ç¨¿",
    "3ä¸ªç‰ˆæœ¬", "ä¸‰ä¸ªç‰ˆæœ¬", "2ä¸ªç‰ˆæœ¬", "ä¸¤ä¸ªç‰ˆæœ¬", "4ä¸ªç‰ˆæœ¬", "å››ä¸ªç‰ˆæœ¬",
    "å‡ ä¸ªè§’åº¦", "å¤šä¸ªè§’åº¦", "ä¸åŒè§’åº¦", "ä¸åŒé£æ ¼", "å¤šç§é£æ ¼",
    "è®©æˆ‘æŒ‘", "å¸®æˆ‘æŒ‘", "æˆ‘æ¥é€‰", "æˆ‘æ¥æŒ‘", "å“ªä¸ªæ›´å¥½",
    "å¯¹æ¯”å‡ ç§", "å¯¹æ¯”å‡ ä¸ªå†™æ³•", "abå¯¹æ¯”", "a/bå¯¹æ¯”",
    "ä¸åŒæ¨¡å‹å„è‡ª", "è®©ä¸åŒai", "è®©å‡ ä¸ªai", "å¤šä¸ªæ¨¡å‹",
    "å„å†™ä¸€ç‰ˆ", "å„è‡ªå†™", "åˆ†åˆ«å†™",
    "å‡ ç§å†™æ³•", "å¤šç§å†™æ³•", "ä¸åŒå†™æ³•",
    # è‹±æ–‡
    "multiple versions", "several versions", "multi-version",
    "multiple drafts", "different angles", "different styles",
    "let me pick", "let me choose", "a/b test", "ab test",
    "compare versions", "compare drafts", "side by side",
    "each model", "different models", "multiple models",
    "3 versions", "3 drafts", "several drafts",
]

# è”ç½‘éœ€æ±‚ä¿¡å·è¯ï¼šåˆ¤æ–­æ˜¯å¦éœ€è¦ sessions_spawnï¼ˆæŒ‡æŒ¥å®˜/æ··åˆï¼‰
SEARCH_SIGNALS = [
    # ä¸­æ–‡
    "æœç´¢", "æœä¸€ä¸‹", "æŸ¥ä¸€ä¸‹", "è”ç½‘", "æœ€æ–°", "ç°åœ¨", "ä»Šå¤©",
    "æœ€è¿‘", "å®æ—¶", "æ–°é—»", "å½“å‰", "æŸ¥æ‰¾èµ„æ–™", "è°ƒç ”", "ç ”ç©¶",
    "æŸ¥èµ„æ–™", "æ‰¾èµ„æ–™", "çˆ¬", "æŠ“å–",
    # è‹±æ–‡
    "search", "look up", "latest", "current", "real-time", "recent",
    "news", "find information", "research", "scrape", "fetch",
    "web", "internet", "online",
]

TIER_KEYWORDS: Dict[str, Dict] = {
    "FAST": {
        "description": "ç®€å•æŸ¥è¯¢ã€åˆ—è¡¨ã€çŠ¶æ€æ£€æŸ¥ã€ç¿»è¯‘ã€æ ¼å¼è½¬æ¢",
        "keywords": [
            # ä¸­æ–‡
            "æŸ¥è¯¢", "åˆ—å‡º", "çŠ¶æ€", "ç¿»è¯‘", "æ ¼å¼", "è½¬æ¢", "æ˜¯å¦", "å¤šå°‘", "ä»€ä¹ˆæ—¶å€™",
            "è·å–", "æ˜¾ç¤º", "æŸ¥çœ‹", "æ£€æŸ¥", "ç¡®è®¤", "ç®€å•", "å¿«é€Ÿ",
            # è‹±æ–‡
            "query", "list", "status", "translate", "format", "convert", "check",
            "get", "show", "display", "simple", "quick"
        ],
        "weight": 1.0,
    },
    "CODE": {
        "description": "ä»£ç ç›¸å…³ä»»åŠ¡ï¼šç¼–ç¨‹ã€è°ƒè¯•ã€å®ç°ã€é‡æ„",
        "keywords": [
            # ä¸­æ–‡
            "ä»£ç ", "ç¼–ç¨‹", "å®ç°åŠŸèƒ½", "å‡½æ•°", "bug", "ä¿®å¤bug", "æŠ¥é”™",
            "é‡æ„", "ç¨‹åº", "çˆ¬è™«", "è„šæœ¬", "æ¥å£", "ç®—æ³•", "å•å…ƒæµ‹è¯•",
            # è‹±æ–‡
            "code", "programming", "implement", "function", "class", "api", "fix",
            "refactor", "script", "develop", "module", "library", "algorithm"
        ],
        "weight": 1.2,
    },
    "RESEARCH": {
        "description": "è°ƒç ”ã€æœç´¢ã€æ”¶é›†ä¿¡æ¯ã€åˆ†æå¯¹æ¯”",
        "keywords": [
            # ä¸­æ–‡
            "è°ƒç ”", "æœç´¢", "æŸ¥æ‰¾", "æ”¶é›†", "æ•´ç†", "åˆ†æ", "å¯¹æ¯”", "æ¯”è¾ƒ",
            "survey", "research", "ç ”ç©¶", "è°ƒæŸ¥", "æ¢ç´¢", "äº†è§£", "å­¦ä¹ ",
            "èµ„æ–™", "æ–‡çŒ®", "ç»¼è¿°", "æ¦‚è§ˆ", "ç°çŠ¶", "è¶‹åŠ¿",
            # è‹±æ–‡
            "research", "survey", "investigate", "explore", "study", "analyze",
            "compare", "collect", "gather", "review", "overview"
        ],
        "weight": 1.1,
    },
    "CREATIVE": {
        "description": "å†™ä½œã€åˆ›æ„ã€æ–‡æ¡ˆã€æŠ¥å‘Šæ’°å†™",
        "keywords": [
            # ä¸­æ–‡ï¼ˆç²¾ç¡®è¯ï¼Œé¿å…"å†™"å¤ªæ³›ï¼‰
            "å†™ä½œ", "æ–‡ç« ", "æ–‡æ¡ˆ", "åˆ›æ„", "æ•…äº‹", "æ’°å†™", "åˆ›ä½œ",
            "æ¶¦è‰²", "æ”¹å†™", "æ‰‹å†Œ", "æŒ‡å—", "æ•™ç¨‹", "åšå®¢", "æ¨æ–‡",
            # è‹±æ–‡
            "writing", "creative", "story", "draft", "compose", "copywriting", "blog"
        ],
        "weight": 1.0,
    },
    "REASONING": {
        "description": "å¤æ‚æ¨ç†ã€æ•°å­¦è®¡ç®—ã€é€»è¾‘åˆ†æã€æ¶æ„è®¾è®¡",
        "keywords": [
            # ä¸­æ–‡
            "æ¨ç†", "åˆ†æ", "è®¡ç®—", "é€»è¾‘", "æ•°å­¦", "è§„åˆ’", "è®¾è®¡æ–¹æ¡ˆ", "æ¶æ„",
            "è¯æ˜", "æ¨å¯¼", "éªŒè¯", "ä¼˜åŒ–", "ç­–ç•¥", "å†³ç­–", "è¯„ä¼°",
            "å¤æ‚", "æ·±åº¦", "ç³»ç»Ÿæ€§", "å…¨é¢", "è¯¦ç»†", "ç²¾ç¡®",
            # è‹±æ–‡
            "reasoning", "logic", "mathematical", "math", "planning", "design",
            "architecture", "optimize", "strategy", "prove", "derive", "complex"
        ],
        "weight": 1.3,
    },
}


@dataclass
class ClassificationResult:
    """åˆ†ç±»ç»“æœ"""
    tier: str
    confidence: float
    reason: str


@dataclass
class SpawnTask:
    """ç”Ÿæˆçš„å­ä»»åŠ¡"""
    task: str
    tier: str
    model: Optional[str] = None
    reason: str = ""


class TaskRouter:
    """ä»»åŠ¡è·¯ç”±å™¨ - æ ¹æ®å†…å®¹è‡ªåŠ¨åˆ†ç±»ä»»åŠ¡"""

    def __init__(self):
        self.tier_keywords = TIER_KEYWORDS

    def _validate_task(self, task: str) -> None:
        """éªŒè¯ä»»åŠ¡å­—ç¬¦ä¸²"""
        if not task or not isinstance(task, str):
            raise ValueError("ä»»åŠ¡ä¸èƒ½ä¸ºç©º")
        if len(task) > MAX_TASK_LENGTH:
            raise ValueError(f"ä»»åŠ¡é•¿åº¦è¶…è¿‡é™åˆ¶ï¼ˆæœ€å¤§ {MAX_TASK_LENGTH} å­—ç¬¦ï¼‰")

    def _count_keywords(self, task: str) -> Dict[str, Tuple[int, List[str]]]:
        """
        ç»Ÿè®¡æ¯ä¸ª tier çš„å…³é”®è¯åŒ¹é…æ•°é‡å’ŒåŒ¹é…åˆ°çš„å…³é”®è¯
        è¿”å›: {tier: (count, matched_keywords)}
        """
        task_lower = task.lower()
        results = {}

        for tier, config in self.tier_keywords.items():
            count = 0
            matched = []
            for keyword in config["keywords"]:
                # ä¸­æ–‡å…³é”®è¯ç›´æ¥ç”¨ in åŒ¹é…ï¼Œè‹±æ–‡å…³é”®è¯ç”¨è¯è¾¹ç•Œ
                kw = keyword.lower()
                if any('\u4e00' <= c <= '\u9fff' for c in kw):
                    # ä¸­æ–‡ï¼šç›´æ¥å­ä¸²åŒ¹é…
                    if kw in task_lower:
                        count += 1
                        matched.append(keyword)
                else:
                    # è‹±æ–‡ï¼šè¯è¾¹ç•ŒåŒ¹é…
                    pattern = r'\b' + re.escape(kw) + r'\b'
                    if re.search(pattern, task_lower):
                        count += 1
                        matched.append(keyword)
            results[tier] = (count, matched)

        return results

    def classify(self, task: str) -> ClassificationResult:
        """
        å¯¹å•ä¸ªä»»åŠ¡è¿›è¡Œåˆ†ç±»

        Args:
            task: ä»»åŠ¡æè¿°å­—ç¬¦ä¸²

        Returns:
            ClassificationResult åŒ…å« tierã€confidence å’Œ reason
        """
        self._validate_task(task)

        keyword_stats = self._count_keywords(task)

        # è®¡ç®—åŠ æƒåˆ†æ•°
        scores = {}
        for tier, (count, matched) in keyword_stats.items():
            weight = self.tier_keywords[tier]["weight"]
            scores[tier] = count * weight

        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•å…³é”®è¯ï¼Œé»˜è®¤ä½¿ç”¨ REASONINGï¼ˆå¤æ‚ä»»åŠ¡ä¿é™©èµ·è§ï¼‰
        total_matches = sum(count for count, _ in keyword_stats.values())

        if total_matches == 0:
            # å°è¯•åŸºäºä»»åŠ¡é•¿åº¦å’Œå¤æ‚åº¦è¿›è¡Œå¯å‘å¼åˆ¤æ–­
            if len(task) < 50:
                best_tier = "FAST"
                confidence = 0.5
                reason = "ä»»åŠ¡è¾ƒçŸ­ï¼Œæ— æ˜ç¡®å…³é”®è¯ï¼Œé»˜è®¤å½’ç±»ä¸ºç®€å•æŸ¥è¯¢"
            else:
                best_tier = "REASONING"
                confidence = 0.4
                reason = "æœªåŒ¹é…åˆ°æ˜ç¡®å…³é”®è¯ï¼ŒæŒ‰å¤æ‚ä»»åŠ¡å¤„ç†"
            return ClassificationResult(tier=best_tier, confidence=confidence, reason=reason)

        # æ‰¾å‡ºæœ€é«˜åˆ†
        best_tier = max(scores, key=scores.get)
        best_score = scores[best_tier]
        _, best_matched = keyword_stats[best_tier]

        # è®¡ç®—ç½®ä¿¡åº¦
        # åŸºç¡€ç½®ä¿¡åº¦ = å½“å‰ tier å¾—åˆ† / æ€»å¾—åˆ†
        total_score = sum(scores.values())
        base_confidence = best_score / total_score if total_score > 0 else 0

        # æ ¹æ®åŒ¹é…æ•°é‡è°ƒæ•´ç½®ä¿¡åº¦
        match_bonus = min(len(best_matched) * 0.1, 0.2)  # æœ€å¤šåŠ  0.2
        confidence = min(base_confidence + match_bonus, 0.95)

        # æ„å»ºåŸå› è¯´æ˜
        matched_str = ", ".join(best_matched[:5])  # æœ€å¤šæ˜¾ç¤º5ä¸ªåŒ¹é…è¯
        if len(best_matched) > 5:
            matched_str += f" ç­‰{len(best_matched)}ä¸ªå…³é”®è¯"

        reason = f"åŒ…å«å…³é”®è¯: {matched_str}"

        return ClassificationResult(
            tier=best_tier,
            confidence=round(confidence, 2),
            reason=reason
        )

    def split_task(self, task: str) -> List[str]:
        """
        å°è¯•å°†å¤åˆä»»åŠ¡æ‹†åˆ†ä¸ºå¤šä¸ªå­ä»»åŠ¡
        åŸºäºå¸¸è§çš„è¿æ¥è¯è¿›è¡Œæ‹†åˆ†

        Args:
            task: å¤åˆä»»åŠ¡æè¿°

        Returns:
            å­ä»»åŠ¡åˆ—è¡¨
        """
        self._validate_task(task)

        # å®šä¹‰æ‹†åˆ†æ¨¡å¼ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        split_patterns = [
            # ä¸­æ–‡è¿æ¥è¯
            r'[,ï¼Œ;ï¼›]\s*ç„¶å\s*',
            r'[,ï¼Œ;ï¼›]\s*æ¥ç€\s*',
            r'[,ï¼Œ;ï¼›]\s*å†\s*',
            r'[,ï¼Œ;ï¼›]\s*å¹¶ä¸”\s*',
            r'[,ï¼Œ;ï¼›]\s*åŒæ—¶\s*',
            r'\s+å¹¶\s*',
            r'\s+ç„¶å\s*',
            r'[,ï¼Œ;ï¼›]\s*',
            # è‹±æ–‡è¿æ¥è¯
            r'\s*,\s*then\s+',
            r'\s*,\s*and\s+then\s+',
            r'\s+and\s+',
            r'[,;]\s*',
        ]

        subtasks = [task]

        for pattern in split_patterns:
            new_subtasks = []
            for t in subtasks:
                parts = re.split(pattern, t)
                # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²å’Œè¿‡çŸ­çš„ç‰‡æ®µ
                parts = [p.strip() for p in parts if p and len(p.strip()) > 5]
                new_subtasks.extend(parts)
            subtasks = new_subtasks
            if len(subtasks) > 1:
                break  # æˆåŠŸæ‹†åˆ†ååœæ­¢

        # å¦‚æœæ‹†åˆ†ååªæœ‰ä¸€ä¸ªä»»åŠ¡ä¸”åŸä»»åŠ¡è¾ƒé•¿ï¼Œå°è¯•æŒ‰å¥å­æ‹†åˆ†
        if len(subtasks) == 1 and len(task) > 100:
            sentence_pattern = r'[ã€‚ï¼ï¼Ÿ\.!?]\s+'
            parts = re.split(sentence_pattern, task)
            parts = [p.strip() for p in parts if p and len(p.strip()) > 10]
            if len(parts) > 1:
                subtasks = parts

        return subtasks if subtasks else [task]

    def detect_hybrid_intent(self, task: str) -> bool:
        """
        æ£€æµ‹ç”¨æˆ·æ˜¯å¦æœ‰ã€Œå¤šç‰ˆæœ¬è‰ç¨¿ã€æ„å›¾ï¼ˆè§¦å‘æ··åˆæ¨¡å¼ï¼‰
        """
        task_lower = task.lower()
        for signal in HYBRID_SIGNALS:
            if signal.lower() in task_lower:
                return True
        return False

    def detect_search_intent(self, task: str) -> bool:
        """
        æ£€æµ‹ç”¨æˆ·æ˜¯å¦éœ€è¦è”ç½‘æœç´¢ï¼ˆè§¦å‘æŒ‡æŒ¥å®˜/æ··åˆæ¨¡å¼ï¼‰
        """
        task_lower = task.lower()
        for signal in SEARCH_SIGNALS:
            if signal.lower() in task_lower:
                return True
        return False

    def recommend_mode(self, task: str) -> Dict:
        """
        æ ¹æ®ä»»åŠ¡å†…å®¹æ¨èæ‰§è¡Œæ¨¡å¼

        å†³ç­–æ ‘ï¼š
          éœ€è¦å¤šç‰ˆæœ¬ï¼Ÿ
            YES + éœ€è¦è”ç½‘ â†’ hybridï¼ˆæ··åˆï¼‰
            YES + ä¸éœ€è”ç½‘ â†’ pipelineï¼ˆæµæ°´çº¿ï¼‰
            NO  + éœ€è¦è”ç½‘ â†’ orchestratorï¼ˆæŒ‡æŒ¥å®˜ï¼‰
            NO  + ä¸éœ€è”ç½‘ â†’ pipelineï¼ˆæµæ°´çº¿ï¼‰

        Returns:
            {"mode": str, "needs_search": bool, "needs_multi_draft": bool, "reason": str}
        """
        self._validate_task(task)
        needs_search = self.detect_search_intent(task)
        needs_multi_draft = self.detect_hybrid_intent(task)

        if needs_multi_draft and needs_search:
            mode = "hybrid"
            reason = "éœ€è¦è”ç½‘æœç´¢ + å¤šç‰ˆæœ¬è‰ç¨¿å¯¹æ¯” â†’ æ··åˆæ¨¡å¼ï¼ˆå…ˆæŒ‡æŒ¥å®˜æœç´¢ï¼Œå†æµæ°´çº¿å¹¶è¡Œç”Ÿæˆï¼‰"
        elif needs_multi_draft:
            mode = "pipeline"
            reason = "éœ€è¦å¤šç‰ˆæœ¬è‰ç¨¿å¯¹æ¯”ï¼Œæ— éœ€è”ç½‘ â†’ æµæ°´çº¿æ¨¡å¼ï¼ˆå¹¶è¡Œç”Ÿæˆå¤šç‰ˆï¼‰"
        elif needs_search:
            mode = "orchestrator"
            reason = "éœ€è¦è”ç½‘æœç´¢ï¼Œåªè¦ä¸€ä»½ç»“æœ â†’ æŒ‡æŒ¥å®˜æ¨¡å¼ï¼ˆsessions_spawn å¹¶è¡Œï¼‰"
        else:
            mode = "pipeline"
            reason = "çº¯æ–‡æœ¬ä»»åŠ¡ï¼Œæ— éœ€è”ç½‘ â†’ æµæ°´çº¿æ¨¡å¼"

        return {
            "mode": mode,
            "needs_search": needs_search,
            "needs_multi_draft": needs_multi_draft,
            "reason": reason,
        }

    def spawn(self, task: str, multi: bool = False) -> List[SpawnTask]:
        """
        ç”Ÿæˆä»»åŠ¡é…ç½®

        Args:
            task: ä»»åŠ¡æè¿°
            multi: æ˜¯å¦å°è¯•æ‹†åˆ†ä¸ºå¤šä¸ªå­ä»»åŠ¡

        Returns:
            SpawnTask åˆ—è¡¨
        """
        self._validate_task(task)

        if multi:
            subtasks = self.split_task(task)
        else:
            subtasks = [task]

        spawn_tasks = []
        for subtask in subtasks:
            result = self.classify(subtask)
            spawn_tasks.append(SpawnTask(
                task=subtask,
                tier=result.tier,
                model=None,  # å§‹ç»ˆè¿”å› Noneï¼Œè®© OpenClaw ä½¿ç”¨ç”¨æˆ·é»˜è®¤æ¨¡å‹
                reason=result.reason
            ))

        return spawn_tasks


def main():
    parser = argparse.ArgumentParser(
        description="OpenClaw Multi-Agent - æ™ºèƒ½ä»»åŠ¡è·¯ç”±å™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åˆ†ç±»å•ä¸ªä»»åŠ¡
  python router.py classify "è°ƒç ”LangChainæ¡†æ¶"

  # ç”Ÿæˆä»»åŠ¡é…ç½®ï¼ˆå•ä»»åŠ¡ï¼‰
  python router.py spawn --json "å†™ä¸€ä¸ªPythonçˆ¬è™«"

  # ç”Ÿæˆä»»åŠ¡é…ç½®ï¼ˆå¤šä»»åŠ¡æ‹†åˆ†ï¼‰
  python router.py spawn --json --multi "è°ƒç ”LangChainå¹¶å†™æŠ¥å‘Š"
"""
    )

    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    # mode å‘½ä»¤ï¼ˆæ¨èæ‰§è¡Œæ¨¡å¼ï¼‰
    mode_parser = subparsers.add_parser(
        "mode",
        help="æ¨èæ‰§è¡Œæ¨¡å¼ï¼šorchestrator / pipeline / hybrid"
    )
    mode_parser.add_argument("task", help="ä»»åŠ¡æè¿°å­—ç¬¦ä¸²")
    mode_parser.add_argument("--json", action="store_true", help="ä»¥ JSON æ ¼å¼è¾“å‡º")

    # classify å‘½ä»¤
    classify_parser = subparsers.add_parser(
        "classify",
        help="å¯¹ä»»åŠ¡è¿›è¡Œåˆ†ç±»ï¼Œè¿”å›æ¨èçš„ tier"
    )
    classify_parser.add_argument(
        "task",
        help="ä»»åŠ¡æè¿°å­—ç¬¦ä¸²"
    )
    classify_parser.add_argument(
        "--json",
        action="store_true",
        help="ä»¥ JSON æ ¼å¼è¾“å‡º"
    )

    # spawn å‘½ä»¤
    spawn_parser = subparsers.add_parser(
        "spawn",
        help="ç”Ÿæˆä»»åŠ¡é…ç½®"
    )
    spawn_parser.add_argument(
        "task",
        help="ä»»åŠ¡æè¿°å­—ç¬¦ä¸²"
    )
    spawn_parser.add_argument(
        "--json",
        action="store_true",
        help="ä»¥ JSON æ ¼å¼è¾“å‡º"
    )
    spawn_parser.add_argument(
        "--multi",
        action="store_true",
        help="å°è¯•å°†å¤åˆä»»åŠ¡æ‹†åˆ†ä¸ºå¤šä¸ªå­ä»»åŠ¡"
    )

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    router = TaskRouter()

    try:
        if args.command == "mode":
            result = router.recommend_mode(args.task)
            if args.json:
                print(json.dumps(result, ensure_ascii=False))
            else:
                mode_emoji = {"orchestrator": "ğŸ¯", "pipeline": "ğŸ”„", "hybrid": "ğŸ”€"}.get(result["mode"], "â“")
                print(f"æ¨èæ¨¡å¼: {mode_emoji} {result['mode'].upper()}")
                print(f"éœ€è¦è”ç½‘: {'âœ…' if result['needs_search'] else 'âŒ'}")
                print(f"å¤šç‰ˆè‰ç¨¿: {'âœ…' if result['needs_multi_draft'] else 'âŒ'}")
                print(f"åŸå› : {result['reason']}")

        elif args.command == "classify":
            result = router.classify(args.task)
            if args.json:
                print(json.dumps(asdict(result), ensure_ascii=False))
            else:
                print(f"Tier: {result.tier}")
                print(f"Confidence: {result.confidence}")
                print(f"Reason: {result.reason}")

        elif args.command == "spawn":
            tasks = router.spawn(args.task, multi=args.multi)
            if args.json:
                output = [
                    {"task": t.task, "tier": t.tier, "model": t.model, "reason": t.reason}
                    for t in tasks
                ]
                # å¦‚æœæ˜¯å•ä»»åŠ¡ï¼Œè¿”å›å¯¹è±¡è€Œéæ•°ç»„
                if len(output) == 1 and not args.multi:
                    print(json.dumps(output[0], ensure_ascii=False))
                else:
                    print(json.dumps(output, ensure_ascii=False))
            else:
                for i, t in enumerate(tasks, 1):
                    print(f"\nä»»åŠ¡ {i}:")
                    print(f"  Task: {t.task}")
                    print(f"  Tier: {t.tier}")
                    print(f"  Model: {t.model}")
                    print(f"  Reason: {t.reason}")

    except ValueError as e:
        print(f"é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"æœªçŸ¥é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(2)


if __name__ == "__main__":
    import sys
    main()
