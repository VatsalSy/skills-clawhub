#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenClaw Native Multi-Agent Engine
é€šè¿‡ OpenClaw CLI å®ç°çœŸæ­£çš„å¤š Agent å¹¶è¡Œç¼–æ’

ä¸éœ€è¦ä»»ä½• API keyï¼Œç›´æ¥å¤ç”¨ OpenClaw å†…éƒ¨æ¨¡å‹è·¯ç”±ã€‚

Security Design Notes:
- This engine is a pipeline mode runner for the claw-multi-agent skill.
- Task descriptions are composed by the main OpenClaw agent (not raw user input),
  which is itself sandboxed by OpenClaw's permission model.
- Sub-agents run within the same OpenClaw session context and inherit the same
  permission boundaries as the main agent.
- The {file_path} placeholder in templates should always be a project-relative path.
  It is the responsibility of the orchestrating agent to validate paths before use.
- This skill does not introduce new attack surface beyond what OpenClaw already permits.
"""

import subprocess
import concurrent.futures
import json
import uuid
import time
import sys
import os
import logging
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)
logger = logging.getLogger("multiagent")


# æ¨¡å‹åˆ«åæ˜ å°„
# è®¾è®¡åŸåˆ™ï¼šç”¨æˆ· OpenClaw é‡Œé…äº†ä»€ä¹ˆæ¨¡å‹ï¼Œå°±ç”¨ä»€ä¹ˆæ¨¡å‹
# - ä¸ä¼  model â†’ openclaw agent CLI ä½¿ç”¨ç”¨æˆ·è‡ªå·±çš„é»˜è®¤æ¨¡å‹ï¼ˆæ¨èï¼‰
# - ä¼  None    â†’ åŒä¸Š
# - ä¼ å…·ä½“ id  â†’ ä½¿ç”¨æŒ‡å®šæ¨¡å‹ï¼ˆé«˜çº§ç”¨æ³•ï¼‰
#
# åˆ«åä»…ä½œä¸ºè¯­ä¹‰æ ‡è®°ï¼Œæ–¹ä¾¿åœ¨ task é‡Œå†™ "fast"/"smart"/"best"
# å®é™… model id å…¨éƒ¨è§£æä¸º Noneï¼ˆèµ°ç”¨æˆ·é»˜è®¤ï¼‰ï¼Œé™¤éç”¨æˆ·æ˜¾å¼æŒ‡å®š
MODEL_ALIASES: Dict[str, Optional[str]] = {
    "fast":  None,   # â†’ ç”¨æˆ·é»˜è®¤æ¨¡å‹ï¼ˆè½»é‡ä»»åŠ¡ï¼‰
    "smart": None,   # â†’ ç”¨æˆ·é»˜è®¤æ¨¡å‹ï¼ˆä¸­ç­‰ä»»åŠ¡ï¼‰
    "best":  None,   # â†’ ç”¨æˆ·é»˜è®¤æ¨¡å‹ï¼ˆé«˜è´¨é‡ä»»åŠ¡ï¼‰
    "default": None, # â†’ ç”¨æˆ·é»˜è®¤æ¨¡å‹
}

# è§’è‰² â†’ æ¨¡å‹åˆ«åï¼ˆéƒ½èµ°ç”¨æˆ·é»˜è®¤ï¼Œä¿æŒä¸€è‡´ï¼‰
ROLE_MODEL_MAP: Dict[str, str] = {
    "researcher": "fast",
    "writer":     "smart",
    "coder":      "smart",
    "analyst":    "smart",
    "reviewer":   "fast",
    "planner":    "fast",
}

# æˆæœ¬æƒé‡ï¼ˆè¯­ä¹‰ç”¨ï¼Œå®é™…éƒ½èµ°åŒä¸€ä¸ªæ¨¡å‹ï¼Œä¿ç•™ä¾›æœªæ¥æ‰©å±•ï¼‰
MODEL_COST_TIER: Dict[str, int] = {
    "fast":    1,
    "smart":   3,
    "best":    5,
    "default": 3,
}


@dataclass
class AgentTask:
    """å•ä¸ªå­ä»»åŠ¡å®šä¹‰"""
    task: str                          # ä»»åŠ¡å†…å®¹
    model: str = "kimi"               # æ¨¡å‹åˆ«åï¼ˆè§ MODEL_ALIASESï¼‰
    role: str = "assistant"           # è§’è‰²æè¿°ï¼ˆä¼šæ³¨å…¥åˆ° task å‰ç¼€ï¼‰
    label: str = ""                   # ä»»åŠ¡æ ‡ç­¾ï¼ˆä¾¿äºè¿½è¸ªï¼‰
    thinking: str = "off"             # æ€è€ƒæ¨¡å¼ï¼šoff/low/medium/high
    timeout: int = 300                # è¶…æ—¶ç§’æ•°
    session_id: str = field(default_factory=lambda: str(uuid.uuid4()))  # éš”ç¦» session


@dataclass
class AgentResult:
    """å­ä»»åŠ¡æ‰§è¡Œç»“æœ"""
    label: str
    model: str
    task: str
    output: str
    success: bool
    execution_time: float
    error: Optional[str] = None


class OrchestratorGuide:
    """
    æŒ‡æŒ¥å®˜æ¨¡å¼ä½¿ç”¨æŒ‡å—
    æä¾› sessions_spawn çš„æœ€ä½³å®è·µæ¨¡æ¿ï¼Œä¾›ä¸» Agent å‚è€ƒ
    """
    
    # é¢„è®¾è§’è‰²å®šä¹‰ï¼ˆä» agent-swarm è¿ç§»ï¼‰
    PRESETS = {
        "planner": {
            "model": "glm",
            "description": "è§„åˆ’è€…ï¼šéœ€æ±‚åˆ†æã€ä»»åŠ¡æ‹†è§£ã€ä¼˜å…ˆçº§æ’åº",
            "system_hint": "ä½ æ˜¯ä¸€ä¸ªé¡¹ç›®è§„åˆ’ä¸“å®¶ï¼Œæ“…é•¿å°†å¤æ‚éœ€æ±‚æ‹†è§£ä¸ºæ¸…æ™°çš„æ‰§è¡Œæ­¥éª¤ã€‚"
        },
        "researcher": {
            "model": "glm", 
            "description": "ä¿¡æ¯çŒæ‰‹ï¼šå¹¿åº¦æœç´¢ã€äº¤å‰éªŒè¯ã€ç»“æ„åŒ–è¾“å‡ºï¼ˆæœ‰ web_search å·¥å…·ï¼‰",
            "system_hint": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šç ”ç©¶å‘˜ï¼Œæ“…é•¿æœç´¢å’Œæ•´ç†ä¿¡æ¯ï¼Œè¾“å‡ºç»“æ„åŒ–æŠ¥å‘Šã€‚"
        },
        "coder": {
            "model": "kimi",
            "description": "ä»£ç å·¥åŒ ï¼šç¼–ç ã€è°ƒè¯•ã€æµ‹è¯•ã€é‡æ„ï¼ˆæœ‰ exec å·¥å…·ï¼‰",
            "system_hint": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±å·¥ç¨‹å¸ˆï¼Œæ“…é•¿ç¼–å†™é«˜è´¨é‡ã€å¯ç»´æŠ¤çš„ä»£ç ã€‚"
        },
        "writer": {
            "model": "gemini",
            "description": "æ–‡å­—å·¥åŒ ï¼šæ–‡æ¡£ã€æŠ¥å‘Šã€æ–‡æ¡ˆã€æ•´ç†ï¼ˆæœ‰ write å·¥å…·ï¼‰",
            "system_hint": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šå†™ä½œè€…ï¼Œæ“…é•¿å°†ä¿¡æ¯ç»„ç»‡æˆæ¸…æ™°ã€æœ‰ä»·å€¼çš„æ–‡æ¡£ã€‚"
        },
        "reviewer": {
            "model": "glm",
            "description": "è´¨é‡å®ˆé—¨äººï¼šä»£ç å®¡æŸ¥ã€å†…å®¹å®¡æ ¸ã€åˆè§„æ£€æŸ¥",
            "system_hint": "ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„å®¡æŸ¥å‘˜ï¼Œå®¢è§‚æŒ‡å‡ºé—®é¢˜å¹¶ç»™å‡ºå»ºè®¾æ€§æ”¹è¿›æ„è§ã€‚"
        },
        "analyst": {
            "model": "kimi",
            "description": "æ•°æ®ä¾¦æ¢ï¼šæ•°æ®å¤„ç†ã€ç»Ÿè®¡åˆ†æã€è¶‹åŠ¿é¢„æµ‹ï¼ˆæœ‰ exec å·¥å…·ï¼‰",
            "system_hint": "ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»æ•°æ®ä¸­å‘ç°è§„å¾‹å’Œæ´å¯Ÿã€‚"
        }
    }
    
    @staticmethod
    def get_preset_task_template(role: str, task: str, context: str = "") -> str:
        """ç”Ÿæˆé€‚åˆ sessions_spawn çš„ task æè¿°æ¨¡æ¿"""
        preset = OrchestratorGuide.PRESETS.get(role, {})
        hint = preset.get("system_hint", "")
        
        template = f"""{hint}

{'ã€ä¸Šä¸‹æ–‡ã€‘' + chr(10) + context + chr(10) if context else ''}ã€ä½ çš„ä»»åŠ¡ã€‘
{task}

ã€è¾“å‡ºè¦æ±‚ã€‘
- æ ¼å¼æ¸…æ™°ï¼Œä½¿ç”¨ Markdown
- ç»“æœä¿å­˜åˆ°æŒ‡å®šè·¯å¾„ï¼ˆå¦‚æœ‰ï¼‰
- å®Œæˆåç®€çŸ­æ€»ç»“åšäº†ä»€ä¹ˆ"""
        return template
    
    @staticmethod
    def print_orchestrator_guide():
        """æ‰“å°æŒ‡æŒ¥å®˜æ¨¡å¼ä½¿ç”¨æŒ‡å—"""
        print("\nğŸ“‹ æŒ‡æŒ¥å®˜æ¨¡å¼ - é¢„è®¾è§’è‰²")
        print("=" * 60)
        for role, info in OrchestratorGuide.PRESETS.items():
            print(f"\n  {role} (é»˜è®¤æ¨¡å‹: {info['model']})")
            print(f"    {info['description']}")
        print("\n" + "=" * 60)
        print("ä½¿ç”¨æ–¹å¼ï¼šåœ¨ä¸» Agent çš„å¯¹è¯ä¸­ï¼Œä½¿ç”¨ sessions_spawn å·¥å…·")
        print("è¯¦è§ SKILL.md ä¸­çš„ã€ŒæŒ‡æŒ¥å®˜æ¨¡å¼ã€ç« èŠ‚")


class MultiAgentEngine:
    """
    OpenClaw åŸç”Ÿ Multi-Agent å¼•æ“
    
    é€šè¿‡ `openclaw agent` CLI å¹¶è¡Œè§¦å‘å¤šä¸ª Agentï¼Œ
    æ”¶é›†ç»“æœåè¿›è¡Œèšåˆè¾“å‡ºã€‚
    """

    def __init__(
        self,
        max_concurrent: int = 5,
        continue_on_error: bool = True,
        verbose: bool = False
    ):
        self.max_concurrent = max_concurrent
        self.continue_on_error = continue_on_error
        self.verbose = verbose

    def _resolve_model(self, model_alias: str) -> str:
        """å°†åˆ«åè§£æä¸º OpenClaw model idï¼ŒNone è¡¨ç¤ºä½¿ç”¨ç”¨æˆ·é»˜è®¤æ¨¡å‹
        è§£æé¡ºåºï¼š
        1. è§’è‰²åˆ«åï¼ˆresearcher/writer ç­‰ï¼‰â†’ æ¨¡å‹åˆ«å
        2. æ¨¡å‹åˆ«åï¼ˆfast/smart/bestï¼‰â†’ Noneï¼ˆç”¨æˆ·é»˜è®¤ï¼‰æˆ–å…·ä½“ model id
        3. å…¶ä»–å­—ç¬¦ä¸² â†’ ç›´æ¥å½“ model id é€ä¼ 
        """
        # å¦‚æœæ˜¯è§’è‰²åï¼Œå…ˆæ˜ å°„åˆ°æ¨¡å‹åˆ«å
        if model_alias in ROLE_MODEL_MAP:
            model_alias = ROLE_MODEL_MAP[model_alias]
        # åˆ«åè¡¨é‡ŒæŸ¥ï¼ŒNone è¡¨ç¤ºèµ°ç”¨æˆ·é»˜è®¤
        if model_alias in MODEL_ALIASES:
            return MODEL_ALIASES[model_alias]  # å¯èƒ½æ˜¯ None
        # ä¸åœ¨åˆ«åè¡¨é‡Œï¼Œå½“ä½œçœŸå® model id é€ä¼ 
        return model_alias

    def _run_agent(self, task: AgentTask) -> AgentResult:
        """
        é€šè¿‡ openclaw agent CLI æ‰§è¡Œå•ä¸ªå­ä»»åŠ¡
        """
        label = task.label or task.session_id[:8]
        model_id = self._resolve_model(task.model)

        # æ„å»ºå®Œæ•´ promptï¼ˆåŠ å…¥è§’è‰²å‰ç¼€ï¼‰
        if task.role and task.role != "assistant":
            full_prompt = f"ä½ ç°åœ¨æ‰®æ¼”çš„è§’è‰²æ˜¯ï¼š{task.role}\n\n{task.task}"
        else:
            full_prompt = task.task

        # æ„å»º CLI å‘½ä»¤
        cmd = [
            "openclaw", "agent",
            "--session-id", task.session_id,
            "--message", full_prompt,
            "--json",
        ]
        if task.thinking != "off":
            cmd += ["--thinking", task.thinking]

        # model_id ä¸º None â†’ ä¸ä¼  --modelï¼Œè®© OpenClaw ç”¨ç”¨æˆ·è‡ªå·±é…ç½®çš„é»˜è®¤æ¨¡å‹
        # model_id æœ‰å€¼  â†’ é€ä¼ ç»™ CLIï¼Œä½¿ç”¨æŒ‡å®šæ¨¡å‹
        env = {**os.environ}
        if model_id:
            env["OPENCLAW_AGENT_MODEL"] = model_id
            logger.info(f"[{label}] å¯åŠ¨ Agent (model={model_id}, thinking={task.thinking})")
        else:
            logger.info(f"[{label}] å¯åŠ¨ Agent (model=ç”¨æˆ·é»˜è®¤, thinking={task.thinking})")

        start_time = time.time()

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=task.timeout,
                env=env
            )
            elapsed = time.time() - start_time

            if result.returncode != 0:
                err = result.stderr.strip() or result.stdout.strip()
                logger.warning(f"[{label}] æ‰§è¡Œå¤±è´¥ ({elapsed:.1f}s): {err[:200]}")
                return AgentResult(
                    label=label, model=task.model, task=task.task,
                    output="", success=False, execution_time=elapsed,
                    error=err
                )

            # è§£æ JSON è¾“å‡ºï¼ˆopenclaw agent --json æ ¼å¼ï¼‰
            output_text = ""
            try:
                data = json.loads(result.stdout)
                # openclaw agent --json çš„æ ‡å‡†è¾“å‡ºæ ¼å¼
                payloads = (
                    data.get("result", {})
                        .get("payloads", [])
                )
                if payloads:
                    output_text = "\n".join(
                        p.get("text", "") for p in payloads if p.get("text")
                    )
                else:
                    # å…œåº•ï¼šå°è¯•å¸¸è§å­—æ®µ
                    output_text = (
                        data.get("reply") or
                        data.get("output") or
                        data.get("text") or
                        result.stdout.strip()
                    )
            except json.JSONDecodeError:
                output_text = result.stdout.strip()

            logger.info(f"[{label}] å®Œæˆ ({elapsed:.1f}s), è¾“å‡º {len(output_text)} å­—ç¬¦")
            return AgentResult(
                label=label, model=task.model, task=task.task,
                output=output_text, success=True, execution_time=elapsed
            )

        except subprocess.TimeoutExpired:
            elapsed = time.time() - start_time
            logger.error(f"[{label}] è¶…æ—¶ ({task.timeout}s)")
            return AgentResult(
                label=label, model=task.model, task=task.task,
                output="", success=False, execution_time=elapsed,
                error=f"è¶…æ—¶ï¼ˆ{task.timeout}sï¼‰"
            )
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"[{label}] å¼‚å¸¸: {e}")
            return AgentResult(
                label=label, model=task.model, task=task.task,
                output="", success=False, execution_time=elapsed,
                error=str(e)
            )

    def run_parallel(self, tasks: List[AgentTask]) -> List[AgentResult]:
        """
        å¹¶è¡Œæ‰§è¡Œå¤šä¸ªä»»åŠ¡ï¼Œæœ€å¤š max_concurrent ä¸ªåŒæ—¶è¿è¡Œ
        æ‰€æœ‰ä»»åŠ¡æ”¶åˆ°ç›¸åŒï¼ˆæˆ–å„è‡ªå®šåˆ¶çš„ï¼‰ä»»åŠ¡æè¿°ï¼ŒåŒæ—¶æ‰§è¡Œ
        """
        logger.info(f"ğŸš€ å¹¶è¡Œæ‰§è¡Œ {len(tasks)} ä¸ªä»»åŠ¡ (max_concurrent={self.max_concurrent})")
        results = []

        with concurrent.futures.ThreadPoolExecutor(
            max_workers=self.max_concurrent
        ) as executor:
            future_map = {
                executor.submit(self._run_agent, t): t
                for t in tasks
            }
            for future in concurrent.futures.as_completed(future_map):
                try:
                    r = future.result()
                    results.append(r)
                except Exception as e:
                    task = future_map[future]
                    logger.error(f"[{task.label}] æœªæ•è·å¼‚å¸¸: {e}")
                    if not self.continue_on_error:
                        raise

        return results

    def run_sequential(
        self,
        tasks: List[AgentTask],
        pass_context: bool = True
    ) -> List[AgentResult]:
        """
        ä¸²è¡Œæ‰§è¡Œä»»åŠ¡ï¼Œå‰ä¸€ä¸ªçš„è¾“å‡ºå¯ä»¥ä½œä¸ºåä¸€ä¸ªçš„ä¸Šä¸‹æ–‡
        """
        logger.info(f"ğŸ“‹ ä¸²è¡Œæ‰§è¡Œ {len(tasks)} ä¸ªä»»åŠ¡")
        results = []
        context = ""

        for i, task in enumerate(tasks):
            if pass_context and context and i > 0:
                task.task = (
                    f"ã€å‰åºä»»åŠ¡è¾“å‡ºã€‘\n{context}\n\n"
                    f"ã€å½“å‰ä»»åŠ¡ã€‘\n{task.task}"
                )
            r = self._run_agent(task)
            results.append(r)
            if r.success:
                context = r.output
            elif not self.continue_on_error:
                logger.error(f"ä¸²è¡Œä»»åŠ¡å¤±è´¥ï¼Œä¸­æ­¢æ‰§è¡Œ")
                break

        return results

    def run_hybrid(
        self,
        research_tasks: List[AgentTask],
        draft_task_template: str,
        num_drafts: int = 3,
        draft_models: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        """
        æ··åˆæ¨¡å¼ï¼šå…ˆå¹¶è¡Œæœç´¢ï¼ˆä¾èµ–å¤–éƒ¨æŒ‡æŒ¥å®˜ï¼‰ï¼Œå†æµæ°´çº¿å¹¶è¡Œç”Ÿæˆå¤šç‰ˆè‰ç¨¿

        Phase 1: å¹¶è¡Œæ‰§è¡Œ research_tasksï¼ˆæœç´¢/è°ƒç ”ï¼‰
        Phase 2: æŠŠ Phase 1 ç»“æœæ³¨å…¥ contextï¼Œå¹¶è¡Œç”Ÿæˆ num_drafts ç‰ˆè‰ç¨¿

        Args:
            research_tasks: Phase 1 è°ƒç ”ä»»åŠ¡åˆ—è¡¨
            draft_task_template: Phase 2 è‰ç¨¿ä»»åŠ¡æ¨¡æ¿ï¼Œç”¨ {research} å ä½ç¬¦æ³¨å…¥è°ƒç ”ç»“æœ
            num_drafts: Phase 2 è‰ç¨¿æ•°é‡ï¼ˆé»˜è®¤ 3ï¼‰
            draft_models: Phase 2 æ¯ä¸ªè‰ç¨¿ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨ï¼ˆé»˜è®¤éƒ½ç”¨ defaultï¼‰

        Returns:
            {"research_results": [...], "draft_results": [...], "stats": {...}}
        """
        logger.info(f"ğŸ”€ æ··åˆæ¨¡å¼å¯åŠ¨: {len(research_tasks)} è°ƒç ”ä»»åŠ¡ â†’ {num_drafts} ç‰ˆè‰ç¨¿")

        # Phase 1: å¹¶è¡Œè°ƒç ”
        logger.info("ğŸ“¡ Phase 1: å¹¶è¡Œè°ƒç ”ä¸­...")
        research_results = self.run_parallel(research_tasks)

        # èšåˆè°ƒç ”ç»“æœ
        research_summary = "\n\n".join([
            f"[{r.label}] {r.output}"
            for r in research_results if r.success
        ])

        if not research_summary:
            logger.warning("Phase 1 è°ƒç ”å…¨éƒ¨å¤±è´¥ï¼Œè·³è¿‡ Phase 2")
            return {
                "research_results": research_results,
                "draft_results": [],
                "stats": {"phase1_ok": 0, "phase2_ok": 0},
            }

        # Phase 2: å¹¶è¡Œç”Ÿæˆå¤šç‰ˆè‰ç¨¿
        logger.info(f"âœï¸  Phase 2: å¹¶è¡Œç”Ÿæˆ {num_drafts} ç‰ˆè‰ç¨¿...")
        if draft_models is None:
            draft_models = ["default"] * num_drafts

        draft_tasks = []
        for i in range(num_drafts):
            model = draft_models[i] if i < len(draft_models) else "default"
            task_text = draft_task_template.format(research=research_summary)
            draft_tasks.append(AgentTask(
                task=task_text,
                model=model,
                role="writer",
                label=f"draft_{i+1}",
                timeout=300,
            ))

        draft_results = self.run_parallel(draft_tasks)

        return {
            "research_results": research_results,
            "draft_results": draft_results,
            "stats": {
                "phase1_ok": sum(1 for r in research_results if r.success),
                "phase1_total": len(research_results),
                "phase2_ok": sum(1 for r in draft_results if r.success),
                "phase2_total": len(draft_results),
            },
        }

    def aggregate(
        self,
        results: List[AgentResult],
        mode: str = "synthesize",
        original_task: str = ""
    ) -> str:
        """
        èšåˆå¤šä¸ªç»“æœ

        mode:
          - concatenate: ç®€å•æ‹¼æ¥
          - synthesize:  ç”Ÿæˆç»¼åˆæ‘˜è¦æ¨¡æ¿ï¼ˆä¾›ä¸» Agent è¿›ä¸€æ­¥å¤„ç†ï¼‰
          - compare:     å¹¶æ’å¯¹æ¯”
          - last:        åªè¿”å›æœ€åä¸€ä¸ªï¼ˆä¸²è¡Œåœºæ™¯ï¼‰
        """
        successful = [r for r in results if r.success]

        if not successful:
            return "âš ï¸ æ‰€æœ‰å­ä»»åŠ¡å‡å¤±è´¥ï¼Œæ— æœ‰æ•ˆç»“æœã€‚"

        if mode == "concatenate":
            parts = []
            for r in successful:
                parts.append(f"### [{r.label}] ({r.model})\n\n{r.output}")
            return "\n\n---\n\n".join(parts)

        elif mode == "compare":
            lines = [f"## æ¨¡å‹å¯¹æ¯”ç»“æœ\n\n**ä»»åŠ¡**: {original_task}\n"]
            for r in results:
                status = "âœ…" if r.success else "âŒ"
                lines.append(
                    f"### {status} {r.model} ({r.label})\n"
                    f"*è€—æ—¶: {r.execution_time:.1f}s*\n\n"
                    + (r.output if r.success else f"é”™è¯¯: {r.error}")
                )
            return "\n\n".join(lines)

        elif mode == "last":
            return successful[-1].output if successful else ""

        else:  # synthesizeï¼ˆé»˜è®¤ï¼‰
            parts = []
            for i, r in enumerate(successful, 1):
                parts.append(f"**å­ä»»åŠ¡ {i}ï¼ˆ{r.label} / {r.model}ï¼‰**:\n{r.output}")
            combined = "\n\n".join(parts)
            return (
                f"## å­ä»»åŠ¡æ±‡æ€»ï¼ˆå…± {len(successful)}/{len(results)} æˆåŠŸï¼‰\n\n"
                f"åŸå§‹ä»»åŠ¡ï¼š{original_task}\n\n"
                f"{combined}\n\n"
                f"---\n\n*è¯·æ ¹æ®ä»¥ä¸Šå­ä»»åŠ¡ç»“æœï¼Œç»¼åˆæ•´ç†æœ€ç»ˆç­”æ¡ˆã€‚*"
            )

    def print_stats(self, results: List[AgentResult]) -> None:
        """è¾“å‡ºæ‰§è¡Œç»Ÿè®¡"""
        total = len(results)
        ok = sum(1 for r in results if r.success)
        total_time = sum(r.execution_time for r in results)
        max_time = max(r.execution_time for r in results) if results else 0

        print("\n" + "=" * 60)
        print("ğŸ“Š Multi-Agent æ‰§è¡Œç»Ÿè®¡")
        print("=" * 60)
        print(f"{'Agent':<20} {'æ¨¡å‹':<15} {'çŠ¶æ€':<6} {'è€—æ—¶':>6}")
        print("-" * 60)
        for r in results:
            status = "âœ…" if r.success else "âŒ"
            print(f"{r.label:<20} {r.model:<15} {status:<6} {r.execution_time:>5.1f}s")
        print("-" * 60)
        print(f"æ€»è®¡: {ok}/{total} æˆåŠŸ | ä¸²è¡Œæ€»æ—¶: {total_time:.1f}s | å¹¶è¡ŒèŠ‚çœçº¦: {total_time - max_time:.1f}s")
        print("=" * 60)
