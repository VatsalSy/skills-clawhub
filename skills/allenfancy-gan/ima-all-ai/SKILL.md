---
name: IMA Studio
version: 1.0.3
category: file-generation
author: IMA Studio (imastudio.com)
keywords: imastudio, ai creation, multimodal
argument-hint: "[text prompt, image URL, or music description]"
description: >
  Use for any IMA AI content generation: images, videos, and music via IMA Open API.
  IMPORTANT ‚Äî Default model selection rule: always recommend the NEWEST and most POPULAR model,
  NOT the cheapest. Defaults: image ‚Üí SeeDream 4.5 (doubao-seedream-4.5, 5pts);
  image budget ‚Üí Nano Banana2 (gemini-3.1-flash-image, 4pts for 512px);
  video text_to_video ‚Üí Wan 2.6 (wan2.6-t2v, 25pts) ‚Äî most popular, balanced cost;
  video image_to_video ‚Üí Wan 2.6 (wan2.6-i2v, 25pts);
  music ‚Üí Suno sonic (25pts).
  Production models (2026-02-27) ‚Äî Image text_to_image (3): SeeDream 4.5, Nano Banana2, Nano Banana Pro.
  Image image_to_image (3): SeeDream 4.5, Nano Banana2, Nano Banana Pro.
  Video text_to_video (14): Wan 2.6, Hailuo 2.0/2.3, Vidu Q2, SeeDance 1.5 Pro, Sora 2 Pro,
  Kling O1/2.6, Google Veo 3.1, Pixverse V3.5-V5.5.
  Video image_to_video (14): Wan 2.6, Hailuo 2.0/2.3, Vidu Q2 Pro, SeeDance 1.5 Pro, Sora 2 Pro,
  Kling O1/2.6, Google Veo 3.1, Pixverse V3.5-V5.5.
  Video first_last_frame_to_video (10): Hailuo 2.0, Vidu Q2 Pro, Kling O1/2.6,
  Google Veo 3.1, Pixverse V3.5-V5.5.
  Video reference_image_to_video (9): Vidu Q2, Kling O1, Google Veo 3.1, Pixverse (all versions).
  Music text_to_music (3): Suno sonic/sonic-v5, DouBao BGM, DouBao Song.
  Use this all-in-one skill when a task spans multiple media types; use the focused
  ima-image-ai / ima-video-ai / ima-voice-ai skills for single-media workflows.
  Requires an ima_* API key.
---

# IMA AI Creation

## ‚öôÔ∏è How This Skill Works

**For transparency:** This skill uses a bundled Python script (`scripts/ima_create.py`) to call the IMA Open API. The script:
- Sends your prompt to **two IMA-owned domains** (see "Network Endpoints" below)
- Uses `--user-id` **only locally** as a key for storing your model preferences
- Returns image/video/music URLs when generation is complete

**What gets sent to IMA servers:**
- ‚úÖ Your prompt/description (image/video/music)
- ‚úÖ Model selection (SeeDream/Wan/Suno/etc.)
- ‚úÖ Generation parameters (size, duration, style, etc.)
- ‚ùå NO API key in prompts (key is used for authentication only)
- ‚ùå NO user_id (it's only used locally)

**What's stored locally:**
- `~/.openclaw/memory/ima_prefs.json` - Your model preferences (< 1 KB)
- `~/.openclaw/logs/ima_skills/` - Generation logs (auto-deleted after 7 days)
- See [SECURITY.md](SECURITY.md) for complete privacy policy

---

## üåê Network Endpoints Used

| Domain | Owner | Purpose | Data Sent | Privacy |
|--------|-------|---------|-----------|---------|
| `api.imastudio.com` | IMA Studio | Main API (product list, task creation, task polling) | Prompts, model IDs, generation params, **your API key** | Standard HTTPS, data processed for AI generation |
| `imapi.liveme.com` | IMA Studio | Image/Video upload service (presigned URL generation) | **Your API key**, file metadata (MIME type, extension) | Standard HTTPS, used for image/video tasks only |
| `*.aliyuncs.com`, `*.esxscloud.com` | Alibaba Cloud (OSS) | Image/video storage (file upload, CDN delivery) | Raw image/video bytes (via presigned URL, **NO API key**) | IMA-managed OSS buckets, presigned URLs expire after 7 days |

**Key Points:**
- **Music tasks** (`text_to_music`) only use `api.imastudio.com`.
- **Image/video tasks** require `imapi.liveme.com` to obtain presigned URLs for uploading input images.
- Your API key is sent to **both `api.imastudio.com` and `imapi.liveme.com`** (both owned by IMA Studio).
- Verify network calls: `tcpdump -i any -n 'host api.imastudio.com or host imapi.liveme.com'` (see [SECURITY.md](SECURITY.md)).

---

## ‚ö†Ô∏è Credential Security Notice

**Your API key is sent to both IMA-owned domains:**
1. `Authorization: Bearer ima_xxx...` ‚Üí `api.imastudio.com` (main API)
2. Query param `appUid=ima_xxx...` ‚Üí `imapi.liveme.com` (upload service)

**Security best practices:**
- üß™ **Use test keys for experiments:** Generate a separate API key for testing.
- üîç **Monitor usage:** Check `https://imastudio.com/dashboard` for unauthorized activity.
- ‚è±Ô∏è **Rotate keys:** Regenerate your API key periodically (monthly recommended).
- üìä **Review logs:** Check `~/.openclaw/logs/ima_skills/` for unexpected API calls.

**Why two domains?** IMA Studio uses a microservices architecture:
- **`api.imastudio.com`**: Core AI generation API
- **`imapi.liveme.com`**: Specialized image/video upload service (shared infrastructure)

Both domains are operated by IMA Studio. The same API key grants access to both services.

### Agent Execution (Internal Reference)

> **Note for users:** You can review the script source at `scripts/ima_create.py` anytime.  
> The agent uses this script to simplify API calls. **Music tasks** use only `api.imastudio.com`, while **image/video tasks** also call `imapi.liveme.com` for file uploads (see "Network Endpoints" above).

Use the bundled script internally for all task types ‚Äî it ensures correct parameter construction:

```bash
# ‚îÄ‚îÄ‚îÄ Image Generation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# Basic text-to-image (default model)
python3 {baseDir}/scripts/ima_create.py \
  --api-key $IMA_API_KEY --task-type text_to_image \
  --model-id doubao-seedream-4.5 --prompt "a cute puppy on grass, photorealistic" \
  --user-id {user_id} --output-json

# Text-to-image with size override (Nano Banana2)
python3 {baseDir}/scripts/ima_create.py \
  --api-key $IMA_API_KEY --task-type text_to_image \
  --model-id gemini-3.1-flash-image --prompt "city skyline at sunset, 4K" \
  --size 2k --user-id {user_id} --output-json

# Image-to-image with input URL
python3 {baseDir}/scripts/ima_create.py \
  --api-key $IMA_API_KEY --task-type image_to_image \
  --model-id doubao-seedream-4.5 --prompt "turn into oil painting style" \
  --input-images https://example.com/photo.jpg --user-id {user_id} --output-json

# ‚îÄ‚îÄ‚îÄ Video Generation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# Basic text-to-video (default model, 5s 720P)
python3 {baseDir}/scripts/ima_create.py \
  --api-key $IMA_API_KEY --task-type text_to_video \
  --model-id wan2.6-t2v --prompt "a puppy dancing happily, cinematic" \
  --user-id {user_id} --output-json

# Text-to-video with extra params (10s 1080P)
python3 {baseDir}/scripts/ima_create.py \
  --api-key $IMA_API_KEY --task-type text_to_video \
  --model-id wan2.6-t2v --prompt "dramatic ocean waves, sunset" \
  --extra-params '{"duration":10,"resolution":"1080P","aspect_ratio":"16:9"}' \
  --user-id {user_id} --output-json

# Image-to-video (animate static image)
python3 {baseDir}/scripts/ima_create.py \
  --api-key $IMA_API_KEY --task-type image_to_video \
  --model-id wan2.6-i2v --prompt "camera slowly zooms in, gentle movement" \
  --input-images https://example.com/photo.jpg --user-id {user_id} --output-json

# First-last frame video (two images)
python3 {baseDir}/scripts/ima_create.py \
  --api-key $IMA_API_KEY --task-type first_last_frame_to_video \
  --model-id kling-video-o1 --prompt "smooth transition between frames" \
  --input-images https://example.com/frame1.jpg https://example.com/frame2.jpg \
  --user-id {user_id} --output-json

# ‚îÄ‚îÄ‚îÄ Music Generation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# Basic text-to-music (Suno default)
python3 {baseDir}/scripts/ima_create.py \
  --api-key $IMA_API_KEY --task-type text_to_music \
  --model-id sonic --prompt "upbeat electronic music, 120 BPM, no vocals" \
  --user-id {user_id} --output-json

# Music with custom lyrics (Suno custom mode)
python3 {baseDir}/scripts/ima_create.py \
  --api-key $IMA_API_KEY --task-type text_to_music \
  --model-id sonic --prompt "pop ballad, emotional" \
  --extra-params '{"custom_mode":true,"lyrics":"Your custom lyrics here...","vocal_gender":"female"}' \
  --user-id {user_id} --output-json

# Background music (DouBao BGM)
python3 {baseDir}/scripts/ima_create.py \
  --api-key $IMA_API_KEY --task-type text_to_music \
  --model-id GenBGM --prompt "relaxing ambient music for meditation" \
  --user-id {user_id} --output-json
```

The script outputs JSON with `url`, `model_name`, `credit` ‚Äî use these values in the UX protocol messages below. The script internals (product list query, parameter construction, polling) are invisible to users.

---

## Overview

Call IMA Open API to create AI-generated content. All endpoints require an `ima_*` API key. The core flow is: **query products ‚Üí create task ‚Üí poll until done**.

---

## üîí Security & Transparency Policy

> **This skill is community-maintained and open for inspection.**

### ‚úÖ What Users CAN Do

**Full transparency:**
- ‚úÖ **Review all source code**: Check `scripts/ima_create.py` and `ima_logger.py` anytime
- ‚úÖ **Verify network calls**: Music tasks use `api.imastudio.com` only; image/video tasks also use `imapi.liveme.com` (see "Network Endpoints" section)
- ‚úÖ **Inspect local data**: View `~/.openclaw/memory/ima_prefs.json` and log files
- ‚úÖ **Control privacy**: Delete preferences/logs anytime, or disable file writes (see below)

**Configuration allowed:**
- ‚úÖ **Set API key** in environment or agent config:
  - Environment variable: `export IMA_API_KEY=ima_your_key_here`
  - OpenClaw/MCP config: Add `IMA_API_KEY` to agent's environment configuration
  - Get your key at: https://imastudio.com
- ‚úÖ **Use scoped/test keys**: Test with limited API keys, rotate after testing
- ‚úÖ **Disable file writes**: Make prefs/logs read-only or symlink to `/dev/null`

**Data control:**
- ‚úÖ **View stored data**: `cat ~/.openclaw/memory/ima_prefs.json`
- ‚úÖ **Delete preferences**: `rm ~/.openclaw/memory/ima_prefs.json` (resets to defaults)
- ‚úÖ **Delete logs**: `rm -rf ~/.openclaw/logs/ima_skills/` (auto-cleanup after 7 days anyway)
- ‚úÖ **Review security**: See [SECURITY.md](SECURITY.md) for complete privacy policy

### ‚ö†Ô∏è Advanced Users: Fork & Modify

If you need to modify this skill for your use case:
1. **Fork the repository** (don't modify the original)
2. **Update your fork** with your changes
3. **Test thoroughly** with limited API keys
4. **Document your changes** for troubleshooting

**Note:** Modified skills may break API compatibility or introduce security issues. Official support only covers the unmodified version.

### ‚ùå What to AVOID (Security Risks)

**Actions that could compromise security:**
- ‚ùå Sharing API keys publicly or in skill files
- ‚ùå Modifying API endpoints to unknown servers
- ‚ùå Disabling SSL/TLS certificate verification
- ‚ùå Logging sensitive user data (prompts, IDs, etc.)
- ‚ùå Bypassing authentication or billing mechanisms

**Why this matters:**
1. **API Compatibility**: Skill logic aligns with IMA Open API schema
2. **Security**: Malicious modifications could leak credentials or bypass billing
3. **Support**: Modified skills may not be supported
4. **Community**: Breaking changes affect all users

### üìã Privacy & Data Handling Summary

**What this skill does with your data:**

| Data Type | Sent to IMA? | Stored Locally? | User Control |
|-----------|-------------|-----------------|--------------|
| Prompts (image/video/music) | ‚úÖ Yes (required for generation) | ‚ùå No | None (required) |
| API key | ‚úÖ Yes (authentication header) | ‚ùå No | Set via env var |
| user_id (optional CLI arg) | ‚ùå **Never** (local preference key only) | ‚úÖ Yes (as prefs file key) | Change `--user-id` value |
| Model preferences | ‚ùå No | ‚úÖ Yes (~/.openclaw) | Delete anytime |
| Generation logs | ‚ùå No | ‚úÖ Yes (~/.openclaw) | Auto-cleanup 7 days |

**Privacy recommendations:**
1. **Use test/scoped API keys** for initial testing
2. **Note**: `--user-id` is **never sent to IMA servers** - it's only used locally as a key for storing preferences in `~/.openclaw/memory/ima_prefs.json`
3. **Review source code** at `scripts/ima_create.py` to verify network calls (search for `create_task` function)
4. **Rotate API keys** after testing or if compromised

**Get your IMA API key:** Visit https://imastudio.com to register and get started.

### üîß For Skill Maintainers Only

**Version control:**
- All changes must go through Git with proper version bumps (semver)
- CHANGELOG.md must document all changes
- Production deployments require code review

Â¶ÇÊûú‰Ω†ÈúÄË¶ÅÂÆöÂà∂ÂäüËÉΩÔºåËØ∑Ôºö
1. Fork Ëøô‰∏™ Skill ÂàõÂª∫ÁßÅÊúâÁâàÊú¨Ôºà‰∏ç‰øùËØÅÂÖºÂÆπÊÄßÔºâ
2. ÊàñËÄÖËÅîÁ≥ª IMA ÊäÄÊúØÊîØÊåÅÁî≥ËØ∑‰ºÅ‰∏öÂÆöÂà∂
```

### üîß For Skill Maintainers Only

**Version control:**
- All changes must go through Git with proper version bumps (semver)
- CHANGELOG.md must document all changes
- Production deployments require code review

**File checksums (optional):**
```bash
# Verify skill integrity
sha256sum SKILL.md scripts/ima_create.py
```

If users report issues, verify file integrity first.

---

## üß† User Preference Memory

> User preferences **override** recommended defaults across ALL task types.  
> If a user has generated before, use their preferred model ‚Äî not the system default.

### Storage: `~/.openclaw/memory/ima_prefs.json`

Single file, shared across all IMA skills:

```json
{
  "user_{user_id}": {
    "text_to_image":             { "model_id": "doubao-seedream-4.5", "model_name": "SeeDream 4.5",    "credit": 5,  "last_used": "2026-02-27T03:07:27Z" },
    "image_to_image":            { "model_id": "doubao-seedream-4.5", "model_name": "SeeDream 4.5",    "credit": 5,  "last_used": "2026-02-27T03:07:27Z" },
    "text_to_video":             { "model_id": "wan2.6-t2v",           "model_name": "Wan 2.6",         "credit": 25, "last_used": "2026-02-27T10:00:00Z" },
    "image_to_video":            { "model_id": "wan2.6-i2v",          "model_name": "Wan 2.6",         "credit": 25, "last_used": "2026-02-27T10:00:00Z" },
    "first_last_frame_to_video": { "model_id": "kling-video-o1",      "model_name": "Kling O1",        "credit": 48, "last_used": "2026-02-26T08:00:00Z" },
    "reference_image_to_video":  { "model_id": "kling-video-o1",      "model_name": "Kling O1",        "credit": 48, "last_used": "2026-02-26T08:00:00Z" },
    "text_to_music":             { "model_id": "sonic",               "model_name": "Suno",            "credit": 25, "last_used": "2026-02-26T06:00:00Z" }
  }
}
```

If the file or key doesn't exist, fall back to the ‚≠ê Recommended Defaults below.

---

### Model Selection Priority (Strict Order)

```
1. User explicitly specifies a model in this message
      ‚Üí use it, save as new preference, confirm if different from old preference
2. User has a saved preference for this task type
      ‚Üí use it, mention "Ê†πÊçÆ‰Ω†ÁöÑ‰ΩøÁî®‰π†ÊÉØ"
3. No preference exists
      ‚Üí use ‚≠ê Recommended Default, save after success
```

---

### When to Read (Before Every Generation)

```python
import json, os

prefs_path = os.path.expanduser("~/.openclaw/memory/ima_prefs.json")
try:
    with open(prefs_path) as f:
        prefs = json.load(f)
    user_pref = prefs.get(f"user_{user_id}", {}).get(task_type)
except (FileNotFoundError, json.JSONDecodeError):
    user_pref = None

if user_pref:
    model_id   = user_pref["model_id"]
    model_name = user_pref["model_name"]
    credit     = user_pref["credit"]
    source     = "preference"   # pre-generation message: "Ê†πÊçÆ‰Ω†ÁöÑ‰ΩøÁî®‰π†ÊÉØ"
else:
    model_id, model_name, credit = RECOMMENDED_DEFAULTS[task_type]
    source = "default"
```

### When to Write (After Every Successful Generation)

```python
os.makedirs(os.path.dirname(prefs_path), exist_ok=True)
try:
    with open(prefs_path) as f:
        prefs = json.load(f)
except (FileNotFoundError, json.JSONDecodeError):
    prefs = {}

from datetime import datetime, timezone
prefs.setdefault(f"user_{user_id}", {})[task_type] = {
    "model_id":   model_id,
    "model_name": model_name,
    "credit":     credit,
    "last_used":  datetime.now(timezone.utc).isoformat(),
}
with open(prefs_path, "w") as f:
    json.dump(prefs, f, ensure_ascii=False, indent=2)
```

### When to Update (User Explicitly Changes Model)

| User Says | Action |
|-----------|--------|
| `Áî®XXX` / `Êç¢ÊàêXXX` / `ÊîπÁî®XXX` / `use XXX` | Use that model this time AND save as new preference |
| `‰ª•ÂêéÈÉΩÁî®XXX` / `ÈªòËÆ§Áî®XXX` / `always use XXX` | Save preference + confirm: `‚úÖ Â∑≤ËÆ∞‰ΩèÔºÅ‰ª•Âêé [Á±ªÂûã] ÁîüÊàêÈªòËÆ§Áî® [XXX]` |
| `Êç¢‰∏™Ê®°Âûã` / `try another model` | Show top 3 alternatives, let user pick; save chosen |
| `Áî®ÊúÄÂ•ΩÁöÑ` / `best quality` | Use highest-quality model for this type; save preference |
| `Áî®‰æøÂÆúÁöÑ` / `cheapest` | Use lowest-cost model; only save if user adds "‰ª•ÂêéÈÉΩÁî®" |
| `Ê∏ÖÈô§ÊàëÁöÑÂÅèÂ•Ω` / `reset preference` | Delete `user_{user_id}.{task_type}` from prefs file; confirm |

### Pre-Generation Notification (with preference)

When using a saved preference, mention it naturally:

```
üé® Ê†πÊçÆ‰Ω†ÁöÑ‰ΩøÁî®‰π†ÊÉØÔºåÂ∞ÜÁî® [Model Name] Â∏Æ‰Ω†ÁîüÊàê‚Ä¶
‚Ä¢ Ê®°ÂûãÔºö[Model Name]Ôºà‰Ω†ÁöÑÂ∏∏Áî®Ê®°ÂûãÔºâ
‚Ä¢ È¢ÑËÆ°ËÄóÊó∂Ôºö[X ~ Y Áßí]
‚Ä¢ Ê∂àËÄóÁßØÂàÜÔºö[N pts]
```

### Preference Change Confirmation

When user switches to a different model than their saved preference:

```
üí° ‰Ω†‰πãÂâçÂñúÊ¨¢Áî® [Old Model]ÔºåËøôÊ¨°Êç¢Êàê‰∫Ü [New Model]„ÄÇ
Ë¶ÅÊää [New Model] ËÆæ‰∏∫‰ª•ÂêéÁöÑÈªòËÆ§ÂêóÔºü
ÂõûÂ§ç„ÄåÊòØ„Äç‰øùÂ≠ò / ÂõûÂ§ç„ÄåÂê¶„Äç‰ªÖÊú¨Ê¨°‰ΩøÁî®
```

---

## ‚≠ê Recommended Defaults

> **These are fallback defaults ‚Äî only used when no user preference exists.**  
> **Always default to the newest and most popular model. Do NOT default to the cheapest.**

| Task Type | Default Model | model_id | Cost | Why |
|-----------|--------------|----------|------|-----|
| text_to_image | **SeeDream 4.5** | `doubao-seedream-4.5` | 5 pts | Latest doubao flagship, photorealistic 4K |
| image_to_image | **SeeDream 4.5** | `doubao-seedream-4.5` | 5 pts | Latest, best i2i quality |
| text_to_video | **Wan 2.6** | `wan2.6-t2v` | 25 pts | üî• Most popular t2v, balanced cost. Premium ‚Üí Hailuo 2.3 (38 pts) |
| image_to_video | **Wan 2.6** | `wan2.6-i2v` | 25 pts | üî• Most popular i2v, 1080P |
| first_last_frame_to_video | **Kling O1** | `kling-video-o1` | 48 pts | Newest Kling reasoning model |
| reference_image_to_video | **Kling O1** | `kling-video-o1` | 48 pts | Best reference fidelity |
| text_to_music | **Suno (sonic-v4)** | `sonic` | 25 pts | Latest Suno engine, best quality |

**Quick selection guide (production as of 2026-02-27, sorted by popularity):**
- **Image (3 models available)** ‚Üí **SeeDream 4.5** (5, default); budget ‚Üí Nano Banana2 (4, 512px); premium ‚Üí Nano Banana Pro (10-18)
- **üî• Video from text (most popular)** ‚Üí **Wan 2.6** (25, balanced); premium ‚Üí Hailuo 2.3 (38); budget ‚Üí Vidu Q2 (5)
- **üî• Video from image (most popular)** ‚Üí **Wan 2.6** (25)
- Music ‚Üí **Suno** (25); DouBao BGM/Song (30 each)
- Cheapest ‚Üí Nano Banana2 512px (4) for image; Vidu Q2 (5) for video

**‚ö†Ô∏è Production Image Models (3 available):**
- SeeDream 4.5 (`doubao-seedream-4.5`) ‚Äî 5 pts, default
- Nano Banana Pro (`gemini-3-pro-image`) ‚Äî 10/10/18 pts for 1K/2K/4K

**All other image models mentioned in older documentation are no longer available in production.**

**üåü Parameter Support Notes (All Task Types):**

### Image Models (text_to_image / image_to_image)
- ‚ùå **aspect_ratio**: NOT supported by any production image model (all produce 1:1 or fixed aspect ratio only)
- ‚úÖ **size**: 
  - **Nano Banana2**: 512px, 1K, 2K, 4K (via different `attribute_id`s, 4-13 pts)
  - **Nano Banana Pro**: 1K, 2K, 4K (via different `attribute_id`s, 10-18 pts)
  - **SeeDream 4.5**: Adaptive default only (no size control, 5 pts)
- ‚ùå **8K**: No model supports 8K (max is 4K via Nano Banana Pro)
- ‚ùå **Custom aspect ratios** (7:3, 4:5, etc.): Not supported. Use video models as workaround.
- ‚úÖ **n**: Multiple outputs supported (1-4), credit √ó n

### Video Models (text_to_video / image_to_video / first_last_frame / reference_image)
- ‚úÖ **resolution**: 540P, 720P, 1080P, 2K, 4K (model-dependent, higher res = higher cost)
- ‚úÖ **aspect_ratio**: 16:9, 9:16, 1:1, 4:3 (model-dependent, check `form_config`)
- ‚úÖ **duration**: 4s, 5s, 10s, 15s (model-dependent, longer = higher cost)
- ‚ö†Ô∏è **generate_audio**: Supported by Veo 3.1, Kling O1, Hailuo (check `form_config`)
- ‚úÖ **prompt_extend**: AI-powered prompt enhancement (most models support)
- ‚úÖ **negative_prompt**: Content exclusion (most models support)
- ‚úÖ **shot_type**: Single/multi-shot control (model-dependent)
- ‚úÖ **seed**: Reproducibility control (most models support, -1 = random)
- ‚úÖ **n**: Multiple outputs (1-4), credit √ó n

### Music Models (text_to_music)
- ‚úÖ **custom_mode**: Suno only (enables vocal_gender, lyrics support)
- ‚úÖ **vocal_gender**: Suno only (male/female/mixed, requires custom_mode=True)
- ‚úÖ **lyrics**: Suno only (custom lyrics support, requires custom_mode=True)
- ‚ùå **duration**: Fixed-length output (DouBao ~30s, Suno ~2min, not user-controllable)
- ‚úÖ **n**: Multiple outputs supported (1-2), credit √ó n

### Common Parameter Patterns
- **n (batch generation)**: Supported by ALL models. Cost = base_credit √ó n. Creates n independent resources.
- **seed**: Supported by most models (-1 = random, >0 = reproducible results)
- **prompt_extend**: AI-powered prompt enhancement (video models only)

### Decision Tree: When User Requests Unsupported Features

```
User asks for custom aspect ratio image (e.g. "7:3 landscape")
  ‚Üí ‚ùå Image models don't support custom ratios
  ‚Üí ‚úÖ Solution: "ÂõæÁâáÊ®°Âûã‰∏çÊîØÊåÅËá™ÂÆö‰πâÊØî‰æã„ÄÇÂª∫ËÆÆÁî®ËßÜÈ¢ëÊ®°Âûã(Wan 2.6 t2v)ÁîüÊàê16:9ËßÜÈ¢ëÔºåÁÑ∂ÂêéÊà™ÂèñÈ¶ñÂ∏ß‰Ωú‰∏∫ÂõæÁâá„ÄÇ"

User asks for 8K image
  ‚Üí ‚ùå No model supports 8K
  ‚Üí ‚úÖ Solution: "ÂΩìÂâçÊúÄÈ´òÊîØÊåÅ4KÂàÜËæ®Áéá(Nano Banana ProÔºå18ÁßØÂàÜ)„ÄÇË¶Å‰ΩøÁî®ÂêóÔºü"

User asks for video with audio
  ‚Üí Check model: Veo 3.1 / Kling O1 / Hailuo have generate_audio
  ‚Üí ‚úÖ Solution: "Veo 3.1 Âíå Kling O1 ÊîØÊåÅÈü≥È¢ëÁîüÊàê(ÈúÄÂú®ÂèÇÊï∞‰∏≠ËÆæÁΩÆ generate_audio=True)„ÄÇË¶ÅÁî®Âì™‰∏™Ôºü"

User asks for long music (e.g. "5 minute track")
  ‚Üí ‚ùå Duration not user-controllable
  ‚Üí ‚úÖ Solution: "Suno ÁîüÊàêÁ∫¶2ÂàÜÈíüÈü≥‰πê„ÄÇÈúÄË¶ÅÊõ¥ÈïøÊó∂ÈïøÂèØ‰ª•ÁîüÊàêÂ§öÊÆµÂêéÊãºÊé•„ÄÇ"

User asks for 30s video
  ‚Üí Check model: Most models max 15s
  ‚Üí ‚úÖ Solution: "ÂΩìÂâçÊúÄÈïø15Áßí„ÄÇÂèØÈÄâÊ®°ÂûãÔºöWan 2.6(15s, 75ÁßØÂàÜ), Kling O1(10s, 96ÁßØÂàÜ)„ÄÇ"
```

**When user requests unsupported combinations:**
- Any image model + custom aspect_ratio ‚Üí "‰∏çÊîØÊåÅËá™ÂÆö‰πâÊØî‰æã,Âª∫ËÆÆÁî®ËßÜÈ¢ëÊ®°Âûã(Wan 2.6)ÁîüÊàêÂêéÊà™ÂèñÈ¶ñÂ∏ß"
- Any model + 8K ‚Üí "ÊúÄÈ´òÊîØÊåÅ4K (Nano Banana Pro, 18 pts)"
- Image model + 7:3 ‚Üí "ÂõæÁâáÊ®°Âûã‰∏çÊîØÊåÅ,Âª∫ËÆÆÁî® Wan 2.6 ËßÜÈ¢ëÊ®°Âûã(ÊîØÊåÅ16:9/9:16)ÁîüÊàêÂêéÊà™Â∏ß"
- Video + audio (unsupported model) ‚Üí "ËØ•Ê®°Âûã‰∏çÊîØÊåÅÈü≥È¢ë„ÄÇÂª∫ËÆÆÁî® Veo 3.1 Êàñ Kling O1 (ÊîØÊåÅ generate_audio ÂèÇÊï∞)"
- Music + custom duration ‚Üí "Èü≥‰πêÊó∂ÈïøÁî±Ê®°ÂûãÂõ∫ÂÆö(SunoÁ∫¶2ÂàÜÈíü,DouBaoÁ∫¶30Áßí),Êó†Ê≥ïËá™ÂÆö‰πâ"


---

## üí¨ User Experience Protocol (IM / Feishu / Discord)

> This skill runs inside IM platforms (Feishu, Discord via OpenClaw).  
> Generation takes 10 seconds (music) up to 6 minutes (video). **Never let users wait in silence.**  
> Always follow all 4 steps below, every single time.

### üö´ Never Say to Users

The following are **internal implementation details**. Never mention them in any user-facing message, under any circumstances:

| ‚ùå Never say | ‚úÖ What users care about |
|-------------|--------------------------|
| `ima_create.py` / ËÑöÊú¨ / script | ‚Äî |
| Ëá™Âä®ÂåñËÑöÊú¨ / automation script | ‚Äî |
| Ëá™Âä®Â§ÑÁêÜ‰∫ßÂìÅÂàóË°®Êü•ËØ¢ | ‚Äî |
| Ëá™Âä®Ëß£ÊûêÂèÇÊï∞ÂíåÈÖçÁΩÆ | ‚Äî |
| Êô∫ËÉΩËΩÆËØ¢ / polling / ËΩÆËØ¢ | ‚Äî |
| product list / ÂïÜÂìÅÂàóË°®Êé•Âè£ | ‚Äî |
| attribute_id / model_version / form_config | ‚Äî |
| API Ë∞ÉÁî® / HTTP ËØ∑Ê±Ç | ‚Äî |
| ‰ªª‰ΩïÊäÄÊúØÂèÇÊï∞Âêç | Ê®°ÂûãÂêçÁß∞„ÄÅÁßØÂàÜ„ÄÅÁîüÊàêÊó∂Èó¥ |

User messages must only contain: **model name, estimated/actual time, credits consumed, result URL, and natural language status updates.**

---

### Estimated Generation Time (All Task Types)

| Task Type | Model | Estimated Time | Poll Every | Send Progress Every |
|-----------|-------|---------------|------------|---------------------|
| **text_to_image** | SeeDream 4.5 | 25~60s | 5s | 20s |
| | Nano Banana2 üíö | 20~40s | 5s | 15s |
| | Nano Banana Pro | 60~120s | 5s | 30s |
| **image_to_image** | SeeDream 4.5 | 25~60s | 5s | 20s |
| | Nano Banana2 üíö | 20~40s | 5s | 15s |
| | Nano Banana Pro | 60~120s | 5s | 30s |
| **text_to_video** | Wan 2.6, Hailuo 2.0/2.3, Vidu Q2, Pixverse | 60~120s | 8s | 30s |
| | SeeDance 1.5 Pro, Kling 2.6, Veo 3.1 | 90~180s | 8s | 40s |
| | Kling O1, Sora 2 Pro | 180~360s | 8s | 60s |
| **image_to_video** | Same ranges as text_to_video | ‚Äî | 8s | 40s |
| **first_last_frame / reference** | Kling O1, Veo 3.1 | 180~360s | 8s | 60s |
| **text_to_music** | DouBao BGM / Song | 10~25s | 5s | 10s |
| | Suno (sonic-v5) | 20~45s | 5s | 15s |

`estimated_max_seconds` = upper bound of the range (e.g. 60 for SeeDream 4.5, 40 for Nano Banana2, 120 for Nano Banana Pro, 180 for Kling 2.6, 360 for Kling O1).

---

### Step 1 ‚Äî Pre-Generation Notification

**Before calling the create API**, immediately send:

```
[Emoji] ÂºÄÂßãÁîüÊàê [ÂÜÖÂÆπÁ±ªÂûã]ÔºåËØ∑Á®çÂÄô‚Ä¶
‚Ä¢ Ê®°ÂûãÔºö[Model Name]
‚Ä¢ È¢ÑËÆ°ËÄóÊó∂Ôºö[X ~ Y Áßí]
‚Ä¢ Ê∂àËÄóÁßØÂàÜÔºö[N pts]
```

**Emoji by content type:**
- ÂõæÁâá ‚Üí `üé®`  
- ËßÜÈ¢ë ‚Üí `üé¨`ÔºàÂä†Ê≥®:ËßÜÈ¢ëÁîüÊàêÈúÄË¶ÅËæÉÈïøÊó∂Èó¥ÔºåÊàë‰ºöÂÆöÊó∂Ê±áÊä•ËøõÂ∫¶Ôºâ  
- Èü≥‰πê ‚Üí `üéµ`

**Cost transparency (new requirement):**
- Always show credit cost with model tier context
- For expensive models (>50 pts), offer cheaper alternative proactively
- Examples:
  - Balanced (default): "‰ΩøÁî® Wan 2.6Ôºà25 ÁßØÂàÜÔºåÊúÄÊñ∞ WanÔºâ"
  - Premium (user explicit): "‰ΩøÁî®È´òÁ´ØÊ®°Âûã Kling O1Ôºà48-120 ÁßØÂàÜÔºâÔºåË¥®ÈáèÊúÄ‰Ω≥"
  - Premium (auto-selected): "‰ΩøÁî® Wan 2.6Ôºà25 ÁßØÂàÜÔºâ„ÄÇËã•ÈúÄÊõ¥È´òË¥®ÈáèÂèØÈÄâ Kling O1Ôºà48 ÁßØÂàÜËµ∑Ôºâ"
  - Budget (user asked): "‰ΩøÁî® Vidu Q2Ôºà5 ÁßØÂàÜÔºåÊúÄÁúÅÈí±Ôºâ"

> Adapt language to match the user (Chinese / English). For video, always add a note that it takes longer. For expensive models, always mention cheaper alternatives unless user explicitly requested premium.

---

### Step 2 ‚Äî Progress Updates

Poll the task detail API every `[Poll Every]` seconds per the table.  
Send a progress update every `[Send Progress Every]` seconds.

```
‚è≥ Ê≠£Âú®ÁîüÊàê‰∏≠‚Ä¶ [P]%
Â∑≤Á≠âÂæÖ [elapsed]sÔºåÈ¢ÑËÆ°ÊúÄÈïø [max]s
```

**Progress formula:**
```
P = min(95, floor(elapsed_seconds / estimated_max_seconds * 100))
```

- **Cap at 95%** ‚Äî never reach 100% until the API confirms `success`
- If `elapsed > estimated_max`: freeze at 95%, append `„ÄåÂø´‰∫ÜÔºåÁ®çÁ≠â‰∏Ä‰∏ã‚Ä¶„Äç`
- For video with max=360s: at 120s ‚Üí 33%, at 250s ‚Üí 69%, at 400s ‚Üí 95% (frozen)

---

### Step 3 ‚Äî Success Notification

When task status = `success`, send:

```
‚úÖ [ÂÜÖÂÆπÁ±ªÂûã]ÁîüÊàêÊàêÂäüÔºÅ
‚Ä¢ Ê®°ÂûãÔºö[Model Name]
‚Ä¢ ËÄóÊó∂ÔºöÈ¢ÑËÆ° [X~Y]sÔºåÂÆûÈôÖ [actual]s
‚Ä¢ Ê∂àËÄóÁßØÂàÜÔºö[N pts]

[ÁªìÊûúÈìæÊé•]
```

---

### Step 4 ‚Äî Failure Notification

When task status = `failed` or any API/network error, send:

```
‚ùå [ÂÜÖÂÆπÁ±ªÂûã]ÁîüÊàêÂ§±Ë¥•
‚Ä¢ ÂéüÂõ†Ôºö[natural_language_error_message]
‚Ä¢ Âª∫ËÆÆÊîπÁî®Ôºö
  - [Alt Model 1]Ôºà[ÁâπÁÇπ]Ôºå[N pts]Ôºâ
  - [Alt Model 2]Ôºà[ÁâπÁÇπ]Ôºå[N pts]Ôºâ

ÈúÄË¶ÅÊàëÂ∏Æ‰Ω†Áî®ÂÖ∂‰ªñÊ®°ÂûãÈáçËØïÂêóÔºü
```

**‚ö†Ô∏è CRITICAL: Error Message Translation**

**NEVER show technical error messages to users.** Always translate API errors into natural language:

| Technical Error | ‚ùå Never Say | ‚úÖ Say Instead (Chinese) | ‚úÖ Say Instead (English) |
|----------------|-------------|------------------------|------------------------|
| `"Invalid product attribute"` / `"Insufficient points"` | Invalid product attribute | ÁîüÊàêÂèÇÊï∞ÈÖçÁΩÆÂºÇÂ∏∏ÔºåËØ∑Á®çÂêéÈáçËØï | Configuration error, please try again later |
| `Error 6006` (credit mismatch) | Error 6006 | ÁßØÂàÜËÆ°ÁÆóÂºÇÂ∏∏ÔºåÁ≥ªÁªüÊ≠£Âú®‰øÆÂ§ç | Points calculation error, system is fixing |
| `Error 6010` (attribute_id mismatch) | Attribute ID does not match | Ê®°ÂûãÂèÇÊï∞‰∏çÂåπÈÖçÔºåËØ∑Â∞ùËØïÂÖ∂‰ªñÊ®°Âûã | Model parameters incompatible, try another model |
| `error 400` (bad request) | error 400 / Bad request | ËØ∑Ê±ÇÂèÇÊï∞ÊúâËØØÔºåËØ∑Á®çÂêéÈáçËØï | Invalid request parameters, please try again |
| `resource_status == 2` | Resource status 2 / Failed | ÁîüÊàêËøáÁ®ãÈÅáÂà∞ÈóÆÈ¢òÔºåÂª∫ËÆÆÊç¢‰∏™Ê®°ÂûãËØïËØï | Generation failed, please try another model |
| `status == "failed"` (no details) | Task failed | ËøôÊ¨°ÁîüÊàêÊ≤°ÊàêÂäüÔºåË¶Å‰∏çÊç¢‰∏™Ê®°ÂûãËØïËØïÔºü | Generation unsuccessful, try a different model? |
| `timeout` | Task timed out / Timeout error | ÁîüÊàêÊó∂Èó¥ËøáÈïøÂ∑≤Ë∂ÖÊó∂ÔºåÂª∫ËÆÆÁî®Êõ¥Âø´ÁöÑÊ®°Âûã | Generation took too long, try a faster model |
| Network error / Connection refused | Connection refused / Network error | ÁΩëÁªúËøûÊé•‰∏çÁ®≥ÂÆöÔºåËØ∑Ê£ÄÊü•ÁΩëÁªúÂêéÈáçËØï | Network connection unstable, check network and retry |
| API key invalid | Invalid API key / 401 Unauthorized | API ÂØÜÈí•Êó†ÊïàÔºåËØ∑ËÅîÁ≥ªÁÆ°ÁêÜÂëò | API key invalid, contact administrator |
| Rate limit exceeded | 429 Too Many Requests / Rate limit | ËØ∑Ê±ÇËøá‰∫éÈ¢ëÁπÅÔºåËØ∑Á®çÁ≠âÁâáÂàªÂÜçËØï | Too many requests, please wait a moment |
| Prompt moderation (Sora only) | Content policy violation | ÊèêÁ§∫ËØçÂåÖÂê´ÊïèÊÑüÂÜÖÂÆπÔºåËØ∑‰øÆÊîπÂêéÈáçËØï | Prompt contains restricted content, please modify |
| Model unavailable | Model not available / 503 Service Unavailable | ÂΩìÂâçÊ®°ÂûãÊöÇÊó∂‰∏çÂèØÁî®ÔºåÂª∫ËÆÆÊç¢‰∏™Ê®°Âûã | Model temporarily unavailable, try another model |

**Generic fallback (when error is unknown):**
- Chinese: `ÁîüÊàêËøáÁ®ãÈÅáÂà∞ÈóÆÈ¢òÔºåËØ∑Á®çÂêéÈáçËØïÊàñÊç¢‰∏™Ê®°ÂûãËØïËØï`
- English: `Generation encountered an issue, please try again or use another model`

**Best Practices:**
1. **Focus on user action**: Tell users what to do next, not what went wrong technically
2. **Be reassuring**: Use phrases like "Âª∫ËÆÆÊç¢‰∏™Ê®°ÂûãËØïËØï" instead of "Â§±Ë¥•‰∫Ü"
3. **Avoid blame**: Never say "‰Ω†ÁöÑÊèêÁ§∫ËØçÊúâÈóÆÈ¢ò" ‚Üí say "ÊèêÁ§∫ËØçÈúÄË¶ÅË∞ÉÊï¥‰∏Ä‰∏ã"
4. **Provide alternatives**: Always suggest 1-2 alternative models in the failure message

**Failure fallback by task type:**

| Task Type | Failed Model | First Alt | Second Alt |
|-----------|-------------|-----------|------------|
| text_to_image | SeeDream 4.5 | Nano Banana2 (4pts, fast) | Nano Banana Pro (10-18pts, premium) |
| text_to_image | Nano Banana2 | SeeDream 4.5 (5pts, better quality) | Nano Banana Pro (10-18pts) |
| text_to_image | Nano Banana Pro | SeeDream 4.5 (5pts) | Nano Banana2 (4pts, budget) |
| image_to_image | SeeDream 4.5 | Nano Banana2 (4pts, fast) | Nano Banana Pro (10pts) |
| image_to_image | Nano Banana2 | SeeDream 4.5 (5pts) | Nano Banana Pro (10pts) |
| image_to_image | Nano Banana Pro | SeeDream 4.5 (5pts) | Nano Banana2 (4pts) |
| text_to_video | Kling O1 | Wan 2.6 (25pts) | Vidu Q2 (5pts) |
| text_to_video | Google Veo 3.1 | Kling O1 (48pts) | Sora 2 Pro (122pts) |
| text_to_video | Any | Wan 2.6 (25pts, most popular) | Hailuo 2.0 (5pts) |
| image_to_video | Wan 2.6 | Kling O1 (48pts) | Hailuo 2.0 i2v (25pts) |
| image_to_video | Any | Wan 2.6 (25pts, most popular) | Vidu Q2 Pro (20pts) |
| first_last / reference | Kling O1 | Kling 2.6 (80pts) | Veo 3.1 (70pts+) |
| text_to_music | Suno | DouBao BGM (6pts) | DouBao Song (6pts) |
| text_to_music | DouBao | Suno (21pts) | DouBao BGM/Song (‰∫íÊç¢) |

---

## Supported Models at a Glance

> **Source: production `GET /open/v1/product/list` (2026-02-27).** Model count reduced significantly. Always query product list API at runtime.

### Image Generation (3 models each)

| Category | Name | model_id | Cost |
|----------|------|----------|------|
| **text_to_image** | SeeDream 4.5 üåü | `doubao-seedream-4.5` | 5 pts |
| text_to_image | Nano Banana2 üíö | `gemini-3.1-flash-image` | 4/6/10/13 pts |
| text_to_image | Nano Banana Pro | `gemini-3-pro-image` | 10/10/18 pts |
| **image_to_image** | SeeDream 4.5 üåü | `doubao-seedream-4.5` | 5 pts |
| image_to_image | Nano Banana2 üíö | `gemini-3.1-flash-image` | 4/6/10/13 pts |
| image_to_image | Nano Banana Pro | `gemini-3-pro-image` | 10 pts |

**Nano Banana2 size options**: 512px (4pts), 1K (6pts), 2K (10pts), 4K (13pts)  
**Nano Banana Pro size options**: 1K (10pts), 2K (10pts), 4K (18pts for t2i / 10pts for i2i)

‚ùå **Removed**: SeeDream 3.0/4.0, Nano Banana (gemini-2.5), GPT Image 1.0/1.5, Wan 2.6 t2i/i2i, Midjourney, Imagen 4, SeedEdit 3.0

### Video Generation

| Category | Name | model_id | Cost Range |
|----------|------|----------|-----------|
| **text_to_video (14)** | Wan 2.6 üî• | `wan2.6-t2v` | 25-120 pts |
| | Hailuo 2.3 | `MiniMax-Hailuo-2.3` | 32+ pts |
| | Hailuo 2.0 | `MiniMax-Hailuo-02` | 5+ pts |
| | Vidu Q2 | `viduq2` | 5-70 pts |
| | SeeDance 1.5 Pro | `doubao-seedance-1.5-pro` | 20+ pts |
| | Sora 2 Pro | `sora-2-pro` | 122+ pts |
| | Kling O1 | `kling-video-o1` | 48-120 pts |
| | Kling 2.6 | `kling-v2-6` | 80+ pts |
| | Google Veo 3.1 | `veo-3.1-generate-preview` | 70-330 pts |
| | Pixverse V5.5 / V5 / V4.5 / V4 / V3.5 | `pixverse` | 12-48 pts |
| **image_to_video (14)** | Wan 2.6 üî• | `wan2.6-i2v` | 25-120 pts |
| | Hailuo 2.3 / 2.0 | `MiniMax-Hailuo-2.3/02` | 25-32 pts |
| | Vidu Q2 Pro | `viduq2-pro` | 20-70 pts |
| | SeeDance 1.5 Pro | `doubao-seedance-1.5-pro` | 47+ pts |
| | Sora 2 Pro | `sora-2-pro` | 122+ pts |
| | Kling O1 / 2.6 | `kling-video-o1/v2-6` | 48-120 pts |
| | Google Veo 3.1 | `veo-3.1-generate-preview` | 70-330 pts |
| | Pixverse V5.5-V3.5 | `pixverse` | 12-48 pts |
| **first_last_frame (11)** | Kling O1 üåü | `kling-video-o1` | 48-120 pts |
| | Kling 2.6 | `kling-v2-6` | 80+ pts |
| | Others (9) | Hailuo 2.0, Vidu Q2 Pro, SeeDance 1.5 Pro, Veo 3.1, Pixverse V5.5-V3.5 | ‚Äî |
| **reference_image (6)** | Kling O1 üåü | `kling-video-o1` | 48-120 pts |
| | Google Veo 3.1 | `veo-3.1-generate-preview` | 70-330 pts |
| | Others (4) | Vidu Q2, Pixverse V5.5/V5/V4.5 | ‚Äî |

‚ùå **Removed video models**: Vidu Q2 Turbo (viduq2-turbo), Wan 2.5/2.2 Plus, Kling 1.6/2.1/2.5, Sora 2 (non-Pro), Veo 3.0/3.1 Fast, SeeDance 1.0, Vidu Q1, Hailuo 2.3 Fast
| text_to_video | SeeDance 1.5 Pro / 1.0 Pro | `doubao-seedance-1.5-pro` / `doubao-seedance-1.0-pro` | 16 / 15 pts |
| text_to_video | Sora 2 Pro / Sora 2 | `sora-2-pro` / `sora-2` | 120 / 35 pts |
| text_to_video | Kling O1 / 2.6 / 2.5 Turbo / 1.6 | `kling-video-o1` / `kling-v2-6` / `kling-v2-5-turbo` / `kling-v1-6` | 48 / 80 / 24 / 32 pts |
| text_to_video | Google Veo 3.1 Fast / 3.1 / 3.0 | `veo-3.1-fast-generate-preview` / `veo-3.1-generate-preview` / `veo-3.0-generate-preview` | 55 / 140 / 280 pts |
| text_to_video | Pixverse V3.5‚ÄìV5.5 | `pixverse` | 12 pts |
| image_to_video | Wan 2.6 / 2.6 Flash / 2.5 / 2.2 Plus | `wan2.6-i2v` / `wan2.6-i2v-flash` / `wan2.5-i2v-preview` / `wan2.2-i2v-plus` | 25 / 12 / 12 / 10 pts |
| image_to_video | Kling 2.1 Master | `kling-v2-1-master` | 150 pts |
| first_last_frame_to_video | Kling O1 | `kling-video-o1` | 70 pts |
| reference_image_to_video | Kling O1 / Vidu Q2 / Q1 | `kling-video-o1` / `viduq2` / `viduq1` | 48 / 10 / 25 pts |

### Music Generation

| Category | Name | model_id | Cost | Notes |
|----------|------|----------|------|-------|
| text_to_music | Suno | `sonic` | 25 pts | sonic-v5; custom_mode, lyrics, vocal_gender |
| text_to_music | DouBao BGM | `GenBGM` | 30 pts | Background music |
| text_to_music | DouBao Song | `GenSong` | 30 pts | Song generation |

> Always call `GET /open/v1/product/list?category=<type>` first to get the live `attribute_id` and `form_config` defaults required for task creation.

There are two equivalent route systems serving the same backend logic:

| Route | Auth | Use Case |
|-------|------|----------|
| `/open/v1/` | `Authorization: Bearer ima_*` only | Third-party / agent access |
| `/api/v3/` | Token + API Key (dual auth) | Frontend App |

**This skill documents the `/open/v1/` Open API.** All business logic (credit validation, N-flattening, risk control) runs identically on both paths.

## Environment

Base URL: `https://api.imastudio.com`

Required/recommended headers for all `/open/v1/` endpoints:

| Header | Required | Value | Notes |
|--------|----------|-------|-------|
| `Authorization` | ‚úÖ | `Bearer ima_your_api_key_here` | API key authentication |
| `x-app-source` | ‚úÖ | `ima_skills` | Fixed value ‚Äî identifies skill-originated requests |
| `x_app_language` | recommended | `en` / `zh` | Product label language; defaults to `en` if omitted |

```
Authorization: Bearer ima_your_api_key_here
x-app-source: ima_skills
x_app_language: en
```

---

## üì§ When to Upload Images (Quick Reference)

**The IMA Open API does NOT accept raw bytes or base64 images. All image inputs must be public HTTPS URLs.**

| Task Type | Input Required? | Upload Before Create? | Notes |
|-----------|----------------|----------------------|-------|
| **text_to_image** | ‚ùå No | ‚Äî | Prompt only |
| **image_to_image** | ‚úÖ Yes (1 image) | ‚úÖ Upload first | Single input image |
| **text_to_video** | ‚ùå No | ‚Äî | Prompt only |
| **image_to_video** | ‚úÖ Yes (1 image) | ‚úÖ Upload first | Single input image |
| **first_last_frame_to_video** | ‚úÖ Yes (2 images) | ‚úÖ Upload first | First + last frame |
| **reference_image_to_video** | ‚úÖ Yes (1+ images) | ‚úÖ Upload first | Reference image(s) |
| **text_to_music** | ‚ùå No | ‚Äî | Prompt only |

**Upload flow:**
1. User provides local file path or bytes ‚Üí call `prepare_image_url()` (see section below)
2. User provides HTTPS URL ‚Üí use directly, no upload needed
3. Use the returned CDN URL (`fdl`) as the value for `input_images` / `src_img_url`

**Example workflow (image_to_image):**
```python
# User provides local file
image_url = prepare_image_url("/path/to/photo.jpg", api_key)
# ‚Üí Returns: https://ima-ga.esxscloud.com/webAgent/privite/2026/02/27/..._uuid.jpeg

# Then create task with this URL
create_task(
    task_type="image_to_image",
    input_images=[image_url],  # Use uploaded URL
    prompt="turn into oil painting"
)
```

---

## ‚ö†Ô∏è MANDATORY: Always Query Product List First

> **CRITICAL**: You MUST call `/open/v1/product/list` BEFORE creating any task.  
> The `attribute_id` field is REQUIRED in the create request. If it is `0` or missing, you get:  
> `"Invalid product attribute"` ‚Üí `"Insufficient points"` ‚Üí task fails completely.  
> **NEVER construct a create request from the model table alone. Always fetch the product first.**

### How to get attribute_id (all task types)

```python
# Query product list with the correct category
GET /open/v1/product/list?app=ima&platform=web&category=<task_type>
# task_type: text_to_image | image_to_image | text_to_video | image_to_video |
#            first_last_frame_to_video | reference_image_to_video | text_to_music

# Walk the V2 tree to find your target model (type=3 leaf nodes only)
for group in response["data"]:
    for version in group.get("children", []):
        if version["type"] == "3" and version["model_id"] == target_model_id:
            attribute_id  = version["credit_rules"][0]["attribute_id"]
            credit        = version["credit_rules"][0]["points"]
            model_version = version["id"]    # = version_id / model_version
            model_name    = version["name"]
            form_defaults = {f["field"]: f["value"] for f in version["form_config"]}
            break
```

### Quick Reference: Known attribute_ids

> Pre-queried values for convenience. **Always call the product list at runtime for accuracy.**

| Model | Task Type | model_id | attribute_id | credit | Notes |
|-------|-----------|----------|-------------|--------|-------|
| **text_to_image** |||||| |
| SeeDream 4.5 | text_to_image | `doubao-seedream-4.5` | **2341** | 5 pts | Default, balanced |
| Nano Banana Pro (1K) | text_to_image | `gemini-3-pro-image` | **2399** | 10 pts | 1024√ó1024 |
| Nano Banana Pro (2K) | text_to_image | `gemini-3-pro-image` | **2400** | 10 pts | 2048√ó2048 |
| Nano Banana Pro (4K) | text_to_image | `gemini-3-pro-image` | **2401** | 18 pts | 4096√ó4096 |
| **text_to_video** |||||| |
| Wan 2.6 (720P, 5s) | text_to_video | `wan2.6-t2v` | **2057** | 25 pts | Default, balanced |
| Wan 2.6 (1080P, 5s) | text_to_video | `wan2.6-t2v` | **2058** | 40 pts | ‚Äî |
| Wan 2.6 (720P, 10s) | text_to_video | `wan2.6-t2v` | **2059** | 50 pts | ‚Äî |
| Wan 2.6 (1080P, 10s) | text_to_video | `wan2.6-t2v` | **2060** | 80 pts | ‚Äî |
| Wan 2.6 (720P, 15s) | text_to_video | `wan2.6-t2v` | **2061** | 75 pts | ‚Äî |
| Wan 2.6 (1080P, 15s) | text_to_video | `wan2.6-t2v` | **2062** | 120 pts | ‚Äî |
| Kling O1 (5s, std) | text_to_video | `kling-video-o1` | **2313** | 48 pts | Latest Kling |
| Kling O1 (5s, pro) | text_to_video | `kling-video-o1` | **2314** | 60 pts | ‚Äî |
| Kling O1 (10s, std) | text_to_video | `kling-video-o1` | **2315** | 96 pts | ‚Äî |
| Kling O1 (10s, pro) | text_to_video | `kling-video-o1` | **2316** | 120 pts | ‚Äî |
| **text_to_music** |||||| |
| Suno (sonic-v4) | text_to_music | `sonic` | **2370** | 25 pts | Default |
| DouBao BGM | text_to_music | `GenBGM` | **4399** | 30 pts | ‚Äî |
| DouBao Song | text_to_music | `GenSong` | **4398** | 30 pts | ‚Äî |
| **All others** | any | ‚Äî | ‚Üí query `/open/v1/product/list` | ‚Äî | Always runtime query |

‚ö†Ô∏è **Production warning**: `attribute_id` and `credit` values change frequently in production. Always call `/open/v1/product/list` at runtime; above table is pre-queried reference only (2026-02-27).

### Common Mistakes (and resulting errors)

| Mistake | Error |
|---------|-------|
| `attribute_id` is `0` or missing | `"Invalid product attribute"` + `"Insufficient points"` |
| `attribute_id` outdated (production changed) | Same errors; always query product list first |
| **`attribute_id` doesn't match parameter combination** | **Error 6010: "Attribute ID does not match the calculated rule"** |
| `prompt` at outer `parameters[]` level | Prompt ignored; wrong routing |
| `cast` missing from inner `parameters.parameters` | Billing validation failure |
| `credit` value wrong or missing | Error 6006 |
| `model_name` / `model_version` missing | Wrong backend routing |
| Skipped product list, used table values directly | All of the above |

**‚ö†Ô∏è Critical for Google Veo 3.1 and multi-rule models:**

Models like Google Veo 3.1 have **multiple `credit_rules`**, each with a different `attribute_id` for different parameter combinations:
- `720p + 4s + optimized` ‚Üí attribute_id A
- `720p + 8s + optimized` ‚Üí attribute_id B  
- `4K + 4s + high` ‚Üí attribute_id C

The script automatically selects the correct `attribute_id` by matching your parameters (`duration`, `resolution`, `compression_quality`, `generate_audio`) against each rule's `attributes`. If the match fails, you get error 6010.

**Fix**: The bundled script now checks these video-specific parameters for smart credit_rule selection. Always use the script, not manual API construction.

---

## Core Flow

```
1. GET /open/v1/product/list?app=ima&platform=web&category=<type>
   ‚Üí REQUIRED: Get attribute_id, credit, model_version, model_name, form_config defaults

[If input image required]
2. Upload image ‚Üí get public HTTPS URL
   ‚Üí See "Image Upload" section below

3. POST /open/v1/tasks/create
   ‚Üí Must include: attribute_id, model_name, model_version, credit, cast, prompt (nested!)

4. POST /open/v1/tasks/detail  {"task_id": "..."}
   ‚Üí Poll until medias[].resource_status == 1
   ‚Üí Extract url from completed media
```

---

## Image Upload (Required Before Image Tasks)

**The IMA Open API does NOT accept raw bytes or base64 images. All image inputs must be public HTTPS URLs.**

When a user provides an image (local file, bytes, base64), you must upload it first and get a URL. This is exactly what the IMA frontend does before every image task.

### Real Upload Flow (from IMA Frontend Source)

The frontend uses a **two-step presigned URL flow** via the IM platform:

```
Step 1: GET /api/rest/oss/getuploadtoken   ‚Üí returns { ful, fdl }
          ful = presigned PUT URL (upload destination, expires ~7 days)
          fdl = final CDN download URL (use this as input_images value)

Step 2: PUT {ful}  with raw image bytes + Content-Type header
          ‚Üí image is stored in Aliyun OSS: zhubite-imagent-bot.oss-us-east-1.aliyuncs.com
          ‚Üí accessible via CDN: https://ima-ga.esxscloud.com/...
```

### Step 1: Get Upload Token

```
GET https://imapi-qa.liveme.com/api/rest/oss/getuploadtoken
```

Required query parameters (11 total ‚Äî sourced directly from frontend `generateUploadInfo`):

| Parameter | Example | Description |
|-----------|---------|-------------|
| `appUid` | `ima_xxx...` | **Use IMA API key directly** ‚Äî no separate login needed |
| `appId` | `webAgent` | App identifier (fixed) |
| `appKey` | `32jdskjdk320eew` | App secret (fixed, used for `sign` generation) |
| `cmimToken` | `ima_xxx...` | **Use IMA API key directly** ‚Äî same as appUid |
| `sign` | `117CF6CF...` | IM auth HMAC: `SHA1("webAgent\|32jdskjdk320eew\|{timestamp}\|{nonce}").upper()` |
| `timestamp` | `1772042430` | Unix timestamp (seconds), generated per request |
| `nonce` | `CxI1FLI5ajLJZ1jlxZmeg` | Random nonce string, generated per request |
| `fService` | `privite` | Fixed: storage service type |
| `fType` | `picture` | `picture` for images, `video`, `audio` |
| `fSuffix` | `jpeg` | File extension: `jpeg`, `png`, `mp4`, `mp3` |
| `fContentType` | `image/jpeg` | MIME type of the file |

> **ÁÆÄÂåñËÆ§ËØÅ**ÔºöÁõ¥Êé•‰ΩøÁî® IMA API key Â°´ÂÖÖ `appUid` Âíå `cmimToken` ÂèÇÊï∞ÔºåÊó†ÈúÄÂçïÁã¨Ëé∑ÂèñÂá≠ËØÅ„ÄÇ

Response:
```json
{
  "ful": "https://zhubite-imagent-bot.oss-us-east-1.aliyuncs.com/webAgent/privite/2026/02/26/..._uuid.jpeg?Expires=...&OSSAccessKeyId=...&Signature=...",
  "fdl": "https://ima-ga.esxscloud.com/webAgent/privite/2026/02/26/..._uuid.jpeg",
  "ful_expire": "...",
  "fdl_expire": "...",
  "fdl_key": "..."
}
```

### Step 2: Upload Image via Presigned URL

```
PUT {ful}
Content-Type: image/jpeg
Body: [raw image bytes]
```

No auth headers needed ‚Äî the presigned URL already encodes the credentials.

### Step 3: Use `fdl` as the Image URL

After the PUT succeeds, use `fdl` (the CDN URL) as the value for `input_images` / `src_img_url`.

### Python Implementation

```python
import hashlib, time, uuid, requests, mimetypes

# ‚îÄ‚îÄ üåê IMA Upload Service Endpoint (IMA-owned, for image/video uploads) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
IMA_IM_BASE = "https://imapi-qa.liveme.com"   # prod: https://imapi.liveme.com

# ‚îÄ‚îÄ üîë Hardcoded APP_KEY (Public, Shared Across All Users) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# This APP_KEY is a PUBLIC identifier used by IMA Studio's image/video upload 
# service. It is NOT a secret‚Äîit's intentionally shared across all users and 
# embedded in the IMA web frontend. This key is used to generate HMAC signatures 
# for upload token requests, but your IMA API key (ima_xxx...) is the ACTUAL 
# authentication credential. Think of APP_KEY as a "client ID" rather than a 
# "client secret."
#
# ‚ö†Ô∏è Security Note: Your ima_xxx... API key is the sensitive credential. It is 
# sent to imapi.liveme.com as query parameters (appUid, cmimToken). Always use 
# test keys for experiments and rotate your API key regularly.
#
# üìñ See SECURITY.md for complete disclosure and network verification guide.
APP_ID    = "webAgent"
APP_KEY   = "32jdskjdk320eew"   # Public shared key (used for HMAC sign generation)
APP_UID   = "<your_app_uid>"    # POST /api/v3/login/app ‚Üí data.user_id
APP_TOKEN = "<your_app_token>"  # POST /api/v3/login/app ‚Üí data.token


def _gen_sign() -> tuple[str, str, str]:
    """Generate per-request (sign, timestamp, nonce)."""
    nonce = uuid.uuid4().hex[:21]
    ts    = str(int(time.time()))
    raw   = f"{APP_ID}|{APP_KEY}|{ts}|{nonce}"
    sign  = hashlib.sha1(raw.encode()).hexdigest().upper()
    return sign, ts, nonce


def get_upload_token(app_uid: str, app_token: str,
                     suffix: str, content_type: str) -> dict:
    """Step 1: Get presigned upload URL from IMA's upload service.
    
    Calls GET imapi.liveme.com/api/rest/oss/getuploadtoken with exactly 11 params.
    Returns: { "ful": "<presigned PUT URL>", "fdl": "<CDN download URL>" }
    
    Args:
        app_uid: Your IMA API key (ima_xxx...), used as appUid parameter
        app_token: Your IMA API key (ima_xxx...), used as cmimToken parameter
        suffix: File extension (jpeg, png, mp4, mp3)
        content_type: MIME type (image/jpeg, video/mp4, etc.)
    
    Security Note:
        Your IMA API key (ima_xxx...) is sent to imapi.liveme.com as query 
        parameters (appUid, cmimToken). This is IMA Studio's image/video upload 
        service, separate from the main api.imastudio.com API. Both domains are 
        owned by IMA Studio‚Äîthis is part of IMA's microservices architecture.
        
        Why two domains?
        - api.imastudio.com: Core AI generation API (product list, task creation)
        - imapi.liveme.com: Specialized upload service (presigned URL generation)
        
        Your API key grants access to both services. For security verification, 
        see SECURITY.md section "Network Traffic Verification."
    """
    sign, ts, nonce = _gen_sign()
    r = requests.get(
        f"{IMA_IM_BASE}/api/rest/oss/getuploadtoken",
        params={
            # App Key params
            "appUid":       app_uid,       # APP_UID
            "appId":        APP_ID,
            "appKey":       APP_KEY,
            "cmimToken":    app_token,     # APP_TOKEN
            "sign":         sign,
            "timestamp":    ts,
            "nonce":        nonce,
            # File params
            "fService":     "privite",     # fixed
            "fType":        "picture",     # picture / video / audio
            "fSuffix":      suffix,        # jpeg / png / mp4 / mp3
            "fContentType": content_type,
        },
    )
    r.raise_for_status()
    return r.json()["data"]


def upload_image_to_oss(image_bytes: bytes, content_type: str, ful: str) -> None:
    """Step 2: PUT image bytes to the presigned OSS URL. No auth needed."""
    resp = requests.put(ful, data=image_bytes, headers={"Content-Type": content_type})
    resp.raise_for_status()


def prepare_image_url(source, api_key: str) -> str:
    """
    Full workflow: upload any image and return the CDN URL (fdl).
    
    Args:
        source: file path (str), raw bytes, or already-public HTTPS URL
        api_key: IMA API key for upload authentication
    
    Returns: public HTTPS CDN URL ready to use as input_images value
    """
    # Already a public URL ‚Üí use directly, no upload needed
    if isinstance(source, str) and source.startswith("https://"):
        return source
    
    # Read file bytes
    if isinstance(source, str):
        ext = source.rsplit(".", 1)[-1].lower() if "." in source else "jpeg"
        with open(source, "rb") as f:
            image_bytes = f.read()
        content_type = mimetypes.guess_type(source)[0] or "image/jpeg"
    else:
        image_bytes = source
        ext = "jpeg"
        content_type = "image/jpeg"

    # Step 1: Get presigned URL using API key directly
    token_data = get_upload_token(api_key, ext, content_type)
    ful = token_data["ful"]
    fdl = token_data["fdl"]

    # Step 2: Upload to OSS
    upload_image_to_oss(image_bytes, content_type, ful)

    # Step 3: Return CDN URL
    return fdl   # use this as input_images / src_img_url value
```

> **OSS path format**: `webAgent/privite/{YYYY}/{MM}/{DD}/{timestamp}_{uid}_{uuid}.{ext}`
> **CDN base**: `https://ima-ga.esxscloud.com/`
> **OSS bucket**: `zhubite-imagent-bot.oss-us-east-1.aliyuncs.com`

---

## Quick Reference

### Task Types (category values)

| category | Capability | Input |
|----------|------------|-------|
| `text_to_image` | Text ‚Üí Image | prompt |
| `image_to_image` | Image ‚Üí Image | prompt + input_images |
| `text_to_video` | Text ‚Üí Video | prompt |
| `image_to_video` | Image ‚Üí Video | prompt + input_images |
| `first_last_frame_to_video` | First+Last Frame ‚Üí Video | prompt + src_img_url[2] |
| `reference_image_to_video` | Reference Image ‚Üí Video | prompt + src_img_url[1+] |
| `text_to_music` | Text ‚Üí Music | prompt |

### Detail API status values

Each media in `medias[]` has two fields:

| Field | Type | Values | Description |
|-------|------|--------|-------------|
| **`resource_status`** | int (or `null`) | `0`, `1`, `2`, `3` | 0=Â§ÑÁêÜ‰∏≠, 1=ÂèØÁî®, 2=Â§±Ë¥•, 3=Â∑≤Âà†Èô§„ÄÇAPI ÂèØËÉΩËøîÂõû `null`ÔºåÈúÄÂΩì‰Ωú 0„ÄÇ |
| **`status`** | string | `"pending"`, `"processing"`, `"success"`, `"failed"` | ‰ªªÂä°Áä∂ÊÄÅÊñáÊ°à„ÄÇËΩÆËØ¢Êó∂‰ª• `resource_status` ‰∏∫ÂáÜÔºõ`status == "failed"` Ë°®Á§∫Â§±Ë¥•„ÄÇ |

Poll on `resource_status` first, then ensure `status` is not `"failed"`:

| `resource_status` | `status` | Meaning | Action |
|-------------------|----------|---------|--------|
| `0` or **`null`** | `pending` / `processing` | Â§ÑÁêÜ‰∏≠ | Keep polling; do not stop (null = 0) |
| `1` | `success` (or `completed`) | **ÂÆåÊàê** | Read `url`; stop only when **all** medias are 1 |
| `1` | `failed` | Â§±Ë¥• (status ‰ºòÂÖà) | Stop, handle error |
| `2` | any | Â§±Ë¥• | Stop, handle error |
| `3` | any | Â∑≤Âà†Èô§ | Stop |

> **Important**: (1) Treat `resource_status: null` as 0. (2) Stop only when **all** medias have `resource_status == 1`. (3) When `resource_status=1`, still check `status != "failed"`.

---

## API 1: Product List

```
GET /open/v1/product/list?app=ima&platform=web&category=text_to_image
```

Internally calls downstream `/v1/products/listv2`. Returns a **V2 tree structure**: `type=2` nodes are model groups, `type=3` nodes are versions (leaves). Only `type=3` nodes contain `credit_rules` and `form_config`.

> `webAgent` is auto-converted to `ima` by the gateway ‚Äî you can use either value for `app`.

```json
[
  {
    "id": "SeeDream",
    "type": "2",
    "name": "SeeDream",
    "model_id": "",
    "children": [
      {
        "id": "doubao-seedream-4-0-250828",
        "type": "3",
        "name": "SeeDream 4.0",
        "model_id": "doubao-seedream-4.0",
        "credit_rules": [
          { "attribute_id": 332, "points": 5, "attributes": { "default": "enabled" } }
        ],
        "form_config": [
          { "field": "size", "type": "tags", "value": "1K",
            "options": [{"label":"1K","value":"1K"}, {"label":"2K","value":"2K"}] }
        ]
      }
    ]
  }
]
```

**How to pick a version for task creation:**
1. Traverse nodes to find `type=3` leaves (versions)
2. Use `model_id` and `id` (= `model_version`) from the leaf
3. Pick `credit_rules[].attribute_id` matching your desired quality/size (`attributes` field shows the config)
4. Use `form_config[].value` as default `parameters` values

> `credit_rules[].attribute_id` ‚Üí required for task creation as `attribute_id`.
> `credit_rules[].points` ‚Üí required for task creation as `credit` and `cast.points`.

---

## API 2: Create Task

```
POST /open/v1/tasks/create
```

### Request Structure

```json
{
  "task_type": "text_to_image",
  "enable_multi_model": false,
  "src_img_url": [],
  "upload_img_src": "",
  "parameters": [
    {
      "attribute_id": 8538,
      "model_id":      "doubao-seedream-4.5",
      "model_name":    "SeeDream 4.5",
      "model_version": "doubao-seedream-4-5-251128",
      "app":           "ima",
      "platform":      "web",
      "category":      "text_to_image",
      "credit":        5,
      "parameters": {
        "prompt":       "a beautiful mountain sunset, photorealistic",
        "size":         "4k",
        "n":            1,
        "input_images": [],
        "cast":         {"points": 5, "attribute_id": 8538}
      }
    }
  ]
}
```

### Field Reference

| Field | Required | Description |
|-------|----------|-------------|
| `task_type` | ‚úÖ | Must match `parameters[].category` |
| `parameters[].attribute_id` | ‚úÖ | From `credit_rules[].attribute_id` in product list |
| `parameters[].model_id` | ‚úÖ | From `type=3` leaf node `model_id` |
| `parameters[].model_version` | ‚úÖ | From `type=3` leaf node `id` |
| `parameters[].app` | ‚úÖ | Use `ima` (or `webAgent`, auto-converted) |
| `parameters[].platform` | ‚úÖ | Use `web` |
| `parameters[].category` | ‚úÖ | Must match top-level `task_type` |
| `parameters[].credit` | ‚úÖ | Must equal `credit_rules[].points`. Error 6006 if wrong. |
| `parameters[].parameters.prompt` | ‚úÖ | The actual prompt text used by downstream service |
| `parameters[].parameters.cast` | ‚úÖ | `{"points": N, "attribute_id": N}` ‚Äî mirrors credit |
| `parameters[].parameters.n` | ‚úÖ | Number of outputs (usually `1`). Gateway flattens N>1 into separate resources. |
| `parameters[].parameters.input_images` | image tasks | Array of input image URLs |
| top-level `src_img_url` | multi-image | Array for first_last_frame / reference tasks |

### N-Field Flattening (Gateway Internal Logic)

When `n > 1`, the gateway automatically:
1. Generates `n` independent `resourceBizId` values
2. Deducts credits `n` times (one per resource)
3. Creates `n` separate tasks in the downstream service

Response `medias[]` will contain `n` items. Poll until **all** have `resource_status == 1`.

### Response

```json
{
  "code": 0,
  "data": {
    "id": "task_abc123",
    "biz_id": "biz_xxx",
    "task_type": "text_to_image",
    "medias": [],
    "generate_count": 1,
    "created_at": 1700000000000,
    "timeout_at": 1700000300000
  }
}
```

`data.id` = task ID for polling. `timeout_at` = Unix ms deadline.

---

## API 3: Task Detail (Poll)

```
POST /open/v1/tasks/detail
{"task_id": "<id from create response>"}
```

Poll every 2‚Äì5s (8s+ for video). Completed response:

```json
{
  "id": "task_abc",
  "medias": [{
    "resource_status": 1,
    "status": "success",
    "url": "https://cdn.../output.jpg",
    "cover": "https://cdn.../cover.jpg",
    "format": "jpg",
    "width": 1024,
    "height": 1024
  }]
}
```

**Polling stop condition (must implement exactly):**
- Treat `resource_status: null` (or missing) as **0** (processing). Do **not** stop when you see null; backend may serialize Go `*int` as null.
- Stop **only when ALL** `medias[].resource_status == 1` and no `status == "failed"`. If you return on the first media with `resource_status == 1` while others are still 0, the task is not fully done and you will keep polling or get inconsistent state.
- Stop immediately if any `status == "failed"` or `resource_status == 2` or `resource_status == 3`.

---

## Task Type Examples

### text_to_image ‚úÖ Verified
No image input. `src_img_url: []`, `input_images: []`. See API 2 for full example.

### text_to_video ‚úÖ Verified
Extra fields vs text_to_image ‚Äî all from `form_config` defaults:

```json
{
  "task_type": "text_to_video",
  "src_img_url": [],
  "parameters": [{
    "attribute_id":  4838,
    "model_id":      "wan2.6-t2v",
    "model_name":    "Wan 2.6",
    "model_version": "wan2.6-t2v",
    "category":      "text_to_video",
    "credit":        3,
    "app": "ima", "platform": "web",
    "parameters": {
      "prompt":          "a puppy dancing happily, sunny meadow",
      "negative_prompt": "",
      "prompt_extend":   false,
      "duration":        5,
      "resolution":      "1080P",
      "aspect_ratio":    "16:9",
      "shot_type":       "single",
      "seed":            -1,
      "n":               1,
      "input_images":    [],
      "cast":            {"points": 3, "attribute_id": 4838}
    }
  }]
}
```
> Video-specific fields from `form_config`: `duration` (seconds), `resolution`, `aspect_ratio`, `shot_type`, `negative_prompt`, `prompt_extend`.
> Poll every 8s (video generation is slower). Response `medias[].cover` = first-frame thumbnail.

### text_to_music
No image input. `src_img_url: []`, `input_images: []`.

### image_to_image ‚úÖ Verified
```json
{
  "task_type": "image_to_image",
  "src_img_url": ["https://...input.jpg"],
  "parameters": [{
    "attribute_id":  8560,
    "model_id":      "doubao-seedream-4.5",
    "model_version": "doubao-seedream-4-5-251128",
    "category":      "image_to_image",
    "credit":        5,
    "app": "ima", "platform": "web",
    "parameters": {
      "prompt":       "turn into oil painting style",
      "size":         "4k",
      "n":            1,
      "input_images": ["https://...input.jpg"],
      "cast":         {"points": 5, "attribute_id": 8560}
    }
  }]
}
```
> ‚ö†Ô∏è `size` must be from `form_config` options (e.g. `"2k"`, `"4k"`, `"2048x2048"`). `"adaptive"` is NOT valid for SeeDream 4.5 i2i ‚Äî causes error 400.
> Top-level `src_img_url` **and** `parameters.input_images` must both contain the input image URL.
> Some i2i models (e.g. `doubao-seededit-3.0-i2i`) may not be available in test environments ‚Äî fall back to SeeDream 4.5.

### image_to_video / first_last_frame_to_video / reference_image_to_video
```json
"src_img_url": ["https://first-frame.jpg", "https://last-frame.jpg"]
```
Index 0 = first frame (or reference), index 1 = last frame (first_last_frame only).

---

## Common Mistakes

| Mistake | Fix |
|---------|-----|
| `attribute_id` not from `credit_rules` | Always fetch product list first |
| `credit` value wrong | Must exactly match `credit_rules[].points` ‚Äî error 6006 |
| `prompt` at wrong location | Put prompt in `parameters[].parameters.prompt` (nested), not only at top level |
| Polling `biz_id` instead of `id` | Use `id` (task ID) for `/tasks/detail` |
| Single-poll instead of loop | Poll until `resource_status == 1` for ALL medias |
| Missing `app` / `platform` in parameters | Required fields ‚Äî use `ima` / `web` |
| `category` mismatch | `parameters[].category` must match top-level `task_type` |
| `resource_status == 2` not handled | Check for failure, don't loop forever |
| `status == "failed"` ignored | `resource_status=1` + `status="failed"` means actual failure |
| `n > 1` and only checking first media | All `n` media items must reach `resource_status == 1` |

---

## Complete Python Example

See [examples.md](examples.md) for a full Python implementation covering all 7 task types.
