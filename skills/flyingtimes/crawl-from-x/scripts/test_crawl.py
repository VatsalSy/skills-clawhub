#!/usr/bin/env python3
"""
æµ‹è¯•ç‰ˆï¼šä¿®å¤åŽçš„ crawl è„šæœ¬
"""

import subprocess
import json
import time
from typing import Optional, Dict

class TestCrawler:
    def __init__(self):
        self.target_id = None

    def run_command(self, cmd: list, timeout: int = 30) -> subprocess.CompletedProcess:
        """è¿è¡Œå‘½ä»¤"""
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=timeout
        )
        return result

    def parse_output(self, output: str) -> Optional[Dict]:
        """è§£æžæµè§ˆå™¨å‘½ä»¤è¾“å‡º - ä¿®å¤ç‰ˆ"""
        lines = output.split('\n')

        # æ‰¾åˆ°ç¬¬ä¸€ä¸ª JSON è¡Œï¼ˆä»¥ { å¼€å¤´ï¼‰
        json_start = None
        for i, line in enumerate(lines):
            if line.strip().startswith('{'):
                json_start = i
                break

        if json_start is None:
            # å¤„ç†çº¯ true/false
            output_stripped = output.strip()
            if output_stripped == "true":
                return {"ok": True, "result": True}
            if output_stripped == "false":
                return {"ok": True, "result": False}

            print(f"DEBUG: æ— æ³•è§£æžè¾“å‡ºã€‚æœ€åŽ 500 å­—ç¬¦:\n{output[-500:]}")
            return None

        # ä»Ž JSON å¼€å§‹è¡Œåˆå¹¶åŽé¢çš„æ‰€æœ‰è¡Œ
        json_text = '\n'.join(lines[json_start:])

        try:
            response = json.loads(json_text)
            # æ ‡å‡†åŒ–è¿”å›žæ ¼å¼
            if isinstance(response, dict):
                if response.get("ok"):
                    return response
                elif "result" in response:
                    return response
                else:
                    return {"ok": True, "result": response}
            elif isinstance(response, str):
                return {"ok": True, "result": response}
            else:
                return {"ok": True, "result": response}
        except json.JSONDecodeError as e:
            print(f"DEBUG: JSON è§£æžå¤±è´¥: {e}")
            print(f"JSON å¼€å¤´ 200 å­—ç¬¦:\n{json_text[:200]}")
            return None

    def navigate(self, url: str) -> bool:
        """å¯¼èˆªåˆ° URL"""
        # å…ˆå¯¼èˆª
        cmd = ['openclaw', 'browser', 'navigate', url]
        result = self.run_command(cmd, timeout=20)

        if result.returncode != 0:
            print(f"âŒ å¯¼èˆªå¤±è´¥: {result.stderr}")
            return False

        print(f"âœ… å¯¼èˆªæˆåŠŸ: {url}")

        # ç„¶åŽèŽ·å– snapshot æ¥èŽ·å– targetId
        # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
        print("â³ ç­‰å¾…é¡µé¢åŠ è½½...")
        time.sleep(5)

        cmd = ['openclaw', 'browser', 'snapshot', '--json']
        result = self.run_command(cmd, timeout=10)

        if result.returncode != 0:
            print(f"âŒ snapshot å¤±è´¥: {result.stderr}")
            return False

        response = self.parse_output(result.stdout)
        if response and response.get("ok"):
            self.target_id = response.get("targetId")
            print(f"âœ… èŽ·å– targetId: {self.target_id}")
            return True

        print(f"âŒ snapshot å“åº”æ— æ•ˆ")
        return False

    def evaluate(self, js: str, timeout: int = 10) -> Optional[str]:
        """æ‰§è¡Œ JavaScript"""
        if not self.target_id:
            print("âŒ æ²¡æœ‰ targetId")
            return None

        # ä½¿ç”¨ --fn å‚æ•°ä¼ é€’ JavaScript
        cmd = ['openclaw', 'browser', 'evaluate',
               '--target-id', self.target_id,
               '--fn', js]

        result = self.run_command(cmd, timeout=timeout)

        if result.returncode != 0:
            print(f"âŒ evaluate å¤±è´¥: {result.stderr}")
            return None

        # æ¸…ç†è¾“å‡ºï¼šåŽ»æŽ‰å¼€å¤´çš„è°ƒè¯•ä¿¡æ¯
        output = result.stdout
        lines = output.split('\n')

        # æ‰¾åˆ°å®žé™…ç»“æžœï¼ˆè·³è¿‡è°ƒè¯•ä¿¡æ¯ï¼‰
        for i, line in enumerate(lines):
            if line.strip().startswith(('[', '{', '"', "'")):
                # æ‰¾åˆ°ç»“æžœï¼Œåˆå¹¶åŽé¢çš„è¡Œ
                result_text = '\n'.join(lines[i:])
                return result_text.strip()

        # å¦‚æžœæ²¡æœ‰æ‰¾åˆ° JSONï¼Œç›´æŽ¥è¿”å›žæ¸…ç†åŽçš„è¾“å‡º
        return output.strip()

    def crawl_karpathy(self):
        """æµ‹è¯•æŠ“å– Karpathy"""
        print("=" * 60)
        print("å¼€å§‹æµ‹è¯•æŠ“å– @karpathy")
        print("=" * 60)

        # æ£€æŸ¥ json æ¨¡å—
        print(f"ðŸ” json æ¨¡å—: {json}")
        print(f"ðŸ” json.loads: {json.loads}")

        # å¯¼èˆª
        if not self.navigate("https://x.com/karpathy"):
            return

        # ç­‰å¾…é¡µé¢åŠ è½½
        time.sleep(3)

        # æ‰§è¡Œ JavaScript æå– URL
        js_code = """(() => {
            const articles = document.querySelectorAll('article');
            const now = new Date();
            const oneDayAgo = new Date(now.getTime() - 24 * 60 * 60 * 1000);
            const result = [];

            articles.forEach(article => {
                try {
                    const timeElement = article.querySelector('time');
                    if (!timeElement) return;

                    const datetime = timeElement.getAttribute('datetime');
                    if (!datetime) return;

                    const tweetDate = new Date(datetime);
                    if (tweetDate < oneDayAgo) return;

                    const links = article.querySelectorAll('a[href*="/status/"]');
                    for (const link of links) {
                        const href = link.getAttribute('href');
                        if (href && href.includes('/status/')) {
                            const statusId = href.split('/status/')[1].split('/')[0];
                            const fullUrl = 'https://x.com' + href.split('/status/')[0] + '/status/' + statusId;
                            if (!result.includes(fullUrl)) {
                                result.push(fullUrl);
                            }
                            break;
                        }
                    }
                } catch (e) {
                    // Skip this article
                }
            });

            return JSON.stringify(result);
        })()"""

        result = self.evaluate(js_code, timeout=15)

        print(f"\nðŸ” è°ƒè¯•: result ç±»åž‹={type(result)}, é•¿åº¦={len(result)}")
        print(f"ðŸ” result å‰ 100 å­—ç¬¦: {result[:100]}")

        if result:
            try:
                print(f"ðŸ” å°è¯• JSON è§£æž...")
                print(f"ðŸ” åŽŸå§‹ result: {result}")

                # æµ‹è¯• json.loads
                test_json = '["test1","test2"]'
                test_result = json.loads(test_json)
                print(f"ðŸ” æµ‹è¯• json.loads: è¾“å…¥={test_json}, è¾“å‡ºç±»åž‹={type(test_result)}, è¾“å‡º={test_result}")

                urls = json.loads(result)
                print(f"âœ… JSON è§£æžæˆåŠŸï¼")
                print(f"ðŸ” urls ç±»åž‹={type(urls)}, id={id(urls)}")
                print(f"ðŸ” urls é•¿åº¦={len(urls)}")
                print(f"ðŸ” urls æ˜¯åˆ—è¡¨? {isinstance(urls, list)}")
                print(f"ðŸ” urls æ˜¯å­—ç¬¦ä¸²? {isinstance(urls, str)}")
                print(f"ðŸ” urls å†…å®¹: {urls}")
                print(f"\n{'=' * 60}")
                print(f"âœ… æˆåŠŸæŠ“å–åˆ° {len(urls)} æ¡å¸–å­")
                print(f"{'=' * 60}")
                for i, url in enumerate(urls, 1):
                    print(f"{i}. {url}")
                return urls
            except json.JSONDecodeError as e:
                print(f"âŒ JSON è§£æžå¤±è´¥: {e}")
                print(f"åŽŸå§‹ç»“æžœï¼ˆå‰ 200 å­—ç¬¦ï¼‰: {result[:200]}")
                return []
        else:
            print(f"\nâŒ æ²¡æœ‰æŠ“å–åˆ°å¸–å­")
            return []

if __name__ == "__main__":
    crawler = TestCrawler()
    crawler.crawl_karpathy()
