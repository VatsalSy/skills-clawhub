#!/usr/bin/env python3
"""
Indie Hackers äº§å“æœç´¢

é€šè¿‡ Indie Hackers å†…ç½®çš„ Algolia æœç´¢ API è·å–ç‹¬ç«‹å¼€å‘è€…äº§å“ä¿¡æ¯ã€‚
æ— éœ€è®¤è¯ï¼Œæ— éœ€ Tokenï¼Œç›´æ¥ POST è¯·æ±‚å³å¯ã€‚

Usage:
    # æœç´¢äº§å“
    python3 indiehackers_search.py --keyword "AI tool"
    python3 indiehackers_search.py --keyword "productivity"
    python3 indiehackers_search.py --keywords "newsletter" "SaaS" "automation"
    python3 indiehackers_search.py --keyword "developer tools" --limit 10
    python3 indiehackers_search.py --keyword "AI" --min-revenue 100
"""

import argparse
import json
import os
import sys
import time
import urllib.request
import urllib.error
from datetime import datetime

TMP_DIR = os.path.join(os.getcwd(), "tmp")
RESULT_FILE = os.path.join(TMP_DIR, "ih_results.txt")

# Algolia search-only credentials (public, embedded in IH frontend)
ALGOLIA_APP_ID = "N86T1R3OWZ"
ALGOLIA_API_KEY = "5140dac5e87f47346abbda1a34ee70c3"
ALGOLIA_URL = f"https://{ALGOLIA_APP_ID}-dsn.algolia.net/1/indexes/products/query"

DEFAULT_KEYWORDS = ["productivity tool", "AI tool", "developer tool", "side project"]


def _ensure_tmp_dir():
    os.makedirs(TMP_DIR, exist_ok=True)


def search_products(keyword, hits_per_page=20):
    """æœç´¢ Indie Hackers äº§å“ã€‚

    Args:
        keyword: æœç´¢å…³é”®è¯
        hits_per_page: æ¯é¡µè¿”å›æ•°é‡ï¼ˆæœ€å¤§ 1000ï¼‰

    Returns:
        dict with 'hits' list, 'nbHits' total count, etc.
    """
    payload = json.dumps({
        "query": keyword,
        "hitsPerPage": hits_per_page,
    }).encode("utf-8")

    headers = {
        "X-Algolia-Application-Id": ALGOLIA_APP_ID,
        "X-Algolia-API-Key": ALGOLIA_API_KEY,
        "Content-Type": "application/json",
        "Referer": "https://www.indiehackers.com/",
    }

    req = urllib.request.Request(ALGOLIA_URL, data=payload, headers=headers, method="POST")
    try:
        with urllib.request.urlopen(req, timeout=15) as resp:
            return json.loads(resp.read().decode())
    except urllib.error.HTTPError as e:
        print(f"âš ï¸ Algolia API error {e.code}: {e.read().decode()[:200]}", file=sys.stderr)
        return None
    except urllib.error.URLError as e:
        print(f"âš ï¸ Network error: {e.reason}", file=sys.stderr)
        return None


def parse_tags(tags):
    """è§£æ _tags åˆ—è¡¨ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯ã€‚"""
    info = {
        "verticals": [],
        "revenue_model": "",
        "funding": "",
        "commitment": "",
        "employees": "",
        "platform": [],
    }
    for tag in (tags or []):
        if tag.startswith("vertical-"):
            info["verticals"].append(tag.replace("vertical-", ""))
        elif tag.startswith("revenue-model-"):
            info["revenue_model"] = tag.replace("revenue-model-", "")
        elif tag.startswith("funding-"):
            if not info["funding"]:
                info["funding"] = tag.replace("funding-", "")
        elif tag.startswith("commitment-"):
            info["commitment"] = tag.replace("commitment-", "")
        elif tag.startswith("employees-"):
            info["employees"] = tag.replace("employees-", "")
        elif tag.startswith("platform-"):
            info["platform"].append(tag.replace("platform-", ""))
    return info


def format_as_text(all_products, keywords_used, min_revenue=0):
    """å°†äº§å“åˆ—è¡¨æ ¼å¼åŒ–ä¸ºçº¯æ–‡æœ¬ã€‚"""
    lines = [
        f"Indie Hackers äº§å“æœç´¢ç»“æœ â€” å…³é”®è¯: {', '.join(keywords_used)}",
        "=" * 60,
        "",
    ]

    # å»é‡ï¼ˆåŒä¸€äº§å“å¯èƒ½è¢«ä¸åŒå…³é”®è¯å‘½ä¸­ï¼‰
    seen_ids = set()
    unique = []
    for p in all_products:
        pid = p.get("productId", p.get("objectID", ""))
        if pid and pid not in seen_ids:
            seen_ids.add(pid)
            if p.get("revenue", 0) >= min_revenue:
                unique.append(p)

    # æŒ‰ revenue é™åºæ’åˆ—
    unique.sort(key=lambda p: (p.get("revenue", 0) or 0), reverse=True)

    for i, p in enumerate(unique, 1):
        name = p.get("name", "(unknown)")
        tagline = p.get("tagline", "")
        description = p.get("description", "")
        revenue = p.get("revenue", 0) or 0
        website = p.get("websiteUrl", "")
        pid = p.get("productId", p.get("objectID", ""))
        followers = p.get("numFollowers", 0) or 0

        # æ—¶é—´
        start_date = p.get("startDateStr", "")

        # è§£ææ ‡ç­¾
        tag_info = parse_tags(p.get("_tags", []))
        verticals = ", ".join(tag_info["verticals"]) if tag_info["verticals"] else ""
        platforms = ", ".join(tag_info["platform"]) if tag_info["platform"] else ""
        rev_model = tag_info["revenue_model"]
        funding = tag_info["funding"]
        commitment = tag_info["commitment"]

        ih_url = f"https://www.indiehackers.com/product/{pid}" if pid else ""

        lines.append(f"#{i} {name}")
        meta_parts = []
        if revenue > 0:
            meta_parts.append(f"ğŸ’° ${revenue}/mo")
        else:
            meta_parts.append("ğŸ’° $0/mo")
        if followers:
            meta_parts.append(f"ğŸ‘¥ {followers} followers")
        if start_date:
            meta_parts.append(f"ğŸ“… {start_date}")
        lines.append(f"  {' | '.join(meta_parts)}")

        if tagline:
            lines.append(f"  {tagline}")

        detail_parts = []
        if verticals:
            detail_parts.append(f"é¢†åŸŸ: {verticals}")
        if platforms:
            detail_parts.append(f"å¹³å°: {platforms}")
        if rev_model:
            detail_parts.append(f"æ¨¡å¼: {rev_model}")
        if funding:
            detail_parts.append(f"èèµ„: {funding}")
        if commitment:
            detail_parts.append(f"æŠ•å…¥: {commitment}")
        if detail_parts:
            lines.append(f"  {' | '.join(detail_parts)}")

        if description:
            desc = description if len(description) <= 200 else description[:200] + "..."
            lines.append(f"  {desc}")

        if website:
            lines.append(f"  ğŸ”— {website}")
        if ih_url:
            lines.append(f"  ğŸ“„ {ih_url}")
        lines.append("")

    lines.append(f"å…± {len(unique)} ä¸ªäº§å“ï¼ˆå·²å»é‡ã€æŒ‰æœˆæ”¶å…¥æ’åºï¼‰")
    if min_revenue > 0:
        lines.append(f"ï¼ˆå·²è¿‡æ»¤æœˆæ”¶å…¥ < ${min_revenue} çš„äº§å“ï¼‰")
    return "\n".join(lines)


def main():
    parser = argparse.ArgumentParser(description="Indie Hackers äº§å“æœç´¢")
    parser.add_argument(
        "--keyword", type=str, default=None,
        help="æœç´¢å…³é”®è¯ï¼ˆå•ä¸ªï¼‰"
    )
    parser.add_argument(
        "--keywords", nargs="+", default=None,
        help="å¤šä¸ªæœç´¢å…³é”®è¯"
    )
    parser.add_argument(
        "--limit", type=int, default=None,
        help="é™åˆ¶è¾“å‡ºäº§å“æ•°é‡"
    )
    parser.add_argument(
        "--min-revenue", type=int, default=0,
        help="æœ€ä½æœˆæ”¶å…¥è¿‡æ»¤ï¼ˆç¾å…ƒï¼‰"
    )
    parser.add_argument(
        "--output", type=str, default=None,
        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ tmp/ih_results.txtï¼‰"
    )
    args = parser.parse_args()

    # ç¡®å®šå…³é”®è¯åˆ—è¡¨
    if args.keyword:
        keywords = [args.keyword]
    elif args.keywords:
        keywords = args.keywords
    else:
        keywords = DEFAULT_KEYWORDS

    all_products = []
    for kw in keywords:
        print(f"ğŸ” æœç´¢ Indie Hackers: {kw}...", file=sys.stderr, flush=True)
        resp = search_products(kw, hits_per_page=50)
        if resp:
            hits = resp.get("hits", [])
            total = resp.get("nbHits", 0)
            print(f"  â†’ è·å– {len(hits)} ä¸ªäº§å“ï¼ˆå…± {total} ä¸ªåŒ¹é…ï¼‰", file=sys.stderr, flush=True)
            all_products.extend(hits)
        else:
            print(f"  âš ï¸ æœç´¢å¤±è´¥", file=sys.stderr)

        if len(keywords) > 1:
            time.sleep(0.3)

    if not all_products:
        print("âŒ æœªè·å–åˆ°ä»»ä½•äº§å“", file=sys.stderr)
        sys.exit(1)

    # å»é‡ + æ’åºåæˆªæ–­
    if args.limit:
        seen_ids = set()
        unique = []
        for p in all_products:
            pid = p.get("productId", p.get("objectID", ""))
            if pid and pid not in seen_ids:
                seen_ids.add(pid)
                if p.get("revenue", 0) >= args.min_revenue:
                    unique.append(p)
        unique.sort(key=lambda p: (p.get("revenue", 0) or 0), reverse=True)
        all_products = unique[:args.limit]

    text = format_as_text(all_products, keywords, min_revenue=args.min_revenue)

    _ensure_tmp_dir()
    output_file = args.output or RESULT_FILE
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(text)

    print(text)
    print(f"\nğŸ“„ ç»“æœå·²ä¿å­˜åˆ° {output_file}", file=sys.stderr)


if __name__ == "__main__":
    main()
