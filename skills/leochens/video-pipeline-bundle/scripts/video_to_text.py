#!/usr/bin/env python3
"""
è§†é¢‘è½¬æ–‡å­—ç¨¿è„šæœ¬
1. ç”¨ Faster Whisper è¯†åˆ«è¯­éŸ³ç”Ÿæˆ SRT
2. ç”¨ LLM è¯çº§åˆ«çº é”™
è‡ªåŠ¨æ£€æŸ¥ä¾èµ–ï¼Œæ”¯æŒå¤šç§ LLM
"""

import os
import sys
import argparse
import subprocess
import requests

# é…ç½®
os.environ.setdefault("HF_ENDPOINT", "https://hf-mirror.com")

# æ”¯æŒçš„ LLM æä¾›å•†
LLM_PROVIDERS = {
    "minimax": {
        "name": "MiniMax",
        "url": "https://api.minimaxi.com/anthropic",
        "env_key": "MINIMAX_API_KEY",
        "model": "MiniMax-M2.5"
    },
    "openai": {
        "name": "OpenAI",
        "url": "https://api.openai.com/v1",
        "env_key": "OPENAI_API_KEY",
        "model": "gpt-3.5-turbo"
    },
    "anthropic": {
        "name": "Anthropic Claude",
        "url": "https://api.anthropic.com/v1",
        "env_key": "ANTHROPIC_API_KEY",
        "model": "claude-3-haiku-20240307"
    }
}

TARGET = None

def check_dependencies():
    """æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–"""
    print("ğŸ” æ£€æŸ¥ä¾èµ–...")
    
    deps = ["faster-whisper", "requests"]
    for dep in deps:
        try:
            __import__(dep.replace("-", "_"))
            print(f"  âœ… {dep} å·²å®‰è£…")
        except ImportError:
            print(f"  ğŸ“¦ æ­£åœ¨å®‰è£… {dep}...")
            try:
                subprocess.run([sys.executable, "-m", "pip", "install", dep, "--break-system-packages"], 
                           capture_output=True)
                print(f"  âœ… {dep} å®‰è£…å®Œæˆ")
            except Exception as e:
                print(f"  âŒ {dep} å®‰è£…å¤±è´¥: {e}")
                return False
    return True

def get_llm_config(provider):
    """è·å– LLM é…ç½®"""
    if provider not in LLM_PROVIDERS:
        print(f"âŒ ä¸æ”¯æŒçš„ LLM æä¾›å•†: {provider}")
        print(f"æ”¯æŒçš„æä¾›å•†: {', '.join(LLM_PROVIDERS.keys())}")
        return None
    
    config = LLM_PROVIDERS[provider]
    api_key = os.environ.get(config["env_key"])
    
    if not api_key:
        print(f"âš ï¸ æœªè®¾ç½® {config['env_key']} ç¯å¢ƒå˜é‡")
        print(f"ğŸ’¡ è¯·è®¾ç½®: export {config['env_key']}='ä½ çš„APIKey'")
        return None
    
    return config

def send_message(msg):
    if not TARGET:
        print(msg)
        return
    subprocess.run([
        "openclaw", "message", "send",
        "--channel", "feishu",
        "--target", TARGET,
        "--message", msg
    ], capture_output=True)

def get_video_files(directory, exclude_pattern="å·²è½¬å†™"):
    video_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.flv', '.wmv']
    files = []
    if not os.path.exists(directory):
        return files
    for root, dirs, filenames in os.walk(directory):
        dirs[:] = [d for d in dirs if exclude_pattern not in d]
        for f in filenames:
            if exclude_pattern in f:
                continue
            ext = os.path.splitext(f)[1].lower()
            if ext in video_extensions:
                full_path = os.path.join(root, f)
                rel_path = os.path.relpath(full_path, directory)
                files.append({
                    "full_path": full_path,
                    "rel_path": rel_path,
                    "filename": f,
                    "subdir": os.path.dirname(rel_path)
                })
    return sorted(files, key=lambda x: x["rel_path"])

def ensure_dir(path):
    os.makedirs(path, exist_ok=True)

def format_time(seconds):
    h = int(seconds // 3600)
    m = int((seconds % 3600) // 60)
    s = int(seconds % 60)
    ms = int((seconds % 1) * 1000)
    return f"{h:02d}:{m:02d}:{s:02d},{ms:03d}"

def transcribe(video_path, output_srt, model):
    from faster_whisper import WhisperModel
    print(f"ğŸ”§ åŠ è½½æ¨¡å‹: {model}")
    whisper_model = WhisperModel(model, device="cpu", compute_type="int8")
    print(f"ğŸ¤ è½¬å†™ä¸­: {video_path}")
    segments, info = whisper_model.transcribe(video_path)
    print(f"ğŸ“ è¯­è¨€: {info.language}")
    
    with open(output_srt, "w", encoding="utf-8") as f:
        for i, seg in enumerate(segments, 1):
            start = format_time(seg.start)
            end = format_time(seg.end)
            text = seg.text.strip()
            f.write(f"{i}\n{start} --> {end}\n{text}\n\n")
    
    # çº¯æ–‡æœ¬
    segments, _ = whisper_model.transcribe(video_path)
    text = " ".join([s.text.strip() for s in segments])
    return text

def correct_text(text, api_key, provider="minimax"):
    if not api_key:
        return text
    print("ğŸ¤– LLM çº é”™...")
    
    config = LLM_PROVIDERS.get(provider)
    if not config:
        return text
    
    url = f"{config['url']}/messages"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    
    prompt = "è¯·åªä¿®æ­£ä»¥ä¸‹æ¼”è®²ç¨¿ä¸­çš„é”™åˆ«å­—å’Œæ˜æ˜¾çš„è¯†åˆ«é”™è¯¯ï¼ˆè¯çº§åˆ«ï¼‰ï¼Œä¸ä¿®æ”¹å¥å­ç»“æ„ï¼Œåªè¿”å›ä¿®æ­£åçš„æ–‡å­—ï¼š"
    
    if provider == "anthropic":
        headers["anthropic-version"] = "2023-06-01"
        payload = {"model": config["model"], "max_tokens": 4096, 
                  "messages": [{"role": "user", "content": prompt + text}]}
    else:
        payload = {"model": config["model"], "max_tokens": 4096, 
                  "messages": [{"role": "user", "content": prompt + text}]}
    
    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=120)
        result = resp.json()
        if "content" in result:
            for c in result["content"]:
                if c.get("type") == "text":
                    return c.get("text", text)
    except Exception as e:
        print(f"âŒ APIé”™è¯¯: {e}")
    return text

def correct_srt(srt_path, corrected_text):
    pass  # SRT ä¿æŒåŸå§‹

def process_video(video_info, output_root, model, api_key, provider):
    input_path = video_info["full_path"]
    rel_path = video_info["rel_path"]
    filename = video_info["filename"]
    subdir = video_info["subdir"]
    
    name_without_ext = os.path.splitext(filename)[0]
    ext = os.path.splitext(filename)[1]
    
    if subdir and subdir != ".":
        output_subdir = os.path.join(output_root, subdir)
    else:
        output_subdir = output_root
    ensure_dir(output_subdir)
    
    output_name = f"{name_without_ext}.srt"
    output_path = os.path.join(output_subdir, output_name)
    temp_srt = output_path.replace(".srt", "_temp.srt")
    
    print(f"\nğŸ“¹ å¤„ç†: {rel_path}")
    send_message(f"â–¶ï¸ å¼€å§‹è½¬å†™: {filename}")
    
    # è½¬å†™
    text = transcribe(input_path, temp_srt, model)
    if not text:
        send_message(f"âŒ è½¬å†™å¤±è´¥: {filename}")
        return None
    
    # çº é”™
    corrected = correct_text(text, api_key, provider)
    
    # ä¿å­˜æ ¡æ­£åSRT
    corrected_srt = correct_srt(temp_srt, corrected)
    with open(output_path, "w", encoding="utf-8") as f:
        # ç›´æ¥å¤åˆ¶åŸå§‹ SRTï¼ˆæœ‰æ—¶é—´çº¿ï¼‰
        if os.path.exists(temp_srt):
            with open(temp_srt, "r") as f_orig:
                f.write(f_orig.read())
    
    # ä¿å­˜çº¯æ–‡æœ¬
    txt_path = output_path.replace(".srt", ".txt")
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write(corrected)
    
    if os.path.exists(temp_srt):
        os.remove(temp_srt)
    
    send_message(f"âœ… å®Œæˆ: {filename}\nå­—æ•°: {len(text)} â†’ {len(corrected)}")
    return True

def main():
    global TARGET
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        print("âŒ ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å®‰è£…")
        sys.exit(1)
    
    parser = argparse.ArgumentParser(description="è§†é¢‘è½¬æ–‡å­—ç¨¿")
    parser.add_argument("--input", "-i", required=True)
    parser.add_argument("--output", "-o", default=None)
    parser.add_argument("--model", "-m", default="small", help="Whisper æ¨¡å‹: tiny, small, base, medium")
    parser.add_argument("--target", "-T", default=None)
    parser.add_argument("--api-key", "-k", default=None, help="LLM API Key")
    parser.add_argument("--provider", "-p", default="minimax", 
                       choices=["minimax", "openai", "anthropic"],
                       help="LLM æä¾›å•†")
    args = parser.parse_args()
    
    if args.output is None:
        args.output = args.input
    
    TARGET = args.target
    
    # è·å– API Key
    config = LLM_PROVIDERS[args.provider]
    api_key = args.api_key or os.environ.get(config["env_key"])
    
    if not api_key:
        print(f"\nâš ï¸ éœ€è¦è®¾ç½® {args.provider} çš„ API Key")
        print(f"ğŸ’¡ æ–¹å¼1: --api-key 'ä½ çš„Key'")
        print(f"ğŸ’¡ æ–¹å¼2: export {config['env_key']}='ä½ çš„Key'")
        print(f"\næ”¯æŒçš„ LLM æä¾›å•†:")
        for k, v in LLM_PROVIDERS.items():
            print(f"  â€¢ {k}: {v['name']} (env: {v['env_key']})")
        sys.exit(1)
    
    video_files = get_video_files(args.input)
    if not video_files:
        print("æ²¡æœ‰æ‰¾åˆ°è§†é¢‘")
        return
    
    print(f"ğŸ¬ æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘")
    send_message(f"ğŸ¬ å¼€å§‹è½¬å†™ï¼å…± {len(video_files)} ä¸ªè§†é¢‘\nLLM: {config['name']}")
    
    for i, f in enumerate(video_files, 1):
        process_video(f, args.output, args.model, api_key, args.provider)
    
    send_message(f"ğŸ‰ å…¨éƒ¨å®Œæˆï¼å…±å¤„ç† {len(video_files)} ä¸ªè§†é¢‘")

if __name__ == "__main__":
    TARGET = None
    main()
