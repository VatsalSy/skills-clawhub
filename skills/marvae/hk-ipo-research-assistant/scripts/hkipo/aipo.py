"""AiPO æ•°æ®æºé€‚é…å™¨ã€‚

æ•°æ®æº: https://aipo.myiqdii.com
æ¸¯è‚¡æ‰“æ–°æ•°æ®å®è—ï¼Œæä¾›ï¼š
- å­–å±•æ•°æ®ï¼ˆå„åˆ¸å•†å­–å±•èµ„é‡‘ï¼‰
- è¯„çº§æ•°æ®ï¼ˆå„æœºæ„è¯„çº§è¯„åˆ†ï¼‰â­
- æš—ç›˜æ•°æ®ï¼ˆæš—ç›˜ä»·æ ¼ã€æˆäº¤ï¼‰
- IPO è¯¦æƒ…ï¼ˆä¿èäººã€åŸºçŸ³æŠ•èµ„è€…ç­‰ï¼‰
- å†å²æ•°æ®ï¼ˆIPO è¡¨ç°å†å²ï¼‰

è¿”å›çº¯æ•°æ®å­—å…¸ï¼Œä¸åšè¯„åˆ†æˆ–åˆ¤æ–­ã€‚
"""

import json
import re
import sys
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Optional

import httpx

# å¸¸é‡
BASE_URL = "https://aipo.myiqdii.com"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "application/json",
}


# =============================================================================
# Data Classes
# =============================================================================

@dataclass
class BrokerMargin:
    """å•ä¸ªåˆ¸å•†çš„å­–å±•æ•°æ®"""
    
    broker_name: str  # åˆ¸å•†åç§°
    margin_amount: float  # å­–å±•é‡‘é¢ï¼ˆäº¿æ¸¯å…ƒï¼‰
    interest_rate: float  # å­–å±•åˆ©ç‡ï¼ˆ%ï¼‰
    change_amount: float  # è¾ƒä¸Šæ¬¡å˜åŒ–ï¼ˆäº¿æ¸¯å…ƒï¼‰
    
    def to_dict(self) -> dict:
        return {
            "broker_name": self.broker_name,
            "margin_amount": self.margin_amount,
            "interest_rate": self.interest_rate,
            "change_amount": self.change_amount,
        }


@dataclass
class MarginSummary:
    """IPO å­–å±•æ±‡æ€»"""
    
    code: str  # è‚¡ç¥¨ä»£ç 
    name: str  # è‚¡ç¥¨åç§°
    apply_start: str | None  # æ‹›è‚¡å¼€å§‹æ—¥æœŸ
    apply_end: str | None  # æ‹›è‚¡æˆªæ­¢æ—¥æœŸ
    listing_date: str | None  # ä¸Šå¸‚æ—¥æœŸ
    total_margin: float  # å­–å±•æ€»é¢ï¼ˆäº¿æ¸¯å…ƒï¼‰
    raise_money: float  # å‹Ÿèµ„é‡‘é¢ï¼ˆäº¿æ¸¯å…ƒï¼‰
    oversubscription_actual: float | None  # å®é™…è¶…è´­å€æ•°
    oversubscription_forecast: float | None  # é¢„æµ‹è¶…è´­å€æ•°
    broker_margins: list[BrokerMargin] = field(default_factory=list)  # å„åˆ¸å•†æ˜ç»†
    update_time: str | None = None  # æ•°æ®æ›´æ–°æ—¶é—´
    
    def to_dict(self) -> dict:
        return {
            "code": self.code,
            "name": self.name,
            "apply_start": self.apply_start,
            "apply_end": self.apply_end,
            "listing_date": self.listing_date,
            "total_margin": self.total_margin,
            "raise_money": self.raise_money,
            "oversubscription_actual": self.oversubscription_actual,
            "oversubscription_forecast": self.oversubscription_forecast,
            "broker_margins": [b.to_dict() for b in self.broker_margins],
            "update_time": self.update_time,
        }


@dataclass
class AgencyRating:
    """æœºæ„è¯„çº§"""
    agency_name: str  # æœºæ„åç§°
    score: float  # è¯„åˆ†ï¼ˆ0-100ï¼‰
    rating: str  # è¯„çº§æ–‡å­—æè¿°
    
    def to_dict(self) -> dict:
        return {
            "agency_name": self.agency_name,
            "score": self.score,
            "rating": self.rating,
        }


@dataclass 
class GreyMarketData:
    """æš—ç›˜æ•°æ®"""
    code: str
    name: str
    ipo_price: float  # å‘è¡Œä»·
    grey_price: float  # æš—ç›˜ä»·
    grey_change_pct: float  # æš—ç›˜æ¶¨è·Œå¹…%
    grey_volume: float  # æš—ç›˜æˆäº¤é‡
    grey_turnover: float  # æš—ç›˜æˆäº¤é¢
    result_date: str | None  # é…å”®ç»“æœæ—¥æœŸ
    listing_date: str | None  # ä¸Šå¸‚æ—¥æœŸ
    
    def to_dict(self) -> dict:
        return {
            "code": self.code,
            "name": self.name,
            "ipo_price": self.ipo_price,
            "grey_price": self.grey_price,
            "grey_change_pct": self.grey_change_pct,
            "grey_volume": self.grey_volume,
            "grey_turnover": self.grey_turnover,
            "result_date": self.result_date,
            "listing_date": self.listing_date,
        }


@dataclass
class CornerstoneInvestor:
    """åŸºçŸ³æŠ•èµ„è€…"""
    name: str
    shareholding: float  # æŒè‚¡æ•°
    shareholding_pct: float  # æŒè‚¡æ¯”ä¾‹%
    release_date: str | None  # è§£ç¦æ—¥æœŸ
    profile: str  # ç®€ä»‹
    
    def to_dict(self) -> dict:
        return {
            "name": self.name,
            "shareholding": self.shareholding,
            "shareholding_pct": self.shareholding_pct,
            "release_date": self.release_date,
            "profile": self.profile,
        }


# =============================================================================
# Client
# =============================================================================

class AiPOClient:
    """AiPO API å®¢æˆ·ç«¯"""
    
    def __init__(self):
        self._client: httpx.Client | None = None
        self._token: str | None = None
    
    def _get_client(self) -> httpx.Client:
        """è·å–æˆ–åˆ›å»º HTTP å®¢æˆ·ç«¯"""
        if self._client is None:
            self._client = httpx.Client(follow_redirects=True, timeout=30)
            self._refresh_token()
        return self._client
    
    def _refresh_token(self) -> None:
        """åˆ·æ–°è¯·æ±‚éªŒè¯ Token"""
        client = self._client
        if client is None:
            raise RuntimeError("Client not initialized")
        
        resp = client.get(f"{BASE_URL}/margin/index", headers=HEADERS)
        resp.raise_for_status()
        
        match = re.search(r'name="__RequestVerificationToken"[^>]+value="([^"]+)"', resp.text)
        if match:
            self._token = match.group(1)
        else:
            raise ValueError("Failed to extract RequestVerificationToken from page")
    
    def _get_headers(self) -> dict:
        """è·å–åŒ…å« Token çš„è¯·æ±‚å¤´"""
        if self._token is None:
            self._refresh_token()
        return {
            **HEADERS,
            "RequestVerificationToken": self._token or "",
            "Referer": f"{BASE_URL}/margin/index",
        }
    
    def _request(self, endpoint: str, params: dict | None = None) -> dict:
        """å‘é€ API è¯·æ±‚"""
        client = self._get_client()
        
        for attempt in range(2):
            try:
                resp = client.get(
                    f"{BASE_URL}{endpoint}",
                    params=params,
                    headers=self._get_headers(),
                )
                resp.raise_for_status()
                data = resp.json()
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è·å– token
                if isinstance(data, str) and "éæ³•è¨ªå•" in data:
                    self._refresh_token()
                    continue
                
                return data
            except httpx.HTTPStatusError as e:
                if attempt == 0 and e.response.status_code in (401, 403):
                    self._refresh_token()
                    continue
                raise
        
        raise RuntimeError("Failed to get valid response after retries")
    
    def close(self) -> None:
        """å…³é—­å®¢æˆ·ç«¯"""
        if self._client:
            self._client.close()
            self._client = None
    
    def __enter__(self):
        return self
    
    def __exit__(self, *args):
        self.close()


# =============================================================================
# Helpers
# =============================================================================

def _parse_datetime(value: str | None) -> str | None:
    """è§£ææ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²ä¸º YYYY-MM-DD æ ¼å¼"""
    if not value:
        return None
    try:
        # æ ¼å¼: "2026-02-27T00:00:00" æˆ– "2026-02-27 00:00:00"
        if "T" in value:
            dt = datetime.fromisoformat(value.replace("Z", "+00:00"))
        else:
            dt = datetime.strptime(value.split()[0], "%Y-%m-%d")
        return dt.strftime("%Y-%m-%d")
    except (ValueError, AttributeError):
        return value


def _parse_float(value: Any) -> float:
    """è§£ææµ®ç‚¹æ•°"""
    if value is None:
        return 0.0
    if isinstance(value, (int, float)):
        return float(value)
    if isinstance(value, str):
        try:
            return float(value.replace(",", ""))
        except ValueError:
            return 0.0
    return 0.0


def _normalize_code(code: str) -> str:
    """è§„èŒƒåŒ–è‚¡ç¥¨ä»£ç ä¸º5ä½æ ¼å¼"""
    return code.lstrip("0").zfill(5)


def _code_with_prefix(code: str) -> str:
    """æ·»åŠ  E å‰ç¼€"""
    code = _normalize_code(code)
    return f"E{code}"


# =============================================================================
# Margin APIs (å­–å±•æ•°æ®)
# =============================================================================

def fetch_margin_list(sector: str = "") -> list[dict]:
    """è·å–å½“å‰æ‹›è‚¡ä¸­ IPO çš„å­–å±•åˆ—è¡¨ã€‚
    
    Args:
        sector: æ¿å—è¿‡æ»¤ï¼Œç©ºå­—ç¬¦ä¸²=å…¨éƒ¨, "ä¸»æ¿"=ä¸»æ¿, "åˆ›ä¸šæ¿"=åˆ›ä¸šæ¿
        
    Returns:
        IPO å­–å±•åˆ—è¡¨ï¼ŒåŒ…å«åŸºæœ¬ä¿¡æ¯å’Œå­–å±•æ€»é¢
    """
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetMarginList",
            params={"sector": sector, "pageIndex": 1, "pageSize": 100}
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", {}).get("dataList", [])
    result = []
    
    for row in rows:
        result.append({
            "code": row.get("symbol", ""),
            "name": row.get("shortName", "") or row.get("shortname", ""),
            "apply_start": _parse_datetime(row.get("startdate")),
            "apply_end": _parse_datetime(row.get("enddate")),
            "listing_date": _parse_datetime(row.get("listedDate")),
            "total_margin": _parse_float(row.get("marginData")),
            "margin_type": row.get("marginType"),  # "ä¸Šå‡"/"æŠ½é£›"/null
            "interest_rate": _parse_float(row.get("interestRate")),
        })
    
    return result


def fetch_margin_detail(code: str) -> MarginSummary | None:
    """è·å–å•åªè‚¡ç¥¨çš„å­–å±•è¯¦æƒ…ï¼ŒåŒ…å«å„åˆ¸å•†æ˜ç»†ã€‚
    
    Args:
        code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ "03268" æˆ– "3268"ï¼‰
        
    Returns:
        MarginSummary å¯¹è±¡ï¼ŒåŒ…å«å­–å±•æ±‡æ€»å’Œå„åˆ¸å•†æ˜ç»†ï¼›æœªæ‰¾åˆ°è¿”å› None
    """
    code = _normalize_code(code)
    
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetMarginInfo",
            params={"stockCode": f"E{code}"}
        )
    
    if data.get("result") != 1:
        return None
    
    # msg å­—æ®µåŒ…å« JSON å­—ç¬¦ä¸²
    msg_str = data.get("msg", "{}")
    try:
        info = json.loads(msg_str).get("data", {})
    except json.JSONDecodeError:
        return None
    
    if not info:
        return None
    
    # è§£æå„åˆ¸å•†å­–å±•æ•°æ®
    broker_margins = []
    margin_info = info.get("margininfo", [])
    
    for item in margin_info:
        broker_name = item.get("ratingagency", "")
        if broker_name == "å…¶ä»–":
            # "å…¶ä»–"åŒ…å«å¤šä¸ªå°åˆ¸å•†ï¼Œå±•å¼€æ˜¾ç¤º
            sub_list = item.get("list", [])
            for sub in sub_list:
                broker_margins.append(BrokerMargin(
                    broker_name=sub.get("ratingagency", ""),
                    margin_amount=_parse_float(sub.get("latedmargin")),
                    interest_rate=_parse_float(sub.get("rate")),
                    change_amount=_parse_float(sub.get("ChangeMargin")),
                ))
        else:
            broker_margins.append(BrokerMargin(
                broker_name=broker_name,
                margin_amount=_parse_float(item.get("latedmargin")),
                interest_rate=_parse_float(item.get("rate")),
                change_amount=_parse_float(item.get("ChangeMargin")),
            ))
    
    # æŒ‰å­–å±•é‡‘é¢é™åºæ’åº
    broker_margins.sort(key=lambda x: x.margin_amount, reverse=True)
    
    return MarginSummary(
        code=info.get("code", code),
        name=info.get("name", ""),
        apply_start=_parse_datetime(info.get("StartDate")),
        apply_end=_parse_datetime(info.get("EndDate")),
        listing_date=None,  # detail API ä¸è¿”å›ä¸Šå¸‚æ—¥æœŸ
        total_margin=_parse_float(info.get("totalmargin")),
        raise_money=_parse_float(info.get("raisemoney")),
        oversubscription_actual=_parse_float(info.get("RateOver")) if info.get("RateOver") else None,
        oversubscription_forecast=_parse_float(info.get("RateForcast")) if info.get("RateForcast") else None,
        broker_margins=broker_margins,
        update_time=info.get("modifytime"),
    )


def get_margin_by_code(code: str) -> dict | None:
    """è·å–æŒ‡å®šè‚¡ç¥¨ä»£ç çš„å­–å±•æ•°æ®ï¼ˆä¾¿æ·å‡½æ•°ï¼‰ã€‚"""
    summary = fetch_margin_detail(code)
    if summary:
        return summary.to_dict()
    return None


# =============================================================================
# Rating APIs (è¯„çº§æ•°æ®) â­
# =============================================================================

def fetch_rating_list(sector: str = "", page_size: int = 100) -> list[dict]:
    """è·å–æ–°è‚¡è¯„çº§åˆ—è¡¨ã€‚
    
    Args:
        sector: æ¿å—è¿‡æ»¤ï¼Œç©ºå­—ç¬¦ä¸²=å…¨éƒ¨, "ä¸»æ¿", "åˆ›ä¸šæ¿"
        page_size: æ¯é¡µæ•°é‡
        
    Returns:
        è¯„çº§åˆ—è¡¨ï¼ŒåŒ…å«ç»¼åˆè¯„åˆ†
    """
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetNewStockRatingList",
            params={"sector": sector, "pageIndex": 1, "pageSize": page_size}
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", {}).get("dataList", [])
    result = []
    seen = set()
    
    for row in rows:
        code = row.get("symbol", "").strip()
        if code in seen:
            continue
        seen.add(code)
        result.append({
            "code": code,
            "name": row.get("shortName", "").strip(),
            "sector": row.get("sector", "").strip(),
            "rating_count": row.get("number", 0),  # è¯„åˆ†å®¶æ•°
            "avg_score": _parse_float(row.get("avgScore")),  # ç»¼åˆè¯„åˆ† 0-100
            "max_score": _parse_float(row.get("maxScore")),
            "min_score": _parse_float(row.get("minScore")),
        })
    
    return result


def fetch_rating_detail(code: str) -> list[AgencyRating]:
    """è·å–å•åªè‚¡ç¥¨å„æœºæ„è¯„çº§è¯¦æƒ…ã€‚
    
    Args:
        code: è‚¡ç¥¨ä»£ç 
        
    Returns:
        å„æœºæ„è¯„çº§åˆ—è¡¨
    """
    code = _code_with_prefix(code)
    
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetAgencyRatingInfo",
            params={"code": code}
        )
    
    if data.get("result") != 1:
        return []
    
    # æ•°æ®åœ¨ msg JSON ä¸­
    try:
        msg_data = json.loads(data.get("msg", "{}"))
        ratings_data = msg_data.get("data", [])
    except json.JSONDecodeError:
        return []
    
    result = []
    for item in ratings_data:
        result.append(AgencyRating(
            agency_name=item.get("ratingagency", ""),
            score=_parse_float(item.get("score")),
            rating=item.get("rating", ""),
        ))
    
    # æŒ‰è¯„åˆ†é™åº
    result.sort(key=lambda x: x.score, reverse=True)
    return result


def get_rating_by_code(code: str) -> dict | None:
    """è·å–æŒ‡å®šè‚¡ç¥¨çš„è¯„çº§æ±‡æ€»ï¼ˆä¾¿æ·å‡½æ•°ï¼‰ã€‚"""
    ratings = fetch_rating_detail(code)
    if not ratings:
        return None
    
    scores = [r.score for r in ratings]
    return {
        "code": _normalize_code(code),
        "rating_count": len(ratings),
        "avg_score": sum(scores) / len(scores) if scores else 0,
        "max_score": max(scores) if scores else 0,
        "min_score": min(scores) if scores else 0,
        "ratings": [r.to_dict() for r in ratings],
    }


# =============================================================================
# Grey Market APIs (æš—ç›˜æ•°æ®) ğŸŒ™
# =============================================================================

def fetch_grey_list(
    sector: str = "",
    order_by: str = "resultDate",
    order_dir: str = "desc",
    page_size: int = 100
) -> list[dict]:
    """è·å–æš—ç›˜æ•°æ®åˆ—è¡¨ã€‚
    
    Args:
        sector: æ¿å—è¿‡æ»¤
        order_by: æ’åºå­—æ®µ (resultDate, grayPriceChg)
        order_dir: æ’åºæ–¹å‘ (desc, asc)
        page_size: æ¯é¡µæ•°é‡
        
    Returns:
        æš—ç›˜æ•°æ®åˆ—è¡¨
    """
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetGreyList",
            params={
                "symbol": "",
                "sector": sector,
                "pageIndex": 1,
                "pageSize": page_size,
                "orderField": order_by,
                "orderBy": order_dir,
            }
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", {}).get("dataList", [])
    result = []
    
    for row in rows:
        result.append({
            "code": row.get("symbol", ""),
            "name": row.get("shortName", ""),
            "ipo_price": _parse_float(row.get("ipoPricing")),
            "grey_price": _parse_float(row.get("grayPrice")),
            "grey_change_pct": _parse_float(row.get("grayPriceChg")),
            "grey_volume": _parse_float(row.get("grayZl")),
            "grey_turnover": _parse_float(row.get("grayZe")),
            "result_date": _parse_datetime(row.get("resultDate")),
            "listing_date": _parse_datetime(row.get("listedDate")),
            "issue_number": _parse_float(row.get("issueNumber")),
            "issue_number_hk": _parse_float(row.get("issueNumber_HK")),
            "issue_number_intl": _parse_float(row.get("issueNumber_Other")),
        })
    
    return result


def fetch_allotment_results(page_size: int = 100) -> list[dict]:
    """è·å–é…å”®ç»“æœåˆ—è¡¨ã€‚
    
    Returns:
        é…å”®ç»“æœåˆ—è¡¨ï¼ŒåŒ…å«è¶…è´­å€æ•°ã€ä¸­ç­¾ç‡ç­‰
    """
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetAllotmentResultList",
            params={"pageIndex": 1, "pageSize": page_size}
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", {}).get("dataList", [])
    result = []
    
    for row in rows:
        result.append({
            "code": row.get("symbol", ""),
            "name": row.get("shortName", ""),
            "sector": row.get("sector", ""),
            "industry": row.get("industry", ""),
            "apply_start": _parse_datetime(row.get("startdate")),
            "apply_end": _parse_datetime(row.get("enddate")),
            "result_date": _parse_datetime(row.get("resultDate")),
            "listing_date": _parse_datetime(row.get("listedDate")),
            "ipo_price": _parse_float(row.get("ipoPricing")),
            "price_range": f"{row.get('price_Floor', '')}-{row.get('price_Ceiling', '')}",
            "subscribed": _parse_float(row.get("subscribed")),  # è¶…è´­å€æ•°
            "sponsors": row.get("sponsors", ""),
            "market_value": _parse_float(row.get("marketValue")),
            "pe": _parse_float(row.get("pe")),
            "margin_data": _parse_float(row.get("marginData")),
        })
    
    return result


def fetch_today_grey_market(top: int = 10) -> list[dict]:
    """è·å–ä»Šæ—¥æš—ç›˜è‚¡ç¥¨åˆ—è¡¨ï¼ˆé¦–é¡µç”¨ï¼‰ã€‚
    
    Args:
        top: è¿”å›æ•°é‡
        
    Returns:
        ä»Šæ—¥æš—ç›˜è‚¡ç¥¨åˆ—è¡¨ï¼ŒåŒ…å«å‘è¡Œä»·ã€è¶…è´­å€æ•°ã€å›æ‹¨æ¯”ä¾‹ã€ä¸­ç­¾ç‡ç­‰
    """
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetDarkDiskInfo",
            params={"top": top}
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", [])
    result = []
    
    for row in rows:
        result.append({
            "code": row.get("symbol", ""),
            "name": row.get("shortName", ""),
            "ipo_price": _parse_float(row.get("ipoPricing")),
            "subscribed": _parse_float(row.get("subscribed")),  # è¶…è´­å€æ•°
            "clawback": _parse_float(row.get("clawback")),  # å›æ‹¨æ¯”ä¾‹%
            "codes_rate": _parse_float(row.get("codesRate")),  # ä¸­ç­¾ç‡%
            "result_date": _parse_datetime(row.get("resultDate")),
        })
    
    return result


def fetch_grey_trade_details(
    code: str,
    trade_date: str,
    page_size: int = 100
) -> dict | None:
    """è·å–æš—ç›˜äº¤æ˜“æ˜ç»†ã€‚
    
    Args:
        code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ "00600"ï¼‰
        trade_date: äº¤æ˜“æ—¥æœŸï¼ˆæ ¼å¼ "YYYY-MM-DD"ï¼‰
        page_size: æ¯é¡µæ•°é‡
        
    Returns:
        äº¤æ˜“æ˜ç»†ï¼ŒåŒ…å«æ€»æˆäº¤ç¬”æ•°å’Œé€ç¬”æˆäº¤è®°å½•
    """
    code = _normalize_code(code)
    
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetTradeDateData",
            params={
                "code": code,
                "tradeDate": trade_date,
                "pageIndex": 1,
                "pageSize": page_size,
            }
        )
    
    if data.get("result") != 1:
        return None
    
    result_data = data.get("data", {})
    trades = result_data.get("dataList", [])
    
    return {
        "code": code,
        "trade_date": trade_date,
        "total_trades": result_data.get("totalRows", 0),
        "trades": [
            {
                "time": t.get("time", ""),  # æ ¼å¼: "182900"
                "direction": t.get("buySell", ""),  # è²·å…¥/è³£å‡º/å…¶ä»–
                "volume": _parse_float(t.get("zl")),  # æˆäº¤é‡
                "amount": _parse_float(t.get("ze")),  # æˆäº¤é¢
                "price": _parse_float(t.get("price")),  # æˆäº¤ä»·
            }
            for t in trades
        ],
    }


def fetch_grey_price_distribution(
    code: str,
    trade_date: str
) -> list[dict]:
    """è·å–æš—ç›˜åˆ†ä»·ç»Ÿè®¡ã€‚
    
    Args:
        code: è‚¡ç¥¨ä»£ç 
        trade_date: äº¤æ˜“æ—¥æœŸï¼ˆæ ¼å¼ "YYYY-MM-DD"ï¼‰
        
    Returns:
        åˆ†ä»·ç»Ÿè®¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»·ä½çš„æˆäº¤é‡å’Œå æ¯”
    """
    code = _normalize_code(code)
    
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetTradeDateStatisticsData",
            params={
                "code": code,
                "tradeDate": trade_date,
                "pageIndex": 1,
                "pageSize": 100,
            }
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", {}).get("dataList", [])
    result = []
    
    for row in rows:
        result.append({
            "price": _parse_float(row.get("price")),
            "volume": _parse_float(row.get("zl")),
            "rate": _parse_float(row.get("rate")),  # å æ¯” (0-1)
        })
    
    # æŒ‰ä»·æ ¼é™åºæ’åº
    result.sort(key=lambda x: x["price"], reverse=True)
    return result


def fetch_grey_price_distribution_detail(
    code: str,
    trade_date: str
) -> list[dict]:
    """è·å–æš—ç›˜è¯¦ç»†åˆ†ä»·æ˜ç»†ï¼ˆå«å†…å¤–ç›˜ï¼‰ã€‚
    
    Args:
        code: è‚¡ç¥¨ä»£ç 
        trade_date: äº¤æ˜“æ—¥æœŸï¼ˆæ ¼å¼ "YYYY-MM-DD"ï¼‰
        
    Returns:
        è¯¦ç»†åˆ†ä»·æ˜ç»†ï¼ŒåŒ…å«å†…ç›˜(å–)ã€å¤–ç›˜(ä¹°)æˆäº¤é‡
    """
    code = _normalize_code(code)
    
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetTradeDateStatisticsMore",
            params={
                "code": code,
                "tradeDate": trade_date,
                "pageIndex": 1,
                "pageSize": 100,
            }
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", {}).get("dataList", [])
    result = []
    
    for row in rows:
        result.append({
            "price": _parse_float(row.get("price")),
            "volume": _parse_float(row.get("zl")),
            "rate": _parse_float(row.get("rate")),  # å æ¯” (0-1)
            "inner_volume": _parse_float(row.get("innerZl")),  # å†…ç›˜ï¼ˆä¸»åŠ¨å–ï¼‰
            "outer_volume": _parse_float(row.get("outerZl")),  # å¤–ç›˜ï¼ˆä¸»åŠ¨ä¹°ï¼‰
        })
    
    # æŒ‰ä»·æ ¼é™åºæ’åº
    result.sort(key=lambda x: x["price"], reverse=True)
    return result


def fetch_grey_placing_detail(code: str) -> dict | None:
    """è·å–æš—ç›˜é…å”®è¯¦æƒ…ï¼ˆç”²ä¹™ç»„åˆ†é…ï¼‰ã€‚
    
    Args:
        code: è‚¡ç¥¨ä»£ç 
        
    Returns:
        é…å”®è¯¦æƒ…ï¼ŒåŒ…å«ç”³è´­äººæ•°ã€ä¸€æ‰‹è‚¡æ•°ã€å„æ¡£ä½ä¸­ç­¾æƒ…å†µ
    """
    code = _code_with_prefix(code)
    
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetPlacingResult",
            params={"code": code}
        )
    
    if data.get("result") != 1:
        return None
    
    try:
        msg_data = json.loads(data.get("msg", "{}"))
        info = msg_data.get("data", {})
    except json.JSONDecodeError:
        return None
    
    if not info:
        return None
    
    # è§£æåˆ†ç»„é…å”®æ˜ç»†
    placing_list = []
    for item in info.get("list", []):
        if len(item) >= 5:
            placing_list.append({
                "apply_shares": _parse_float(item[0]),  # ç”³è´­è‚¡æ•°
                "applicants": _parse_float(item[1]),  # ç”³è´­äººæ•°
                "win_rate": _parse_float(item[3]) if item[3] else None,  # ä¸­ç­¾ç‡
                "description": item[4] if item[4] else "",  # æè¿°
                "min_amount": _parse_float(item[6]) if len(item) > 6 else None,  # æœ€ä½å…¥åœºè´¹
            })
    
    return {
        "code": code.replace("E", ""),
        "name": info.get("name", ""),
        "total_applicants": _parse_float(info.get("num")),  # æ€»ç”³è´­äººæ•°
        "lot_size": _parse_float(info.get("lot")),  # ä¸€æ‰‹è‚¡æ•°
        "min_entry_amount": _parse_float(info.get("sz")),  # æœ€ä½å…¥åœºè´¹
        "clawback_rate": info.get("rate", ""),  # å›æ‹¨æ¯”ä¾‹æè¿°ï¼Œå¦‚ "50/1"
        "result_pdf": info.get("rlink", ""),  # é…å”®ç»“æœ PDF é“¾æ¥
        "placing_list": placing_list,
    }


def fetch_market_scroll_messages(top: int = 20) -> list[dict]:
    """è·å–å¸‚åœºæ»šåŠ¨æ¶ˆæ¯ï¼ˆå«æš—ç›˜ã€å­–å±•ã€æŒè‚¡å¼‚åŠ¨ï¼‰ã€‚
    
    Args:
        top: è¿”å›æ•°é‡
        
    Returns:
        æ»šåŠ¨æ¶ˆæ¯åˆ—è¡¨
    """
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetBottomScrollList",
            params={"top": top, "per": 10}
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", [])
    result = []
    
    for row in rows:
        msg_type = row.get("type", "")
        type_name = {
            "1": "å­–å±•å¼‚åŠ¨",
            "2": "æŒè‚¡å¼‚åŠ¨", 
            "3": "æš—ç›˜å¼‚åŠ¨",
        }.get(msg_type, "å…¶ä»–")
        
        result.append({
            "code": row.get("symbol", ""),
            "message": row.get("message", ""),
            "type": type_name,
            "type_code": msg_type,
            "trader_id": row.get("traderId"),
            "modify_time": _parse_datetime(row.get("modifyTime")),
        })
    
    return result


# =============================================================================
# Statistics APIs (å¹´åº¦ç»Ÿè®¡)
# =============================================================================

def fetch_ipo_summary(year: int) -> list[dict]:
    """è·å– IPO å¹´åº¦æ±‡æ€»ï¼ˆå«å­–å±•æ€»é¢ï¼‰ã€‚
    
    Args:
        year: å¹´ä»½ï¼Œå¦‚ 2025
        
    Returns:
        å„å¸‚åœº IPO æ±‡æ€»åˆ—è¡¨ï¼ŒåŒ…å«ä¸Šå¸‚æ•°é‡å’Œå­–å±•æ€»é¢
        
    Note:
        æ­¤ API è¿”å›å­–å±•æ€»é¢ï¼ˆloanAmountï¼‰ï¼Œä½†ä¸å«è¡¨ç°æ•°æ®
    """
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetIPOSummary",
            params={"year": year}
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", [])
    result = []
    
    for row in rows:
        # loanAmount æ˜¯æ¸¯å…ƒï¼Œè½¬æ¢ä¸ºäº¿æ¸¯å…ƒ
        loan_amount = _parse_float(row.get("loanAmount", 0))
        loan_amount_billion = loan_amount / 1e8 if loan_amount else 0
        
        result.append({
            "market": row.get("market", ""),  # HK=æ¸¯è‚¡, N=ç¾è‚¡, A=Aè‚¡
            "list_amount": row.get("listAmount", 0),  # ä¸Šå¸‚æ•°é‡
            "total_margin_billion": round(loan_amount_billion, 2),  # å­–å±•æ€»é¢ï¼ˆäº¿æ¸¯å…ƒï¼‰
            "update_time": _parse_datetime(row.get("updateTime")),
        })
    
    return result


def fetch_ipo_performance_by_year(year: int) -> list[dict]:
    """è·å– IPO å¹´åº¦è¡¨ç°ç»Ÿè®¡ã€‚
    
    Args:
        year: å¹´ä»½ï¼Œå¦‚ 2025
        
    Returns:
        å„å¸‚åœº IPO è¡¨ç°ç»Ÿè®¡ï¼ŒåŒ…å«æ¶¨è·Œåˆ†å¸ƒå’Œå¹³å‡æ¶¨è·Œå¹…
    """
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetIPOSummaryByYear",
            params={"year": year}
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", [])
    result = []
    
    for row in rows:
        list_amount = row.get("listAmount", 0)
        first_up = row.get("firstZs", 0)
        first_down = row.get("firstDs", 0)
        first_flat = row.get("plateAmount", 0)
        
        # è®¡ç®—é¦–æ—¥ä¸Šæ¶¨ç‡
        up_rate = round(first_up / list_amount * 100, 1) if list_amount > 0 else 0
        
        result.append({
            "market": row.get("market", ""),  # HK=æ¸¯è‚¡, N=ç¾è‚¡, A=Aè‚¡
            "list_amount": list_amount,  # ä¸Šå¸‚æ•°é‡
            "first_day_up": first_up,  # é¦–æ—¥ä¸Šæ¶¨æ•°
            "first_day_down": first_down,  # é¦–æ—¥ä¸‹è·Œæ•°
            "first_day_flat": first_flat,  # é¦–æ—¥å¹³ç›˜/ç ´æ¿æ•°
            "first_day_up_rate": up_rate,  # é¦–æ—¥ä¸Šæ¶¨ç‡ %
            "avg_gain_pct": round(_parse_float(row.get("avgZf")), 2),  # å¹³å‡æ¶¨å¹… %
            "avg_loss_pct": round(_parse_float(row.get("avgDf")), 2),  # å¹³å‡è·Œå¹… %
        })
    
    return result


def fetch_ipo_by_registered_office(year: int) -> list[dict]:
    """è·å– IPO æŒ‰æ³¨å†Œåœ°ç»Ÿè®¡ã€‚
    
    Args:
        year: å¹´ä»½ï¼Œå¦‚ 2025
        
    Returns:
        æŒ‰æ³¨å†Œåœ°åˆ†ç»„çš„ IPO æ•°é‡ç»Ÿè®¡
    """
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetIPORegisteredByYear",
            params={"year": year}
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", [])
    result = []
    
    for row in rows:
        if row.get("listAmount", 0) > 0:  # åªè¿”å›æœ‰ä¸Šå¸‚çš„
            result.append({
                "registered_office": row.get("registeredOffice", ""),
                "list_amount": row.get("listAmount", 0),
            })
    
    # æŒ‰ä¸Šå¸‚æ•°é‡é™åº
    result.sort(key=lambda x: x["list_amount"], reverse=True)
    return result


# =============================================================================
# IPO Detail APIs (IPOè¯¦æƒ…)
# =============================================================================

def fetch_ipo_brief(code: str) -> dict | None:
    """è·å–æ–°è‚¡ç®€å†µã€‚
    
    Args:
        code: è‚¡ç¥¨ä»£ç 
        
    Returns:
        IPO ç®€å†µï¼ŒåŒ…å«ä¿èäººã€å‘è¡Œä»·ã€æ‹›è‚¡æ—¥æœŸç­‰
    """
    code = _code_with_prefix(code)
    
    with AiPOClient() as client:
        data = client._request(
            "/Home/NewStockBrief",
            params={"code": code}
        )
    
    if data.get("result") != 1:
        return None
    
    try:
        msg_data = json.loads(data.get("msg", "{}"))
        info = msg_data.get("data", {})
    except json.JSONDecodeError:
        return None
    
    if not info:
        return None
    
    institution = info.get("institutioninfo", {})
    issuance = info.get("issuanceinfo", {})
    ipo_price = issuance.get("ipoprice", {})
    ipo_date = issuance.get("ipodate", {})
    
    return {
        "code": code.replace("E", ""),
        # æœºæ„ä¿¡æ¯
        "principal_office": institution.get("principaloffice", ""),
        "registrars": institution.get("registrars", ""),
        "chairman": institution.get("chairman", ""),
        "secretary": institution.get("secretary", ""),
        "principal_activities": institution.get("principalactivities", ""),
        "substantial_shareholders": institution.get("substantialshareholders", ""),
        # å‘è¡Œä¿¡æ¯
        "industry": issuance.get("industry", ""),
        "sponsors": issuance.get("sponsors", ""),
        "bookrunners": issuance.get("bookrunners", ""),
        "lead_agent": issuance.get("leadagent", ""),
        "coordinator": issuance.get("coordinator", ""),
        "ipo_price_floor": _parse_float(ipo_price.get("floor")),
        "ipo_price_ceiling": _parse_float(ipo_price.get("ceiling")),
        "ipo_pricing": issuance.get("ipopricing", ""),
        "apply_start": _parse_datetime(ipo_date.get("start")),
        "apply_end": _parse_datetime(ipo_date.get("end")),
        "listing_date": _parse_datetime(issuance.get("listeddate")),
        "shares": _parse_float(issuance.get("shares")),
        "minimum_capital": _parse_float(issuance.get("minimumcapital")),
        "subscribed_count": _parse_float(issuance.get("subscribed")),
        "market_cap": issuance.get("marketcap", ""),
        "pe": _parse_float(issuance.get("pe")),
        "codes_rate": issuance.get("codesrate", ""),
    }


def fetch_cornerstone_investors(code: str) -> list[CornerstoneInvestor]:
    """è·å–åŸºçŸ³æŠ•èµ„è€…ä¿¡æ¯ã€‚
    
    Args:
        code: è‚¡ç¥¨ä»£ç 
        
    Returns:
        åŸºçŸ³æŠ•èµ„è€…åˆ—è¡¨
    """
    code = _code_with_prefix(code)
    
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetInvestorInfoByCode",
            params={"code": code}
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", [])
    result = []
    
    for row in rows:
        result.append(CornerstoneInvestor(
            name=row.get("investorName", ""),
            shareholding=_parse_float(row.get("shareholding")),
            shareholding_pct=_parse_float(row.get("shareholding_percentage")),
            release_date=_parse_datetime(row.get("releaseDate")),
            profile=row.get("profile", ""),
        ))
    
    return result


def fetch_placing_result(code: str) -> dict | None:
    """è·å–é…å”®ç»“æœè¯¦æƒ…ã€‚
    
    Args:
        code: è‚¡ç¥¨ä»£ç 
        
    Returns:
        é…å”®ç»“æœï¼ŒåŒ…å«ç”³è´­äººæ•°ã€ä¸­ç­¾ç‡ã€é…å”®æ˜ç»†
    """
    code = _code_with_prefix(code)
    
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetPlacingResult",
            params={"code": code}
        )
    
    if data.get("result") != 1:
        return None
    
    try:
        msg_data = json.loads(data.get("msg", "{}"))
    except json.JSONDecodeError:
        return None
    
    if msg_data.get("result") != 1:
        return None
    
    info = msg_data.get("data", {})
    if not info:
        return None
    
    return {
        "code": code.replace("E", ""),
        "applicants": _parse_float(info.get("num")),  # ç”³è´­äººæ•°
        "codes_rate": _parse_float(info.get("codes_rate")),  # ä¸­ç­¾ç‡%
        "head_hammer": info.get("head_hammer", ""),  # ä¸€æ‰‹è‚¡æ•°
        "subscribed": _parse_float(info.get("subscribed")),  # è¶…è´­å€æ•°
        "rate_desc": info.get("rate", ""),  # "ç”³è´­Xæ‰‹ç¨³è·Yæ‰‹"
        "claw_back": _parse_float(info.get("claw_back")),  # å›æ‹¨æ¯”ä¾‹%
        "placing_list": info.get("list", []),  # åˆ†ç»„é…å”®æ˜ç»†
    }


def fetch_company_managers(code: str) -> list[dict]:
    """è·å–å…¬å¸ç®¡ç†å±‚ä¿¡æ¯ã€‚
    
    Args:
        code: è‚¡ç¥¨ä»£ç ï¼ˆä¸å¸¦Eå‰ç¼€ï¼‰
    """
    code = _normalize_code(code)
    
    with AiPOClient() as client:
        data = client._request(
            "/Home/GetCompanyManager",
            params={"symbol": code}
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", [])
    result = []
    
    for row in rows:
        result.append({
            "name": row.get("name", ""),
            "post": row.get("post", ""),
            "age": row.get("age"),
            "start_year": row.get("startYear"),
            "resume": row.get("resume", ""),
        })
    
    return result


# =============================================================================
# Sponsor/Broker APIs (ä¿èäººæ•°æ®)
# =============================================================================

def fetch_sponsor_history(
    sponsor_name: str,
    sponsor_type: int = 0,
    page_size: int = 20
) -> list[dict]:
    """è·å–ä¿èäºº/æ‰¿é”€å•†å†å²é¡¹ç›®ã€‚
    
    Args:
        sponsor_name: ä¿èäººåç§°
        sponsor_type: 0=ä¿èäºº, 2=è´¦ç°¿ç®¡ç†äºº, 5=æ‰¿é”€å›¢
        page_size: æ¯é¡µæ•°é‡
        
    Returns:
        å†å²é¡¹ç›®åˆ—è¡¨
    """
    with AiPOClient() as client:
        data = client._request(
            "/Home/SpoHisProjects",
            params={
                "market": "mkt_hk",
                "sponsor": sponsor_name,
                "type": sponsor_type,
                "pageIndex": 1,
                "pageSize": page_size,
            }
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", {}).get("dataList", [])
    result = []
    
    for row in rows:
        result.append({
            "code": row.get("symbol", "").replace("E", ""),
            "name": row.get("shortName", ""),
            "grey_change_pct": _parse_float(row.get("grayPriceChg")),
            "first_day_change_pct": _parse_float(row.get("firstDayChg")),
            "listing_date": _parse_datetime(row.get("listedDate")),
            "current_price": _parse_float(row.get("nowprice")),
            "total_change_pct": _parse_float(row.get("zdf")),
        })
    
    return result


# =============================================================================
# Broker Ranking APIs (åˆ¸å•†æ’åæ•°æ®) ğŸ†
# =============================================================================

def fetch_bookrunner_ranking(
    start_date: str,
    end_date: str,
    sector: str = "",
    page_size: int = 50,
    page_index: int = 1,
) -> list[dict]:
    """è·å–è´¦ç°¿ç®¡ç†äººæ’åã€‚
    
    Args:
        start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        sector: æ¿å—è¿‡æ»¤ï¼Œç©º=å…¨éƒ¨, "ä¸»æ¿", "åˆ›ä¸šæ¿"
        page_size: æ¯é¡µæ•°é‡
        page_index: é¡µç 
        
    Returns:
        è´¦ç°¿ç®¡ç†äººæ’ååˆ—è¡¨
    """
    with AiPOClient() as client:
        data = client._request(
            "/Margin/GetBookrunnerJoinSort",
            params={
                "sector": sector,
                "pageIndex": page_index,
                "pageSize": page_size,
                "startDate": start_date,
                "endDate": end_date,
            }
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", {}).get("dataList", [])
    result = []
    
    for row in rows:
        result.append({
            "rank": row.get("rowNo", 0),
            "name": row.get("name", ""),
            "count": row.get("number", 0),  # å‚ä¸å®¶æ•°
            "grey_rise_count": row.get("darkMarketRiserCompanies", 0),  # æš—ç›˜ä¸Šæ¶¨å®¶æ•°
            "first_day_rise_count": row.get("firstDayFallCompanies", 0),  # é¦–æ—¥ä¸Šæ¶¨å®¶æ•°ï¼ˆå­—æ®µåæœ‰è¯¯å¯¼ï¼‰
        })
    
    return result


def fetch_bookrunner_details(
    name: str,
    start_date: str,
    end_date: str,
    sector: str = "",
    page_size: int = 50,
    page_index: int = 1,
) -> list[dict]:
    """è·å–è´¦ç°¿ç®¡ç†äººå‚ä¸çš„ IPO è¯¦æƒ…ã€‚
    
    Args:
        name: è´¦ç°¿ç®¡ç†äººåç§°
        start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        sector: æ¿å—è¿‡æ»¤
        page_size: æ¯é¡µæ•°é‡
        page_index: é¡µç 
        
    Returns:
        è¯¥è´¦ç°¿ç®¡ç†äººå‚ä¸çš„ IPO åˆ—è¡¨
    """
    with AiPOClient() as client:
        data = client._request(
            "/Margin/GetBookrunnerJoinDetails",
            params={
                "sector": sector,
                "pageIndex": page_index,
                "pageSize": page_size,
                "startDate": start_date,
                "endDate": end_date,
                "name": name,
            }
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", {}).get("dataList", [])
    result = []
    
    for row in rows:
        result.append({
            "code": row.get("symbol", ""),
            "name": row.get("shortName", ""),
            "ipo_price": _parse_float(row.get("ipoPricing")),
            "listing_date": _parse_datetime(row.get("listedDate")),
            "first_day_change_pct": _parse_float(row.get("firstDayChg")),
            "grey_change_pct": _parse_float(row.get("grayPriceChg")),
        })
    
    return result


def fetch_broker_participation_ranking(
    start_date: str,
    end_date: str,
    sector: str = "",
    page_size: int = 50,
    page_index: int = 1,
) -> list[dict]:
    """è·å–åˆ¸å•†å‚ä¸æ’åï¼ˆæ‰“æ–°åˆ¸å•†å‚ä¸åº¦ï¼‰ã€‚
    
    Args:
        start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        sector: æ¿å—è¿‡æ»¤ï¼Œç©º=å…¨éƒ¨, "ä¸»æ¿", "åˆ›ä¸šæ¿"
        page_size: æ¯é¡µæ•°é‡
        page_index: é¡µç 
        
    Returns:
        åˆ¸å•†å‚ä¸æ’ååˆ—è¡¨
    """
    with AiPOClient() as client:
        data = client._request(
            "/Margin/GetJoinSort",
            params={
                "sector": sector,
                "pageIndex": page_index,
                "pageSize": page_size,
                "startDate": start_date,
                "endDate": end_date,
            }
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", {}).get("dataList", [])
    result = []
    
    for row in rows:
        result.append({
            "rank": row.get("rowNo", 0),
            "name": row.get("name", ""),
            "count": row.get("number", 0),  # å‚ä¸å®¶æ•°
            "grey_rise_count": row.get("darkMarketRiserCompanies", 0),  # æš—ç›˜ä¸Šæ¶¨å®¶æ•°
            "first_day_rise_count": row.get("firstDayFallCompanies", 0),  # é¦–æ—¥ä¸Šæ¶¨å®¶æ•°
        })
    
    return result


def fetch_broker_participation_details(
    name: str,
    start_date: str,
    end_date: str,
    sector: str = "",
    page_size: int = 50,
    page_index: int = 1,
) -> list[dict]:
    """è·å–åˆ¸å•†å‚ä¸çš„ IPO è¯¦æƒ…ã€‚
    
    Args:
        name: åˆ¸å•†åç§°
        start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        sector: æ¿å—è¿‡æ»¤
        page_size: æ¯é¡µæ•°é‡
        page_index: é¡µç 
        
    Returns:
        è¯¥åˆ¸å•†å‚ä¸çš„ IPO åˆ—è¡¨
    """
    with AiPOClient() as client:
        data = client._request(
            "/Margin/GetJoinDetails",
            params={
                "sector": sector,
                "pageIndex": page_index,
                "pageSize": page_size,
                "startDate": start_date,
                "endDate": end_date,
                "name": name,
            }
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", {}).get("dataList", [])
    result = []
    
    for row in rows:
        result.append({
            "code": row.get("symbol", ""),
            "name": row.get("shortName", ""),
            "ipo_price": _parse_float(row.get("ipoPricing")),
            "listing_date": _parse_datetime(row.get("listedDate")),
            "first_day_change_pct": _parse_float(row.get("firstDayChg")),
            "grey_change_pct": _parse_float(row.get("grayPriceChg")),
        })
    
    return result


def fetch_stableprice_ranking(
    start_date: str,
    end_date: str,
    sector: str = "",
    page_size: int = 50,
    page_index: int = 1,
) -> list[dict]:
    """è·å–ç¨³ä»·äººæ’åã€‚
    
    Args:
        start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        sector: æ¿å—è¿‡æ»¤ï¼Œç©º=å…¨éƒ¨, "ä¸»æ¿", "åˆ›ä¸šæ¿"
        page_size: æ¯é¡µæ•°é‡
        page_index: é¡µç 
        
    Returns:
        ç¨³ä»·äººæ’ååˆ—è¡¨
    """
    with AiPOClient() as client:
        data = client._request(
            "/Margin/GetStablepriceJoinSort",
            params={
                "sector": sector,
                "pageIndex": page_index,
                "pageSize": page_size,
                "startDate": start_date,
                "endDate": end_date,
            }
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", {}).get("dataList", [])
    result = []
    
    for row in rows:
        result.append({
            "rank": row.get("rowNo", 0),
            "name": row.get("name", ""),
            "count": row.get("number", 0),  # å‚ä¸å®¶æ•°
            "grey_rise_count": row.get("darkMarketRiserCompanies", 0),  # æš—ç›˜ä¸Šæ¶¨å®¶æ•°
            "first_day_rise_count": row.get("firstDayFallCompanies", 0),  # é¦–æ—¥ä¸Šæ¶¨å®¶æ•°
        })
    
    return result


def fetch_stableprice_details(
    name: str,
    start_date: str,
    end_date: str,
    sector: str = "",
    page_size: int = 50,
    page_index: int = 1,
) -> list[dict]:
    """è·å–ç¨³ä»·äººå‚ä¸çš„ IPO è¯¦æƒ…ã€‚
    
    Args:
        name: ç¨³ä»·äººåç§°
        start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        sector: æ¿å—è¿‡æ»¤
        page_size: æ¯é¡µæ•°é‡
        page_index: é¡µç 
        
    Returns:
        è¯¥ç¨³ä»·äººå‚ä¸çš„ IPO åˆ—è¡¨
    """
    with AiPOClient() as client:
        data = client._request(
            "/Margin/GetStablepriceJoinDetails",
            params={
                "sector": sector,
                "pageIndex": page_index,
                "pageSize": page_size,
                "startDate": start_date,
                "endDate": end_date,
                "name": name,
            }
        )
    
    if data.get("result") != 1:
        return []
    
    rows = data.get("data", {}).get("dataList", [])
    result = []
    
    for row in rows:
        result.append({
            "code": row.get("symbol", ""),
            "name": row.get("shortName", ""),
            "ipo_price": _parse_float(row.get("ipoPricing")),
            "listing_date": _parse_datetime(row.get("listedDate")),
            "first_day_change_pct": _parse_float(row.get("firstDayChg")),
            "grey_change_pct": _parse_float(row.get("grayPriceChg")),
        })
    
    return result


# =============================================================================
# Formatting Functions
# =============================================================================

def format_margin_table(summary: MarginSummary) -> str:
    """æ ¼å¼åŒ–å­–å±•æ•°æ®ä¸ºè¡¨æ ¼å­—ç¬¦ä¸²ã€‚"""
    lines = [
        f"=== {summary.name} ({summary.code}) å­–å±•æ•°æ® ===",
        f"æ‹›è‚¡æœŸé—´: {summary.apply_start} - {summary.apply_end}",
        f"å­–å±•æ€»é¢: {summary.total_margin:.2f} äº¿æ¸¯å…ƒ",
        f"å‹Ÿèµ„é‡‘é¢: {summary.raise_money:.2f} äº¿æ¸¯å…ƒ",
    ]
    
    if summary.oversubscription_actual:
        lines.append(f"å®é™…è¶…è´­: {summary.oversubscription_actual:.2f} å€")
    if summary.oversubscription_forecast:
        lines.append(f"é¢„æµ‹è¶…è´­: {summary.oversubscription_forecast:.2f} å€")
    
    if summary.update_time:
        lines.append(f"æ›´æ–°æ—¶é—´: {summary.update_time}")
    
    lines.append("")
    lines.append("å„åˆ¸å•†å­–å±•æ˜ç»†:")
    lines.append("-" * 60)
    lines.append(f"{'åˆ¸å•†åç§°':<15} {'å­–å±•é‡‘é¢':>12} {'åˆ©ç‡':>8} {'å˜åŒ–':>12}")
    lines.append("-" * 60)
    
    for b in summary.broker_margins:
        rate_str = f"{b.interest_rate:.2f}%" if b.interest_rate > 0 else "-"
        change_str = f"+{b.change_amount:.4f}" if b.change_amount > 0 else (f"{b.change_amount:.4f}" if b.change_amount < 0 else "-")
        lines.append(f"{b.broker_name:<15} {b.margin_amount:>12.4f} {rate_str:>8} {change_str:>12}")
    
    lines.append("-" * 60)
    
    return "\n".join(lines)


def format_rating_table(ratings: list[AgencyRating]) -> str:
    """æ ¼å¼åŒ–è¯„çº§æ•°æ®ä¸ºè¡¨æ ¼å­—ç¬¦ä¸²ã€‚"""
    if not ratings:
        return "æš‚æ— è¯„çº§æ•°æ®"
    
    lines = ["=== æœºæ„è¯„çº§ ===", "-" * 50]
    lines.append(f"{'æœºæ„åç§°':<20} {'è¯„åˆ†':>10} {'è¯„çº§':>15}")
    lines.append("-" * 50)
    
    for r in ratings:
        lines.append(f"{r.agency_name:<20} {r.score:>10.0f} {r.rating:>15}")
    
    lines.append("-" * 50)
    scores = [r.score for r in ratings]
    lines.append(f"ç»¼åˆè¯„åˆ†: {sum(scores)/len(scores):.1f} ({len(ratings)}å®¶)")
    
    return "\n".join(lines)


# =============================================================================
# CLI
# =============================================================================

def main(argv=None):
    """CLI å…¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description="AiPO æ¸¯è‚¡æ‰“æ–°æ•°æ®æŸ¥è¯¢")
    parser.add_argument("command", choices=[
        "margin-list", "margin-detail",
        "rating-list", "rating-detail",
        "grey-list", "grey-today", "grey-trades", "grey-prices", "grey-placing",
        "allotment", "scroll",
        "ipo-brief", "cornerstone", "placing",
        "summary", "performance", "by-office",
        "bookrunner-rank", "broker-rank", "stableprice-rank",
    ], help="å‘½ä»¤")
    parser.add_argument("code", nargs="?", help="è‚¡ç¥¨ä»£ç  (detail ç±»å‘½ä»¤éœ€è¦)")
    parser.add_argument("--format", "-f", choices=["json", "table"], default="json", help="è¾“å‡ºæ ¼å¼")
    parser.add_argument("--sector", default="", help="æ¿å—è¿‡æ»¤")
    parser.add_argument("--limit", type=int, default=20, help="ç»“æœæ•°é‡é™åˆ¶")
    parser.add_argument("--date", help="äº¤æ˜“æ—¥æœŸ (YYYY-MM-DD)")
    parser.add_argument("--year", type=int, help="ç»Ÿè®¡å¹´ä»½ (summary/performance/by-office å‘½ä»¤éœ€è¦)")
    parser.add_argument("--start-date", help="å¼€å§‹æ—¥æœŸ (YYYY-MM-DD, æ’åå‘½ä»¤éœ€è¦)")
    parser.add_argument("--end-date", help="ç»“æŸæ—¥æœŸ (YYYY-MM-DD, æ’åå‘½ä»¤éœ€è¦)")
    parser.add_argument("--name", help="æœºæ„åç§° (æŸ¥è¯¢è¯¦æƒ…æ—¶éœ€è¦)")

    args = parser.parse_args(argv)

    if args.command == "margin-list":
        result = fetch_margin_list(sector=args.sector)
        if args.format == "json":
            print(json.dumps(result[:args.limit], ensure_ascii=False, indent=2))
        else:
            for m in result[:args.limit]:
                status = m.get("margin_type") or ""
                print(f"{m['code']} {m['name']}: {m['total_margin']:.2f}äº¿ {status}")
    
    elif args.command == "margin-detail":
        if not args.code:
            print("Error: éœ€è¦è‚¡ç¥¨ä»£ç ", file=sys.stderr)
            sys.exit(1)
        summary = fetch_margin_detail(args.code)
        if summary:
            if args.format == "json":
                print(json.dumps(summary.to_dict(), ensure_ascii=False, indent=2))
            else:
                print(format_margin_table(summary))
        else:
            print(f"æœªæ‰¾åˆ°è‚¡ç¥¨ {args.code} çš„å­–å±•æ•°æ®")
    
    elif args.command == "rating-list":
        result = fetch_rating_list(sector=args.sector, page_size=args.limit)
        if args.format == "json":
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            for r in result:
                stars = "â˜…" * int(r['avg_score'] / 20)
                print(f"{r['code']} {r['name']}: {r['avg_score']:.1f}åˆ† {stars} ({r['rating_count']}å®¶)")
    
    elif args.command == "rating-detail":
        if not args.code:
            print("Error: éœ€è¦è‚¡ç¥¨ä»£ç ", file=sys.stderr)
            sys.exit(1)
        ratings = fetch_rating_detail(args.code)
        if ratings:
            if args.format == "json":
                print(json.dumps([r.to_dict() for r in ratings], ensure_ascii=False, indent=2))
            else:
                print(format_rating_table(ratings))
        else:
            print(f"æœªæ‰¾åˆ°è‚¡ç¥¨ {args.code} çš„è¯„çº§æ•°æ®")
    
    elif args.command == "grey-list":
        result = fetch_grey_list(sector=args.sector, page_size=args.limit)
        if args.format == "json":
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            for g in result:
                chg = g['grey_change_pct']
                sign = "+" if chg >= 0 else ""
                print(f"{g['code']} {g['name']}: æš—ç›˜{sign}{chg:.1f}% (å‘è¡Œä»·:{g['ipo_price']:.2f})")
    
    elif args.command == "grey-today":
        result = fetch_today_grey_market(top=args.limit)
        if args.format == "json":
            if not result:
                print(json.dumps({"message": "ä»Šæ—¥æ— æš—ç›˜äº¤æ˜“"}, ensure_ascii=False, indent=2))
            else:
                print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            if not result:
                print("ä»Šæ—¥æ— æš—ç›˜äº¤æ˜“")
            else:
                for g in result:
                    print(f"{g['code']} {g['name']}: å‘è¡Œä»·{g['ipo_price']:.2f} è¶…è´­{g['subscribed']:.1f}å€ ä¸­ç­¾{g['codes_rate']:.2f}%")
    
    elif args.command == "grey-trades":
        if not args.code:
            print("Error: éœ€è¦è‚¡ç¥¨ä»£ç ", file=sys.stderr)
            sys.exit(1)
        if not args.date:
            print("Error: éœ€è¦ --date YYYY-MM-DD", file=sys.stderr)
            sys.exit(1)
        result = fetch_grey_trade_details(args.code, args.date, page_size=args.limit)
        print(json.dumps(result, ensure_ascii=False, indent=2))
    
    elif args.command == "grey-prices":
        if not args.code:
            print("Error: éœ€è¦è‚¡ç¥¨ä»£ç ", file=sys.stderr)
            sys.exit(1)
        if not args.date:
            print("Error: éœ€è¦ --date YYYY-MM-DD", file=sys.stderr)
            sys.exit(1)
        result = fetch_grey_price_distribution_detail(args.code, args.date)
        if args.format == "json":
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            print(f"{'ä»·æ ¼':>10} {'æˆäº¤é‡':>12} {'å æ¯”':>10} {'å†…ç›˜':>10} {'å¤–ç›˜':>10}")
            print("-" * 56)
            for p in result:
                rate_pct = p['rate'] * 100
                inner = p.get('inner_volume') or 0
                outer = p.get('outer_volume') or 0
                print(f"{p['price']:>10.2f} {p['volume']:>12.0f} {rate_pct:>9.2f}% {inner:>10.0f} {outer:>10.0f}")
    
    elif args.command == "grey-placing":
        if not args.code:
            print("Error: éœ€è¦è‚¡ç¥¨ä»£ç ", file=sys.stderr)
            sys.exit(1)
        result = fetch_grey_placing_detail(args.code)
        print(json.dumps(result, ensure_ascii=False, indent=2))
    
    elif args.command == "allotment":
        result = fetch_allotment_results(page_size=args.limit)
        if args.format == "json":
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            for a in result:
                print(f"{a['code']} {a['name']}: è¶…è´­{a['subscribed']:.1f}å€ ä¸Šå¸‚:{a['listing_date']}")
    
    elif args.command == "scroll":
        result = fetch_market_scroll_messages(top=args.limit)
        if args.format == "json":
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            for m in result:
                print(f"[{m['type']}] {m['message']}")
    
    elif args.command == "ipo-brief":
        if not args.code:
            print("Error: éœ€è¦è‚¡ç¥¨ä»£ç ", file=sys.stderr)
            sys.exit(1)
        result = fetch_ipo_brief(args.code)
        print(json.dumps(result, ensure_ascii=False, indent=2))
    
    elif args.command == "cornerstone":
        if not args.code:
            print("Error: éœ€è¦è‚¡ç¥¨ä»£ç ", file=sys.stderr)
            sys.exit(1)
        result = fetch_cornerstone_investors(args.code)
        if args.format == "json":
            print(json.dumps([r.to_dict() for r in result], ensure_ascii=False, indent=2))
        else:
            for c in result:
                print(f"{c.name}: {c.shareholding_pct:.2f}% (è§£ç¦:{c.release_date})")
    
    elif args.command == "placing":
        if not args.code:
            print("Error: éœ€è¦è‚¡ç¥¨ä»£ç ", file=sys.stderr)
            sys.exit(1)
        result = fetch_placing_result(args.code)
        print(json.dumps(result, ensure_ascii=False, indent=2))
    
    elif args.command == "summary":
        year = args.year or datetime.now().year
        result = fetch_ipo_summary(year)
        if args.format == "json":
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            print(f"=== {year}å¹´ IPO å¹´åº¦æ±‡æ€» ===")
            for r in result:
                market_name = {"HK": "æ¸¯è‚¡", "N": "ç¾è‚¡", "A": "Aè‚¡"}.get(r["market"], r["market"])
                print(f"{market_name}: {r['list_amount']}åª | å­–å±•æ€»é¢: {r['total_margin_billion']:.2f}äº¿æ¸¯å…ƒ")
    
    elif args.command == "performance":
        year = args.year or datetime.now().year
        result = fetch_ipo_performance_by_year(year)
        if args.format == "json":
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            print(f"=== {year}å¹´ IPO è¡¨ç°ç»Ÿè®¡ ===")
            for r in result:
                market_name = {"HK": "æ¸¯è‚¡", "N": "ç¾è‚¡", "A": "Aè‚¡"}.get(r["market"], r["market"])
                print(f"{market_name}: {r['list_amount']}åª | é¦–æ—¥â†‘{r['first_day_up']}åª({r['first_day_up_rate']}%) â†“{r['first_day_down']}åª")
                print(f"      å¹³å‡æ¶¨å¹…: +{r['avg_gain_pct']}% | å¹³å‡è·Œå¹…: {r['avg_loss_pct']}%")
    
    elif args.command == "by-office":
        year = args.year or datetime.now().year
        result = fetch_ipo_by_registered_office(year)
        if args.format == "json":
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            print(f"=== {year}å¹´ IPO æŒ‰æ³¨å†Œåœ°åˆ†å¸ƒ ===")
            for r in result:
                print(f"{r['registered_office']}: {r['list_amount']}åª")
    
    elif args.command == "bookrunner-rank":
        start_date = args.start_date or f"{datetime.now().year}-01-01"
        end_date = args.end_date or f"{datetime.now().year}-12-31"
        if args.name:
            # æŸ¥è¯¢è¯¦æƒ…
            result = fetch_bookrunner_details(args.name, start_date, end_date, args.sector, args.limit)
        else:
            # æŸ¥è¯¢æ’å
            result = fetch_bookrunner_ranking(start_date, end_date, args.sector, args.limit)
        if args.format == "json":
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            print(f"=== è´¦ç°¿ç®¡ç†äººæ’å ({start_date} ~ {end_date}) ===")
            for r in result:
                if "rank" in r:
                    print(f"{r['rank']:>2}. {r['name']}: {r['count']}åª (æš—ç›˜â†‘{r['grey_rise_count']}åª, é¦–æ—¥â†‘{r['first_day_rise_count']}åª)")
                else:
                    chg = r.get('first_day_change_pct', 0)
                    sign = "+" if chg >= 0 else ""
                    print(f"{r['code']} {r['name']}: é¦–æ—¥{sign}{chg:.1f}% æš—ç›˜{r.get('grey_change_pct', 0):+.1f}%")
    
    elif args.command == "broker-rank":
        start_date = args.start_date or f"{datetime.now().year}-01-01"
        end_date = args.end_date or f"{datetime.now().year}-12-31"
        if args.name:
            # æŸ¥è¯¢è¯¦æƒ…
            result = fetch_broker_participation_details(args.name, start_date, end_date, args.sector, args.limit)
        else:
            # æŸ¥è¯¢æ’å
            result = fetch_broker_participation_ranking(start_date, end_date, args.sector, args.limit)
        if args.format == "json":
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            print(f"=== åˆ¸å•†å‚ä¸æ’å ({start_date} ~ {end_date}) ===")
            for r in result:
                if "rank" in r:
                    print(f"{r['rank']:>2}. {r['name']}: {r['count']}åª (æš—ç›˜â†‘{r['grey_rise_count']}åª, é¦–æ—¥â†‘{r['first_day_rise_count']}åª)")
                else:
                    chg = r.get('first_day_change_pct', 0)
                    sign = "+" if chg >= 0 else ""
                    print(f"{r['code']} {r['name']}: é¦–æ—¥{sign}{chg:.1f}% æš—ç›˜{r.get('grey_change_pct', 0):+.1f}%")
    
    elif args.command == "stableprice-rank":
        start_date = args.start_date or f"{datetime.now().year}-01-01"
        end_date = args.end_date or f"{datetime.now().year}-12-31"
        if args.name:
            # æŸ¥è¯¢è¯¦æƒ…
            result = fetch_stableprice_details(args.name, start_date, end_date, args.sector, args.limit)
        else:
            # æŸ¥è¯¢æ’å
            result = fetch_stableprice_ranking(start_date, end_date, args.sector, args.limit)
        if args.format == "json":
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            print(f"=== ç¨³ä»·äººæ’å ({start_date} ~ {end_date}) ===")
            for r in result:
                if "rank" in r:
                    print(f"{r['rank']:>2}. {r['name']}: {r['count']}åª (æš—ç›˜â†‘{r['grey_rise_count']}åª, é¦–æ—¥â†‘{r['first_day_rise_count']}åª)")
                else:
                    chg = r.get('first_day_change_pct', 0)
                    sign = "+" if chg >= 0 else ""
                    print(f"{r['code']} {r['name']}: é¦–æ—¥{sign}{chg:.1f}% æš—ç›˜{r.get('grey_change_pct', 0):+.1f}%")



if __name__ == "__main__":
    main()

